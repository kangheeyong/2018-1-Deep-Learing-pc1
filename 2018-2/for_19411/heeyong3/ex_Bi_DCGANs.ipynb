{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": [
     17,
     21,
     25,
     29,
     33,
     44
    ]
   },
   "source": [
    "# Bidirectional DCGANs example\n",
    "\n",
    "## 초기 설정들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     17,
     21,
     25,
     29,
     33,
     44,
     63
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_normal_data :  (5139, 64, 64, 1)\n",
      "test_anomalous_data :  (4861, 64, 64, 1)\n",
      "train_normal_data :  (28038, 64, 64, 1)\n",
      "train_anomalous_data :  (26962, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec \n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "file_dir = 'anoGANs_MNIST_data/'\n",
    "\n",
    "with gzip.open(file_dir + 'test_normal_data.pickle.gzip','rb') as f :\n",
    "    test_normal_data = pickle.load(f)\n",
    "    print('test_normal_data : ' ,test_normal_data.shape)\n",
    "\n",
    "with gzip.open(file_dir + 'test_anomalous_data.pickle.gzip','rb') as f :\n",
    "    test_anomalous_data = pickle.load(f)\n",
    "    print('test_anomalous_data : ',test_anomalous_data.shape)\n",
    "    \n",
    "with gzip.open(file_dir + 'train_normal_data.pickle.gzip','rb') as f :\n",
    "    train_normal_data = pickle.load(f)\n",
    "    print('train_normal_data : ', train_normal_data.shape)\n",
    "    \n",
    "with gzip.open(file_dir + 'train_anomalous_data.pickle.gzip','rb') as f :\n",
    "    train_anomalous_data = pickle.load(f)\n",
    "    print('train_anomalous_data : ',train_anomalous_data.shape )\n",
    "\n",
    "def idx_shuffle(x) : \n",
    "    l = x.shape[0]\n",
    "    idx = np.arange(l)\n",
    "    np.random.shuffle(idx)\n",
    "    shuffled_x = np.empty(x.shape)\n",
    "\n",
    "    for i in range(l):\n",
    "        shuffled_x[idx[i]] = x[i]\n",
    "    \n",
    "    return shuffled_x\n",
    "\n",
    "def mnist_4by4_save(samples,path):\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    gs = gridspec.GridSpec(4, 4)    \n",
    "    gs.update(wspace=0.05, hspace=0.05) #이미지 사이간격 조절\n",
    "  \n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')    \n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "   \n",
    "        plt.imshow(sample.reshape(64, 64), cmap='Greys_r',clim=(0.0,1.0))\n",
    "    plt.colorbar()\n",
    "    plt.savefig(path, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "   \n",
    "    return None\n",
    "\n",
    "def gan_loss_graph_save(G_loss,D_loss,path):\n",
    "    x1 = range(len(G_loss))\n",
    "    x2 = range(len(D_loss))\n",
    "      \n",
    "    y1 = G_loss\n",
    "    y2 = D_loss\n",
    "  \n",
    "      \n",
    "    plt.plot(x1,y1,label='G_loss') \n",
    "    plt.plot(x2,y2,label='D_loss') \n",
    "  \n",
    "    plt.xlabel('weight per update')\n",
    "    plt.ylabel('loss')             \n",
    "    plt.legend(loc=4)              \n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "  \n",
    "    plt.savefig(path)              \n",
    "\n",
    "    return None\n",
    "\n",
    "file_name = 'ex_Bi_DCGANs'\n",
    "\n",
    "if not os.path.isdir(file_name) :\n",
    "    os.mkdir(file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네트워크 정의\n",
    "\n",
    "D부분을 encoder와 discriminator로 나눈 이유는 encoder를 나중에 feature map으로 쓰기 위해서 편의상 나누어서 정의함\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "train_epoch = 50\n",
    "batch_size = 100\n",
    "z_size = 100\n",
    "\n",
    "\n",
    "def G(x,isTrain = True, reuse = False, name = 'G') : #input = (minibatch * w * h * ch)\n",
    "    \n",
    "    # out size = (in size + 2*padding - kenel)/strides + 1    \n",
    "    w_init = tf.truncated_normal_initializer(mean= 0.0, stddev=0.02)\n",
    "    b_init = tf.constant_initializer(0.0)\n",
    "\n",
    "    with tf.variable_scope('G',reuse=reuse)  :\n",
    "        \n",
    "        #x = (-1, 1, 1, 100)\n",
    "\n",
    "        conv1 = tf.layers.conv2d_transpose(x,512,[4,4], strides=(1,1),padding = 'valid',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init) \n",
    "        r1 = tf.nn.elu(tf.layers.batch_normalization(conv1,training=isTrain))#4*4*512\n",
    "        \n",
    "        conv2 = tf.layers.conv2d_transpose(r1,256,[5,5], strides=(2,2),padding = 'same',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r2 = tf.nn.elu(tf.layers.batch_normalization(conv2,training=isTrain))#8*8*256\n",
    "                \n",
    "        conv3 = tf.layers.conv2d_transpose(r2,128,[5,5], strides=(2,2),padding = 'same',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r3 = tf.nn.elu(tf.layers.batch_normalization(conv3,training=isTrain))#16*16*128\n",
    "\n",
    "        conv4 = tf.layers.conv2d_transpose(r3,64,[5,5], strides=(2,2),padding = 'same',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r4 = tf.nn.elu(tf.layers.batch_normalization(conv4,training=isTrain))#32*32*64\n",
    "\n",
    "        conv5 = tf.layers.conv2d_transpose(r4,1,[5,5], strides=(2,2),padding = 'same',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init) #64*64*1\n",
    "        \n",
    "    r5= tf.nn.tanh(conv5,name=name)#64*64*1\n",
    "  \n",
    "    return r5\n",
    "\n",
    "def E(x,isTrain = True, reuse = False, name = 'E') : #input = (minibatch * w * h * ch)\n",
    "    \n",
    "    # out size = (in size + 2*padding - kenel)/strides + 1    \n",
    "    w_init = tf.truncated_normal_initializer(mean= 0.0, stddev=0.02)\n",
    "    b_init = tf.constant_initializer(0.0)\n",
    "\n",
    "    with tf.variable_scope('E',reuse=reuse)  :\n",
    "        \n",
    "        #x = (-1, 64, 64, 1)\n",
    "\n",
    "        conv1 = tf.layers.conv2d(x,64,[5,5], strides=(2,2),padding = 'same',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init) \n",
    "        r1 = tf.nn.elu(conv1)#32*32*64\n",
    "        \n",
    "        conv2 = tf.layers.conv2d(r1,128,[5,5], strides=(2,2),padding = 'same',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r2 = tf.nn.elu(tf.layers.batch_normalization(conv2,training=isTrain))#16*16*128\n",
    "                \n",
    "        conv3 = tf.layers.conv2d(r2,256,[5,5], strides=(2,2),padding = 'same',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r3 = tf.nn.elu(tf.layers.batch_normalization(conv3,training=isTrain))#8*8*256\n",
    "\n",
    "        conv4 = tf.layers.conv2d(r3,512,[5,5], strides=(2,2),padding = 'same',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r4 = tf.nn.elu(tf.layers.batch_normalization(conv4,training=isTrain))#4*4*512\n",
    "\n",
    "        conv5 = tf.layers.conv2d(r4,100,[4,4], strides=(1,1),padding = 'valid',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init) #1*1*100\n",
    "        \n",
    "    r5= tf.add(conv5, 0 ,name=name)#1*1*100\n",
    "  \n",
    "    return r5\n",
    "\n",
    "\n",
    "\n",
    "def D_enc(x,z,isTrain=True,reuse = False, name = 'D_enc') :\n",
    "    \n",
    "    w_init = tf.truncated_normal_initializer(mean= 0.0, stddev=0.02)\n",
    "    b_init = tf.constant_initializer(0.0)\n",
    "    with tf.variable_scope('D_enc', reuse=reuse) :\n",
    "        \n",
    "        \n",
    "        z_flat = tf.reshape(z, (-1, z_size))\n",
    "        \n",
    "        w1 = tf.get_variable('w1',[z_flat.get_shape()[1], 64*64*2],initializer=w_init)\n",
    "        b1 = tf.get_variable('b1',[64*64*2],initializer=b_init)\n",
    "        fc1 = tf.nn.elu(tf.matmul(z_flat,w1) + b1)\n",
    "          \n",
    "        r0 = tf.reshape(fc1, (-1, 64,64,2)) # 64*64*2\n",
    "        \n",
    "        x_cat = tf.concat([x, r0],3)\n",
    "\n",
    "\n",
    "        conv1 = tf.layers.conv2d(x_cat,64,[5,5], strides=(2,2),padding = 'same',\n",
    "                                kernel_initializer=w_init, bias_initializer=b_init) \n",
    "        r1 = tf.nn.elu(conv1)#32*32*64\n",
    "\n",
    "   \n",
    "        conv2 = tf.layers.conv2d(r1,128,[5,5], strides=(2,2),padding = 'same',\n",
    "                                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r2 = tf.nn.elu(tf.layers.batch_normalization(conv2,training=isTrain))#16*16*128\n",
    "\n",
    "  \n",
    "        conv3 = tf.layers.conv2d(r2,256,[5,5], strides=(2,2),padding = 'same',\n",
    "                                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r3 = tf.nn.elu(tf.layers.batch_normalization(conv3,training=isTrain))#8*8*256\n",
    "        \n",
    "        conv4 = tf.layers.conv2d(r3,512,[5,5], strides=(2,2),padding = 'same',\n",
    "                                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        \n",
    "    r4 = tf.nn.elu(tf.layers.batch_normalization(conv4,training=isTrain), name = name)#4*4*512\n",
    "    return r4\n",
    "\n",
    "def D_dis(x,isTrain=True,reuse = False, name = 'D_dis') :\n",
    "    \n",
    "    w_init = tf.truncated_normal_initializer(mean= 0.0, stddev=0.02)\n",
    "    b_init = tf.constant_initializer(0.0)\n",
    "    with tf.variable_scope('D_dis', reuse=reuse) :\n",
    "        \n",
    "        conv5 = tf.layers.conv2d(x,1,[4,4], strides=(1,1),padding = 'valid',\n",
    "                                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "      \n",
    "    r5 = tf.nn.sigmoid(conv5,name=name)#1*1*1\n",
    "    \n",
    "    return r5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네트워크 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "z = tf.placeholder(tf.float32,shape=(None,1,1,z_size),name = 'z')    #x_z = G(z)\n",
    "u = tf.placeholder(tf.float32, shape = (None, 64,64,1),name='u')      #u = x\n",
    "\n",
    "isTrain = tf.placeholder(dtype=tf.bool,name='isTrain')  # BN 설정 parameter\n",
    "\n",
    "\n",
    "G_sample = G(z,isTrain,name='G_sample') # G(z)\n",
    "E_z = E(u,isTrain,name = 'E_z') \n",
    "\n",
    "re_image = G(E_z, isTrain, reuse=True, name ='re_image')\n",
    "\n",
    "D_real = D_dis(D_enc(u, E_z, isTrain,reuse=False), isTrain, reuse=False)                       # D(x)\n",
    "D_fake = D_dis(D_enc(G_sample,z, isTrain,reuse=True), isTrain, reuse=True)         # D(G(z))\n",
    "\n",
    "\n",
    "D_real_loss = tf.reduce_mean(-tf.log(D_real + 1e-8),name = 'D_real_loss')              # E[-log(D(x))] \n",
    "D_fake_loss = tf.reduce_mean(-tf.log(1 - D_fake + 1e-8),name = 'D_fake_loss')      # E[-log(1-D(G(z)))]\n",
    "\n",
    "D_loss =  tf.add(D_real_loss,D_fake_loss,name='D_loss')                                        #  E[-log(D(x))]  + E[-log(1-D(G(z)))]\n",
    "\n",
    "G_loss =  tf.reduce_mean(-tf.log(D_fake + 1e-8),name='G_loss')                             # E[-log(D(G(z)))]\n",
    "E_loss = tf.reduce_mean(-tf.log(1- D_real + 1e-8),name = 'E_loss')\n",
    "\n",
    "                                                                                                                                    \n",
    "\n",
    "T_vars = tf.trainable_variables()\n",
    "D_vars = [var for var in T_vars if var.name.startswith('D_dis') or var.name.startswith('D_enc')]\n",
    "G_vars = [var for var in T_vars if var.name.startswith('G')]\n",
    "E_vars = [var for var in T_vars if var.name.startswith('E')]\n",
    "    \n",
    "    # When using the batchnormalization layers,\n",
    "    # it is necessary to manually add the update operations\n",
    "    # because the moving averages are not included in the graph\n",
    "with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)) :        \n",
    "    D_optim = tf.train.AdamOptimizer(2e-5,beta1=0.5).minimize(D_loss, var_list=D_vars, name='D_optim') \n",
    "    G_optim = tf.train.AdamOptimizer(2e-4,beta1=0.5).minimize(G_loss, var_list=G_vars, name='G_optim')\n",
    "    E_optim = tf.train.AdamOptimizer(2e-4,beta1=0.5).minimize(E_loss, var_list=E_vars, name='E_optim')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D_e : 6.281991, D_real_e : 1.493023, D_fake_e : 4.788968, G_e : 0.025335, E_e : 2.401175\n",
      "D_e : 2.532134, D_real_e : 1.229916, D_fake_e : 1.302218, G_e : 0.416342, E_e : 0.618723\n",
      "D_e : 1.743876, D_real_e : 0.875501, D_fake_e : 0.868375, G_e : 0.564628, E_e : 0.574130\n",
      "D_e : 1.613057, D_real_e : 0.807455, D_fake_e : 0.805602, G_e : 0.617156, E_e : 0.618889\n",
      "D_e : 1.554811, D_real_e : 0.778829, D_fake_e : 0.775982, G_e : 0.641955, E_e : 0.640932\n",
      "D_e : 1.515449, D_real_e : 0.758829, D_fake_e : 0.756620, G_e : 0.668203, E_e : 0.657174\n",
      "D_e : 1.488659, D_real_e : 0.745475, D_fake_e : 0.743184, G_e : 0.684486, E_e : 0.668964\n",
      "D_e : 1.470762, D_real_e : 0.736804, D_fake_e : 0.733958, G_e : 0.699863, E_e : 0.677369\n",
      "D_e : 1.457375, D_real_e : 0.730431, D_fake_e : 0.726944, G_e : 0.705536, E_e : 0.685078\n",
      "D_e : 1.447963, D_real_e : 0.724709, D_fake_e : 0.723255, G_e : 0.710579, E_e : 0.690163\n",
      "D_e : 1.439575, D_real_e : 0.720982, D_fake_e : 0.718593, G_e : 0.719471, E_e : 0.694972\n",
      "D_e : 1.433219, D_real_e : 0.717772, D_fake_e : 0.715447, G_e : 0.723360, E_e : 0.699322\n",
      "D_e : 1.427870, D_real_e : 0.715110, D_fake_e : 0.712760, G_e : 0.719366, E_e : 0.699502\n",
      "D_e : 1.423923, D_real_e : 0.712869, D_fake_e : 0.711054, G_e : 0.719299, E_e : 0.700259\n",
      "D_e : 1.421921, D_real_e : 0.711438, D_fake_e : 0.710483, G_e : 0.726430, E_e : 0.704411\n",
      "D_e : 1.418608, D_real_e : 0.709866, D_fake_e : 0.708742, G_e : 0.731189, E_e : 0.706553\n",
      "D_e : 1.413814, D_real_e : 0.708048, D_fake_e : 0.705767, G_e : 0.727542, E_e : 0.708706\n",
      "D_e : 1.413380, D_real_e : 0.707333, D_fake_e : 0.706047, G_e : 0.731986, E_e : 0.708964\n",
      "D_e : 1.410998, D_real_e : 0.706119, D_fake_e : 0.704879, G_e : 0.730977, E_e : 0.711069\n",
      "D_e : 1.409569, D_real_e : 0.706006, D_fake_e : 0.703563, G_e : 0.736260, E_e : 0.713061\n",
      "D_e : 1.405480, D_real_e : 0.702815, D_fake_e : 0.702664, G_e : 0.729585, E_e : 0.712425\n",
      "D_e : 1.407505, D_real_e : 0.704353, D_fake_e : 0.703152, G_e : 0.734548, E_e : 0.713942\n",
      "D_e : 1.404270, D_real_e : 0.702454, D_fake_e : 0.701817, G_e : 0.721721, E_e : 0.709598\n",
      "D_e : 1.404966, D_real_e : 0.703349, D_fake_e : 0.701617, G_e : 0.735663, E_e : 0.714378\n",
      "D_e : 1.403407, D_real_e : 0.701808, D_fake_e : 0.701599, G_e : 0.733337, E_e : 0.715136\n",
      "D_e : 1.401206, D_real_e : 0.701255, D_fake_e : 0.699950, G_e : 0.731820, E_e : 0.714634\n",
      "D_e : 1.399201, D_real_e : 0.699905, D_fake_e : 0.699296, G_e : 0.730145, E_e : 0.716566\n",
      "D_e : 1.400364, D_real_e : 0.700557, D_fake_e : 0.699807, G_e : 0.727365, E_e : 0.713865\n",
      "D_e : 1.402609, D_real_e : 0.701490, D_fake_e : 0.701119, G_e : 0.725497, E_e : 0.712722\n",
      "D_e : 1.399880, D_real_e : 0.700719, D_fake_e : 0.699161, G_e : 0.729303, E_e : 0.714288\n",
      "D_e : 1.401895, D_real_e : 0.700984, D_fake_e : 0.700911, G_e : 0.722759, E_e : 0.711223\n",
      "D_e : 1.399498, D_real_e : 0.700095, D_fake_e : 0.699403, G_e : 0.725173, E_e : 0.711992\n",
      "D_e : 1.401572, D_real_e : 0.701072, D_fake_e : 0.700500, G_e : 0.727985, E_e : 0.711401\n",
      "D_e : 1.399709, D_real_e : 0.700079, D_fake_e : 0.699630, G_e : 0.726901, E_e : 0.713026\n",
      "D_e : 1.398625, D_real_e : 0.699858, D_fake_e : 0.698767, G_e : 0.726178, E_e : 0.710843\n",
      "D_e : 1.399167, D_real_e : 0.699204, D_fake_e : 0.699964, G_e : 0.721979, E_e : 0.711526\n",
      "D_e : 1.398822, D_real_e : 0.699893, D_fake_e : 0.698928, G_e : 0.724290, E_e : 0.710193\n",
      "D_e : 1.397704, D_real_e : 0.698828, D_fake_e : 0.698876, G_e : 0.722523, E_e : 0.710300\n",
      "D_e : 1.398452, D_real_e : 0.699104, D_fake_e : 0.699347, G_e : 0.723068, E_e : 0.710792\n",
      "D_e : 1.397591, D_real_e : 0.698927, D_fake_e : 0.698664, G_e : 0.723330, E_e : 0.710235\n",
      "D_e : 1.395447, D_real_e : 0.697616, D_fake_e : 0.697831, G_e : 0.722523, E_e : 0.709464\n",
      "D_e : 1.396463, D_real_e : 0.697722, D_fake_e : 0.698741, G_e : 0.723140, E_e : 0.709437\n",
      "D_e : 1.395019, D_real_e : 0.697894, D_fake_e : 0.697124, G_e : 0.726178, E_e : 0.711778\n",
      "D_e : 1.394666, D_real_e : 0.696636, D_fake_e : 0.698030, G_e : 0.725013, E_e : 0.711151\n",
      "D_e : 1.394674, D_real_e : 0.696931, D_fake_e : 0.697743, G_e : 0.726373, E_e : 0.711983\n",
      "D_e : 1.393711, D_real_e : 0.696382, D_fake_e : 0.697329, G_e : 0.721748, E_e : 0.710936\n",
      "D_e : 1.392800, D_real_e : 0.696083, D_fake_e : 0.696717, G_e : 0.720849, E_e : 0.710389\n",
      "D_e : 1.394079, D_real_e : 0.696757, D_fake_e : 0.697323, G_e : 0.723606, E_e : 0.710943\n",
      "D_e : 1.393052, D_real_e : 0.695671, D_fake_e : 0.697381, G_e : 0.724077, E_e : 0.712672\n",
      "D_e : 1.391300, D_real_e : 0.695169, D_fake_e : 0.696131, G_e : 0.729759, E_e : 0.714794\n",
      "total time :  3270.8661670684814\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f286c819588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))) as sess :\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    np.random.seed(int(time.time()))\n",
    "    tf.set_random_seed(int(time.time()))\n",
    "    \n",
    "    mnist_4by4_save(np.reshape(test_normal_data[0:16],(-1,64,64,1)),file_name + '/origin.png')    \n",
    "    test_z = np.random.uniform(-1,1,size=(16,1,1,z_size))\n",
    "\n",
    "    log_txt = open(file_name +'/log.txt','w')\n",
    "\n",
    "    hist_G = []\n",
    "    hist_D = []\n",
    "    G_error = []\n",
    "    D_error = []\n",
    "    E_error = []\n",
    "    D_fake_error = []\n",
    "    D_real_error = []\n",
    "    \n",
    "    start = time.time()\n",
    "    for epoch in range(train_epoch) :\n",
    "        \n",
    "        train_normal_data = idx_shuffle(train_normal_data) \n",
    "        \n",
    "        for iteration in range(train_normal_data.shape[0] // batch_size) : \n",
    "        \n",
    "            \n",
    "            train_images = train_normal_data[iteration*batch_size : (iteration+1)*batch_size]      \n",
    "            u_ = np.reshape(train_images,(-1,64,64,1)) \n",
    "            z_ = np.random.uniform(-1,1,size=(batch_size,1,1,z_size))\n",
    "            \n",
    "        \n",
    "            _ , D_e,D_real_e,D_fake_e = sess.run([D_optim, D_loss,D_real_loss,D_fake_loss], {u : u_, z : z_, isTrain : True})\n",
    "            D_error.append(D_e)\n",
    "            D_real_error.append(np.maximum(0.0, D_real_e))\n",
    "            D_fake_error.append(np.maximum(0.0,D_fake_e))\n",
    "\n",
    "            #    train_images,train_labels = mnist.train.next_batch(100)    \n",
    "            #    u_ = np.reshape(train_images,(-1,64,64,1)) \n",
    "            #    z_ = np.random.normal(0,1,size=(100,1,1,100))\n",
    "   \n",
    "            _ , G_e = sess.run([G_optim, G_loss], {u : u_, z : z_, isTrain : True}) \n",
    "            G_error.append(G_e)\n",
    "            _ , E_e = sess.run([E_optim, E_loss], {u : u_, z : z_, isTrain : True}) \n",
    "            E_error.append(E_e)\n",
    "        \n",
    "\n",
    "\n",
    "        hist_D.append(np.mean(D_error)) \n",
    "        hist_G.append(np.mean(G_error))\n",
    "\n",
    "        print('D_e : %.6f, D_real_e : %.6f, D_fake_e : %.6f, G_e : %.6f, E_e : %.6f'%(np.mean(D_error), np.mean(D_real_error),\n",
    "            np.mean(D_fake_error), np.mean(G_error),np.mean(E_error)))\n",
    "        log_txt.write('D_e : %.6f, D_real_e : %.6f, D_fake_e : %.6f, G_e : %.6f\\n'%(np.mean(D_error),\n",
    "            np.mean(D_real_error), np.mean(D_fake_error), np.mean(G_error)))\n",
    "      \n",
    "        r = sess.run([G_sample],feed_dict={z : test_z, isTrain : False})        \n",
    "        mnist_4by4_save(np.reshape(r,(-1,64,64,1)),file_name + '/result_{}.png'.format(str(epoch).zfill(3)))\n",
    "        re_image\n",
    "        \n",
    "        r = sess.run([re_image],feed_dict={u : test_normal_data[0:16],isTrain : False})        \n",
    "        mnist_4by4_save(np.reshape(r,(-1,64,64,1)),file_name + '/origin_{}.png'.format(str(epoch).zfill(3)))\n",
    "        np.random.seed(int(time.time()))\n",
    "\n",
    "\n",
    "        G_error = []\n",
    "        D_error = []\n",
    "        E_error = []\n",
    "        D_fake_error = []     \n",
    "        D_real_error = []\n",
    "\n",
    "\n",
    "    log_txt.close()\n",
    "    gan_loss_graph_save(G_loss = hist_G,D_loss=hist_D,path = file_name + '/loss_graph.png')   \n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess,file_name + '/para.cktp')\n",
    "\n",
    "    end = time.time()-start\n",
    "\n",
    "    print(\"total time : \",end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## network load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ex_Bi_DCGANs/para.cktp\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(file_name) :\n",
    "    os.mkdir(file_name)\n",
    "\n",
    "    \n",
    "sess = tf.InteractiveSession()\n",
    "    \n",
    "new_saver = tf.train.import_meta_graph(file_name + '/para.cktp.meta')\n",
    "new_saver.restore(sess, tf.train.latest_checkpoint(file_name + '/'))\n",
    "\n",
    "\n",
    "z = sess.graph.get_tensor_by_name(\"z:0\")\n",
    "u = sess.graph.get_tensor_by_name(\"u:0\")\n",
    "\n",
    "isTrain = sess.graph.get_tensor_by_name(\"isTrain:0\")\n",
    "\n",
    "G_sample = sess.graph.get_tensor_by_name(\"G_sample:0\")\n",
    "\n",
    "\n",
    "D_real_loss = sess.graph.get_tensor_by_name('D_real_loss:0')\n",
    "D_fake_loss = sess.graph.get_tensor_by_name('D_fake_loss:0')\n",
    "\n",
    "D_loss = sess.graph.get_tensor_by_name(\"D_loss:0\")\n",
    "G_loss = sess.graph.get_tensor_by_name(\"G_loss:0\")\n",
    "\n",
    "\n",
    "D_optim = sess.graph.get_operation_by_name(\"D_optim\")\n",
    "G_optim = sess.graph.get_operation_by_name(\"G_optim\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8192"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "64*64*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "321px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
