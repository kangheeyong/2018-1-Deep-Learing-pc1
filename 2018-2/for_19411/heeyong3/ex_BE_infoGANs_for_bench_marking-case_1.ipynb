{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": [
     17,
     21,
     25,
     29,
     33,
     44
    ]
   },
   "source": [
    "# Boundary Equilibrimum infoGANs for Fault Detection example\n",
    "\n",
    "## 초기 설정들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     17,
     21,
     25,
     33,
     44,
     63
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_normal_data :  (8991, 64, 64, 1)\n",
      "test_anomalous_data :  (1009, 64, 64, 1)\n",
      "train_normal_data :  (49546, 64, 64, 1)\n",
      "train_anomalous_data :  (5454, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec \n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "file_dir = 'anoGANs_MNIST_data/'\n",
    "\n",
    "with gzip.open(file_dir + 'test_normal_data_inc_9.pickle.gzip','rb') as f :\n",
    "    test_normal_data = pickle.load(f)\n",
    "    print('test_normal_data : ' ,test_normal_data.shape)\n",
    "\n",
    "with gzip.open(file_dir + 'test_anomalous_data_inc_9.pickle.gzip','rb') as f :\n",
    "    test_anomalous_data = pickle.load(f)\n",
    "    print('test_anomalous_data : ',test_anomalous_data.shape)\n",
    "    \n",
    "with gzip.open(file_dir + 'train_normal_data_inc_9.pickle.gzip','rb') as f :\n",
    "    train_normal_data = pickle.load(f)\n",
    "    print('train_normal_data : ', train_normal_data.shape)\n",
    "    \n",
    "with gzip.open(file_dir + 'train_anomalous_data_inc_9.pickle.gzip','rb') as f :\n",
    "    train_anomalous_data = pickle.load(f)\n",
    "    print('train_anomalous_data : ',train_anomalous_data.shape )\n",
    "\n",
    "def idx_shuffle(x) : \n",
    "    l = x.shape[0]\n",
    "    idx = np.arange(l)\n",
    "    np.random.shuffle(idx)\n",
    "    shuffled_x = np.empty(x.shape)\n",
    "\n",
    "    for i in range(l):\n",
    "        shuffled_x[idx[i]] = x[i]\n",
    "    \n",
    "    return shuffled_x\n",
    "\n",
    "def mnist_4by4_save(samples,path):\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    gs = gridspec.GridSpec(4, 4)    \n",
    "    gs.update(wspace=0.05, hspace=0.05) #이미지 사이간격 조절\n",
    "  \n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')    \n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "   \n",
    "        plt.imshow(sample.reshape(64, 64), cmap='Greys_r',clim=(0.0,1.0))\n",
    "    plt.colorbar()\n",
    "    plt.savefig(path, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "   \n",
    "    return None\n",
    "\n",
    "def gan_loss_graph_save(G_loss,D_loss,path):\n",
    "    x1 = range(len(G_loss))\n",
    "    x2 = range(len(D_loss))\n",
    "      \n",
    "    y1 = G_loss\n",
    "    y2 = D_loss\n",
    "  \n",
    "      \n",
    "    plt.plot(x1,y1,label='G_loss') \n",
    "    plt.plot(x2,y2,label='D_loss') \n",
    "  \n",
    "    plt.xlabel('weight per update')\n",
    "    plt.ylabel('loss')             \n",
    "    plt.legend(loc=4)              \n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "  \n",
    "    plt.savefig(path)              \n",
    "\n",
    "    return None\n",
    "\n",
    "file_name = 'ex_BE_infoGANs_for_bench_marking_case_1'\n",
    "\n",
    "if not os.path.isdir(file_name) :\n",
    "    os.mkdir(file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네트워크 정의\n",
    "\n",
    "D부분을 encoder와 discriminator로 나눈 이유는 encoder를 나중에 feature map으로 쓰기 위해서 편의상 나누어서 정의함\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     123
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_epoch = 100\n",
    "batch_size = 100\n",
    "z_size = 100\n",
    "lam = 0.01\n",
    "gamma = 0.7\n",
    "k_curr = 0.0\n",
    "c_size = 10\n",
    "\n",
    "\n",
    "def G(x,c,isTrain = True, reuse = False, name = 'G') : #input = (minibatch * w * h * ch)\n",
    "    \n",
    "    # out size = (in size + 2*padding - kenel)/strides + 1    \n",
    "    w_init = tf.truncated_normal_initializer(mean= 0.0, stddev=0.02)\n",
    "    b_init = tf.constant_initializer(0.0)\n",
    "\n",
    "    with tf.variable_scope('G',reuse=reuse)  :\n",
    "        \n",
    "        #x = (-1, 1, 1, 100)\n",
    "        x_concat = tf.concat([x,c],3)\n",
    "        conv1 = tf.layers.conv2d_transpose(x_concat,512,[4,4], strides=(1,1),padding = 'valid',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init) \n",
    "        r1 = tf.nn.elu(tf.layers.batch_normalization(conv1,training=isTrain))#4*4*512\n",
    "        \n",
    "        conv2 = tf.layers.conv2d_transpose(r1,256,[5,5], strides=(2,2),padding = 'same',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r2 = tf.nn.elu(tf.layers.batch_normalization(conv2,training=isTrain))#8*8*256\n",
    "                \n",
    "        conv3 = tf.layers.conv2d_transpose(r2,128,[5,5], strides=(2,2),padding = 'same',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r3 = tf.nn.elu(tf.layers.batch_normalization(conv3,training=isTrain))#16*16*128\n",
    "\n",
    "        conv4 = tf.layers.conv2d_transpose(r3,64,[5,5], strides=(2,2),padding = 'same',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r4 = tf.nn.elu(tf.layers.batch_normalization(conv4,training=isTrain))#32*32*64\n",
    "\n",
    "        conv5 = tf.layers.conv2d_transpose(r4,1,[5,5], strides=(2,2),padding = 'same',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init) #64*64*1\n",
    "        \n",
    "    r5= tf.nn.tanh(conv5,name=name)#64*64*1\n",
    "  \n",
    "    return r5\n",
    "\n",
    "def E(x,isTrain = True, reuse = False, name = 'E') : #input = (minibatch * w * h * ch)\n",
    "    \n",
    "    # out size = (in size + 2*padding - kenel)/strides + 1    \n",
    "    w_init = tf.truncated_normal_initializer(mean= 0.0, stddev=0.02)\n",
    "    b_init = tf.constant_initializer(0.0)\n",
    "\n",
    "    with tf.variable_scope('E',reuse=reuse)  :\n",
    "        \n",
    "        #x = (-1, 64, 64, 1)\n",
    "\n",
    "        conv1 = tf.layers.conv2d(x,64,[5,5], strides=(2,2),padding = 'same',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init) \n",
    "        r1 = tf.nn.elu(conv1)#32*32*64\n",
    "        \n",
    "        conv2 = tf.layers.conv2d(r1,128,[5,5], strides=(2,2),padding = 'same',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r2 = tf.nn.elu(tf.layers.batch_normalization(conv2,training=isTrain))#16*16*128\n",
    "                \n",
    "        conv3 = tf.layers.conv2d(r2,256,[5,5], strides=(2,2),padding = 'same',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r3 = tf.nn.elu(tf.layers.batch_normalization(conv3,training=isTrain))#8*8*256\n",
    "\n",
    "        conv4 = tf.layers.conv2d(r3,512,[5,5], strides=(2,2),padding = 'same',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r4 = tf.nn.elu(tf.layers.batch_normalization(conv4,training=isTrain))#4*4*512\n",
    "\n",
    "        conv5 = tf.layers.conv2d(r4,100,[4,4], strides=(1,1),padding = 'valid',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init) #1*1*100\n",
    "        \n",
    "        #\n",
    "        \n",
    "        fc0  = tf.reshape(conv4, (-1, 4*4*512))\n",
    "        \n",
    "        w1 = tf.get_variable('w1',[4*4*512, c_size],initializer=w_init)\n",
    "        b1 = tf.get_variable('b1',[c_size],initializer=b_init)\n",
    "        \n",
    "                                          \n",
    "        fc1 = tf.nn.softmax(tf.matmul(fc0,w1) + b1, name = name)\n",
    "        \n",
    "        \n",
    "    r5 = tf.nn.tanh(tf.layers.batch_normalization(conv5,training=isTrain), name = name)#4*4*512\n",
    "  \n",
    "  \n",
    "    return r5, tf.reshape(fc1,(-1,1,1,c_size))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def D_enc(x,isTrain=True,reuse = False, name = 'D_enc') :\n",
    "    \n",
    "    w_init = tf.truncated_normal_initializer(mean= 0.0, stddev=0.02)\n",
    "    b_init = tf.constant_initializer(0.0)\n",
    "    with tf.variable_scope('D_enc', reuse=reuse) :\n",
    "        \n",
    "        #x = (-1,64,64,1)\n",
    "        # out size = (in size + 2*padding - kenel)/strides + 1   \n",
    "\n",
    "        conv1 = tf.layers.conv2d(x,64,[5,5], strides=(2,2),padding = 'same',\n",
    "                                kernel_initializer=w_init, bias_initializer=b_init) \n",
    "        r1 = tf.nn.elu(conv1)#32*32*64\n",
    "\n",
    "   \n",
    "        conv2 = tf.layers.conv2d(r1,128,[5,5], strides=(2,2),padding = 'same',\n",
    "                                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r2 = tf.nn.elu(tf.layers.batch_normalization(conv2,training=isTrain))#16*16*128\n",
    "\n",
    "  \n",
    "        conv3 = tf.layers.conv2d(r2,256,[5,5], strides=(2,2),padding = 'same',\n",
    "                                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r3 = tf.nn.elu(tf.layers.batch_normalization(conv3,training=isTrain))#8*8*256\n",
    "        \n",
    "        conv4 = tf.layers.conv2d(r3,512,[5,5], strides=(2,2),padding = 'same',\n",
    "                                kernel_initializer=w_init, bias_initializer=b_init)    \n",
    "        r4 = tf.nn.elu(tf.layers.batch_normalization(conv4,training=isTrain), name = name)#4*4*512\n",
    "        \n",
    "        conv5 = tf.layers.conv2d(r4,100,[4,4], strides=(1,1),padding = 'valid',\n",
    "                                kernel_initializer=w_init, bias_initializer=b_init)    \n",
    "        r5 = tf.layers.batch_normalization(conv5,training=isTrain)\n",
    "    return tf.add(r5,0,name=name)\n",
    "\n",
    "def D_dec(x,isTrain=True,reuse = False, name = 'D_dec') :\n",
    "    \n",
    "    w_init = tf.truncated_normal_initializer(mean= 0.0, stddev=0.02)\n",
    "    b_init = tf.constant_initializer(0.0)\n",
    "    with tf.variable_scope('D_dec', reuse=reuse) :\n",
    "        \n",
    "        #x = (-1,64,64,1)\n",
    "        # out size = (in size + 2*padding - kenel)/strides + 1   \n",
    "        # 256*16*16\n",
    "        # 128*32*32\n",
    "        # 1*64*64\n",
    "        conv6 = tf.layers.conv2d_transpose(x,512,[4,4], strides=(1,1),padding = 'valid',\n",
    "                                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r6 = tf.nn.elu(tf.layers.batch_normalization(conv6,training=isTrain))#4*4*256\n",
    "        \n",
    "        conv7 = tf.layers.conv2d_transpose(r6,256,[5,5], strides=(2,2),padding = 'same',\n",
    "                                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r7 = tf.nn.elu(tf.layers.batch_normalization(conv7,training=isTrain))#8*8*256\n",
    "\n",
    "\n",
    "        conv8 = tf.layers.conv2d_transpose(r7,128,[5,5], strides=(2,2),padding = 'same',\n",
    "                                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r8 = tf.nn.elu(tf.layers.batch_normalization(conv8,training=isTrain))#16*16*128\n",
    "             \n",
    "        conv9 = tf.layers.conv2d_transpose(r8,64,[5,5], strides=(2,2),padding = 'same',\n",
    "                                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r9 = tf.nn.elu(tf.layers.batch_normalization(conv9,training=isTrain))#32*32*64\n",
    "          \n",
    "        conv10 = tf.layers.conv2d_transpose(r9,1,[5,5], strides=(2,2),padding = 'same',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init) #64*64*1\n",
    "        \n",
    "    r10= tf.nn.tanh(conv10,name=name)#64*64*1\n",
    "    \n",
    "    return r10\n",
    "def Q_cat(x,reuse = False, name = 'Q_cat') :\n",
    "    \n",
    "    w_init = tf.truncated_normal_initializer(mean= 0.0, stddev=0.02)\n",
    "    b_init = tf.constant_initializer(0.0)\n",
    "    with tf.variable_scope('Q_cat', reuse=reuse) :\n",
    "        \n",
    "        #x = (-1,64,64,1)\n",
    "        # out size = (in size + 2*padding - kenel)/strides + 1   \n",
    "        fc0  = tf.reshape(x, (-1, 100))\n",
    "        \n",
    "        w1 = tf.get_variable('w1',[100, c_size],initializer=w_init)\n",
    "        b1 = tf.get_variable('b1',[c_size],initializer=b_init)\n",
    "        \n",
    "                                          \n",
    "    fc1 = tf.nn.softmax(tf.matmul(fc0,w1) + b1, name = name)\n",
    "    \n",
    "    return tf.reshape(fc1, (-1,1,1,c_size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네트워크 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "z = tf.placeholder(tf.float32,shape=(None,1,1,z_size),name = 'z')    #x_z = G(z)\n",
    "c = tf.placeholder(tf.float32,shape=(None,1,1,c_size),name = 'c')    #x_z = G(z,c)\n",
    "\n",
    "u = tf.placeholder(tf.float32, shape = (None, 64,64,1),name='u')      #u = x\n",
    "k = tf.placeholder(tf.float32, name = 'k')\n",
    "\n",
    "\n",
    "isTrain = tf.placeholder(dtype=tf.bool,name='isTrain')  # BN 설정 parameter\n",
    "\n",
    "\n",
    "G_sample = G(z,c,name='G_sample') # G(z)\n",
    "E_z, E_c = E(u,isTrain,name = 'E_z') \n",
    "\n",
    "re_image = G(E_z,E_c, isTrain, reuse=True, name ='re_image')\n",
    "re_z, re_c = E(G_sample, isTrain, reuse=True, name ='re_z')\n",
    "\n",
    "\n",
    "\n",
    "re_z_loss = tf.reduce_mean(tf.sqrt(tf.reduce_sum((re_z - z)**2, axis=[1,2,3])) , name = 're_z_loss') \n",
    "re_c_loss = tf.reduce_mean(tf.reduce_sum(-c*tf.log(re_c + 1e-8), axis = [1,2,3]),name = 're_c_loss')\n",
    "re_image_loss = tf.reduce_mean(tf.sqrt(tf.reduce_sum((re_image - u)**2, axis=[1,2,3])) , name = 're_image_loss') \n",
    "\n",
    "\n",
    "E_loss = tf.add(re_z_loss, re_c_loss, name = 'E_loss')                       \n",
    "\n",
    "\n",
    "D_real = D_dec(D_enc(u, isTrain,reuse=False), isTrain, reuse=False, name = 'D_real')                       # D(x)\n",
    "D_fake = D_dec(D_enc(G_sample, isTrain,reuse=True), isTrain, reuse=True, name = 'D_fake')         # D(G(z))\n",
    "Q_fake = Q_cat(D_enc(G_sample, isTrain,reuse=True), reuse=False, name='Q_fake')\n",
    "\n",
    "#input = (minibatch * w * h * ch)\n",
    "D_real_loss = tf.reduce_mean(tf.sqrt(tf.reduce_sum((D_real-u)**2, axis=[1,2,3])) , name = 'D_real_loss')             \n",
    "\n",
    "D_fake_loss = tf.reduce_mean(tf.sqrt(tf.reduce_sum((D_fake - G_sample)**2, axis=[1,2,3])),  name = 'D_fake_loss' )\n",
    "\n",
    "D_loss =  tf.add(D_real_loss, -k*D_fake_loss, name='D_loss')                                        \n",
    "\n",
    "G_loss =  tf.reduce_mean(tf.sqrt(tf.reduce_sum((D_fake - G_sample)**2, axis=[1,2,3])), name='G_loss')                             # E[-log(D(G(z)))]\n",
    "Q_loss = tf.reduce_mean(tf.reduce_sum(-c*tf.log(Q_fake + 1e-8), axis = [1,2,3]),name = 'Q_loss')\n",
    "\n",
    "                                                                                                                                \n",
    "T_vars = tf.trainable_variables()\n",
    "D_vars = [var for var in T_vars if var.name.startswith('D_dec') or var.name.startswith('D_enc')]\n",
    "G_vars = [var for var in T_vars if var.name.startswith('G')]\n",
    "E_vars = [var for var in T_vars if var.name.startswith('E')]\n",
    "Q_vars = [var for var in T_vars if var.name.startswith('Q')]\n",
    "\n",
    "    # When using the batchnormalization layers,\n",
    "    # it is necessary to manually add the update operations\n",
    "    # because the moving averages are not included in the graph\n",
    "with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)) :        \n",
    "    D_optim = tf.train.AdamOptimizer(2e-5,beta1=0.5).minimize(D_loss, var_list=D_vars, name='D_optim') \n",
    "    G_optim = tf.train.AdamOptimizer(2e-4,beta1=0.5).minimize(G_loss + Q_loss, var_list=G_vars+Q_vars, name='G_optim')\n",
    "    E_optim = tf.train.AdamOptimizer(2e-4,beta1=0.1).minimize(E_loss, var_list=E_vars, name='E_optim')\n",
    "    E_AE_optim = tf.train.AdamOptimizer(2e-4,beta1=0.1).minimize(re_image_loss, var_list=E_vars, name='E_AE_optim')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D_e : -111.532, D_real_e : 50.048, D_fake_e : 34.651, G_e : 34.993, Q_e : 2.102, new_measure : 60.172, k_curr : 0.201636\n",
      "D_e : 24.997, D_real_e : 35.123, D_fake_e : 24.019, G_e : 24.606, Q_e : 2.014, new_measure : 36.438, k_curr : 0.099806\n",
      "D_e : 22.963, D_real_e : 28.007, D_fake_e : 19.214, G_e : 19.563, Q_e : 1.715, new_measure : 29.442, k_curr : 0.307589\n",
      "D_e : 20.276, D_real_e : 22.606, D_fake_e : 15.695, G_e : 15.857, Q_e : 1.414, new_measure : 23.974, k_curr : 0.146709\n",
      "D_e : 17.419, D_real_e : 18.386, D_fake_e : 12.742, G_e : 12.894, Q_e : 1.183, new_measure : 19.853, k_curr : 0.031493\n",
      "D_e : 14.406, D_real_e : 14.770, D_fake_e : 10.250, G_e : 10.346, Q_e : 1.013, new_measure : 15.936, k_curr : -0.002301\n",
      "D_e : 12.033, D_real_e : 12.594, D_fake_e : 8.707, G_e : 8.809, Q_e : 0.883, new_measure : 13.576, k_curr : 0.032215\n",
      "D_e : 10.255, D_real_e : 10.622, D_fake_e : 7.381, G_e : 7.452, Q_e : 0.785, new_measure : 11.264, k_curr : -0.047228\n",
      "D_e : 8.976, D_real_e : 9.317, D_fake_e : 6.427, G_e : 6.504, Q_e : 0.705, new_measure : 9.827, k_curr : 0.040545\n",
      "D_e : 7.632, D_real_e : 8.006, D_fake_e : 5.513, G_e : 5.600, Q_e : 0.640, new_measure : 8.299, k_curr : 0.061966\n",
      "D_e : 6.620, D_real_e : 6.916, D_fake_e : 4.749, G_e : 4.839, Q_e : 0.585, new_measure : 7.157, k_curr : 0.072463\n",
      "D_e : 6.217, D_real_e : 6.480, D_fake_e : 4.451, G_e : 4.539, Q_e : 0.540, new_measure : 6.720, k_curr : 0.055324\n",
      "D_e : 5.939, D_real_e : 6.187, D_fake_e : 4.241, G_e : 4.329, Q_e : 0.500, new_measure : 6.418, k_curr : 0.062539\n",
      "D_e : 5.733, D_real_e : 5.965, D_fake_e : 4.093, G_e : 4.179, Q_e : 0.466, new_measure : 6.189, k_curr : 0.044621\n",
      "D_e : 5.560, D_real_e : 5.785, D_fake_e : 3.962, G_e : 4.048, Q_e : 0.436, new_measure : 5.991, k_curr : 0.052789\n",
      "D_e : 5.414, D_real_e : 5.640, D_fake_e : 3.859, G_e : 3.949, Q_e : 0.410, new_measure : 5.857, k_curr : 0.050547\n",
      "D_e : 5.280, D_real_e : 5.514, D_fake_e : 3.770, G_e : 3.859, Q_e : 0.386, new_measure : 5.713, k_curr : 0.054497\n",
      "D_e : 5.167, D_real_e : 5.412, D_fake_e : 3.694, G_e : 3.784, Q_e : 0.365, new_measure : 5.600, k_curr : 0.073963\n",
      "D_e : 5.061, D_real_e : 5.301, D_fake_e : 3.619, G_e : 3.712, Q_e : 0.347, new_measure : 5.482, k_curr : 0.067107\n",
      "D_e : 4.966, D_real_e : 5.203, D_fake_e : 3.556, G_e : 3.645, Q_e : 0.330, new_measure : 5.402, k_curr : 0.051326\n",
      "D_e : 4.883, D_real_e : 5.125, D_fake_e : 3.495, G_e : 3.583, Q_e : 0.315, new_measure : 5.319, k_curr : 0.072995\n",
      "D_e : 4.785, D_real_e : 5.063, D_fake_e : 3.444, G_e : 3.541, Q_e : 0.301, new_measure : 5.235, k_curr : 0.091357\n",
      "D_e : 4.725, D_real_e : 5.002, D_fake_e : 3.399, G_e : 3.502, Q_e : 0.288, new_measure : 5.180, k_curr : 0.088117\n",
      "D_e : 4.671, D_real_e : 4.939, D_fake_e : 3.356, G_e : 3.457, Q_e : 0.276, new_measure : 5.104, k_curr : 0.090521\n",
      "D_e : 4.595, D_real_e : 4.879, D_fake_e : 3.313, G_e : 3.412, Q_e : 0.265, new_measure : 5.038, k_curr : 0.106205\n",
      "D_e : 4.548, D_real_e : 4.825, D_fake_e : 3.288, G_e : 3.379, Q_e : 0.255, new_measure : 4.989, k_curr : 0.099753\n",
      "D_e : 4.499, D_real_e : 4.783, D_fake_e : 3.250, G_e : 3.348, Q_e : 0.246, new_measure : 4.946, k_curr : 0.102530\n",
      "D_e : 4.432, D_real_e : 4.723, D_fake_e : 3.213, G_e : 3.310, Q_e : 0.237, new_measure : 4.877, k_curr : 0.083937\n",
      "D_e : 4.418, D_real_e : 4.687, D_fake_e : 3.186, G_e : 3.282, Q_e : 0.229, new_measure : 4.847, k_curr : 0.080005\n",
      "D_e : 4.398, D_real_e : 4.652, D_fake_e : 3.164, G_e : 3.255, Q_e : 0.222, new_measure : 4.813, k_curr : 0.086750\n",
      "D_e : 4.346, D_real_e : 4.599, D_fake_e : 3.131, G_e : 3.222, Q_e : 0.215, new_measure : 4.757, k_curr : 0.076248\n",
      "D_e : 4.285, D_real_e : 4.561, D_fake_e : 3.090, G_e : 3.189, Q_e : 0.208, new_measure : 4.709, k_curr : 0.094026\n",
      "D_e : 4.269, D_real_e : 4.538, D_fake_e : 3.082, G_e : 3.178, Q_e : 0.202, new_measure : 4.688, k_curr : 0.087095\n",
      "D_e : 4.254, D_real_e : 4.494, D_fake_e : 3.053, G_e : 3.148, Q_e : 0.197, new_measure : 4.642, k_curr : 0.078889\n",
      "D_e : 4.212, D_real_e : 4.461, D_fake_e : 3.021, G_e : 3.121, Q_e : 0.191, new_measure : 4.615, k_curr : 0.088443\n",
      "D_e : 4.170, D_real_e : 4.432, D_fake_e : 3.011, G_e : 3.098, Q_e : 0.186, new_measure : 4.585, k_curr : 0.108020\n",
      "D_e : 4.154, D_real_e : 4.405, D_fake_e : 2.992, G_e : 3.088, Q_e : 0.181, new_measure : 4.552, k_curr : 0.083830\n",
      "D_e : 4.123, D_real_e : 4.389, D_fake_e : 2.974, G_e : 3.073, Q_e : 0.176, new_measure : 4.539, k_curr : 0.078963\n",
      "D_e : 4.080, D_real_e : 4.353, D_fake_e : 2.956, G_e : 3.046, Q_e : 0.172, new_measure : 4.500, k_curr : 0.083540\n",
      "D_e : 4.075, D_real_e : 4.315, D_fake_e : 2.930, G_e : 3.023, Q_e : 0.168, new_measure : 4.472, k_curr : 0.072806\n",
      "D_e : 4.040, D_real_e : 4.291, D_fake_e : 2.916, G_e : 3.003, Q_e : 0.164, new_measure : 4.437, k_curr : 0.073705\n",
      "D_e : 4.020, D_real_e : 4.282, D_fake_e : 2.902, G_e : 2.993, Q_e : 0.160, new_measure : 4.433, k_curr : 0.098010\n",
      "D_e : 3.991, D_real_e : 4.264, D_fake_e : 2.887, G_e : 2.984, Q_e : 0.156, new_measure : 4.410, k_curr : 0.100943\n",
      "D_e : 3.971, D_real_e : 4.229, D_fake_e : 2.869, G_e : 2.963, Q_e : 0.153, new_measure : 4.383, k_curr : 0.089344\n",
      "D_e : 3.946, D_real_e : 4.190, D_fake_e : 2.848, G_e : 2.931, Q_e : 0.150, new_measure : 4.332, k_curr : 0.098347\n",
      "D_e : 3.917, D_real_e : 4.177, D_fake_e : 2.841, G_e : 2.928, Q_e : 0.146, new_measure : 4.320, k_curr : 0.077669\n",
      "D_e : 3.910, D_real_e : 4.161, D_fake_e : 2.834, G_e : 2.915, Q_e : 0.143, new_measure : 4.293, k_curr : 0.068946\n",
      "D_e : 3.895, D_real_e : 4.137, D_fake_e : 2.807, G_e : 2.892, Q_e : 0.140, new_measure : 4.280, k_curr : 0.090330\n",
      "D_e : 3.875, D_real_e : 4.121, D_fake_e : 2.796, G_e : 2.884, Q_e : 0.138, new_measure : 4.255, k_curr : 0.095063\n",
      "D_e : 3.834, D_real_e : 4.092, D_fake_e : 2.782, G_e : 2.865, Q_e : 0.135, new_measure : 4.215, k_curr : 0.091620\n",
      "D_e : 3.837, D_real_e : 4.084, D_fake_e : 2.773, G_e : 2.859, Q_e : 0.132, new_measure : 4.222, k_curr : 0.091922\n",
      "D_e : 3.823, D_real_e : 4.060, D_fake_e : 2.760, G_e : 2.841, Q_e : 0.130, new_measure : 4.195, k_curr : 0.099260\n",
      "D_e : 3.807, D_real_e : 4.033, D_fake_e : 2.746, G_e : 2.824, Q_e : 0.127, new_measure : 4.165, k_curr : 0.093018\n",
      "D_e : 3.794, D_real_e : 4.022, D_fake_e : 2.738, G_e : 2.820, Q_e : 0.125, new_measure : 4.167, k_curr : 0.073553\n",
      "D_e : 3.766, D_real_e : 4.002, D_fake_e : 2.722, G_e : 2.798, Q_e : 0.123, new_measure : 4.129, k_curr : 0.089459\n",
      "D_e : 3.753, D_real_e : 3.980, D_fake_e : 2.712, G_e : 2.790, Q_e : 0.121, new_measure : 4.101, k_curr : 0.071532\n",
      "D_e : 3.742, D_real_e : 3.956, D_fake_e : 2.693, G_e : 2.767, Q_e : 0.119, new_measure : 4.081, k_curr : 0.085105\n",
      "D_e : 3.729, D_real_e : 3.949, D_fake_e : 2.687, G_e : 2.764, Q_e : 0.117, new_measure : 4.073, k_curr : 0.088881\n",
      "D_e : 3.725, D_real_e : 3.929, D_fake_e : 2.677, G_e : 2.749, Q_e : 0.115, new_measure : 4.060, k_curr : 0.092784\n",
      "D_e : 3.699, D_real_e : 3.908, D_fake_e : 2.668, G_e : 2.738, Q_e : 0.113, new_measure : 4.032, k_curr : 0.078251\n",
      "D_e : 3.668, D_real_e : 3.877, D_fake_e : 2.643, G_e : 2.712, Q_e : 0.111, new_measure : 4.003, k_curr : 0.084758\n",
      "D_e : 3.662, D_real_e : 3.876, D_fake_e : 2.644, G_e : 2.718, Q_e : 0.109, new_measure : 4.011, k_curr : 0.062774\n",
      "D_e : 3.653, D_real_e : 3.855, D_fake_e : 2.622, G_e : 2.694, Q_e : 0.108, new_measure : 3.981, k_curr : 0.085835\n",
      "D_e : 3.645, D_real_e : 3.841, D_fake_e : 2.617, G_e : 2.689, Q_e : 0.106, new_measure : 3.968, k_curr : 0.085967\n",
      "D_e : 3.626, D_real_e : 3.823, D_fake_e : 2.598, G_e : 2.675, Q_e : 0.104, new_measure : 3.960, k_curr : 0.091878\n",
      "D_e : 3.603, D_real_e : 3.806, D_fake_e : 2.603, G_e : 2.669, Q_e : 0.103, new_measure : 3.931, k_curr : 0.070945\n",
      "D_e : 3.615, D_real_e : 3.799, D_fake_e : 2.591, G_e : 2.660, Q_e : 0.101, new_measure : 3.929, k_curr : 0.068671\n",
      "D_e : 3.590, D_real_e : 3.782, D_fake_e : 2.577, G_e : 2.645, Q_e : 0.100, new_measure : 3.903, k_curr : 0.081555\n",
      "D_e : 3.576, D_real_e : 3.762, D_fake_e : 2.568, G_e : 2.633, Q_e : 0.098, new_measure : 3.884, k_curr : 0.087009\n",
      "D_e : 3.566, D_real_e : 3.750, D_fake_e : 2.562, G_e : 2.627, Q_e : 0.097, new_measure : 3.875, k_curr : 0.079675\n",
      "D_e : 3.540, D_real_e : 3.720, D_fake_e : 2.538, G_e : 2.604, Q_e : 0.096, new_measure : 3.835, k_curr : 0.080933\n",
      "D_e : 3.514, D_real_e : 3.709, D_fake_e : 2.528, G_e : 2.593, Q_e : 0.094, new_measure : 3.828, k_curr : 0.097669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D_e : 3.500, D_real_e : 3.707, D_fake_e : 2.534, G_e : 2.599, Q_e : 0.093, new_measure : 3.829, k_curr : 0.080210\n",
      "D_e : 3.497, D_real_e : 3.698, D_fake_e : 2.526, G_e : 2.588, Q_e : 0.092, new_measure : 3.811, k_curr : 0.083281\n",
      "D_e : 3.492, D_real_e : 3.677, D_fake_e : 2.513, G_e : 2.575, Q_e : 0.091, new_measure : 3.791, k_curr : 0.079694\n",
      "D_e : 3.490, D_real_e : 3.670, D_fake_e : 2.504, G_e : 2.569, Q_e : 0.089, new_measure : 3.791, k_curr : 0.079216\n",
      "D_e : 3.476, D_real_e : 3.634, D_fake_e : 2.494, G_e : 2.548, Q_e : 0.087, new_measure : 3.749, k_curr : 0.055620\n",
      "D_e : 3.481, D_real_e : 3.625, D_fake_e : 2.484, G_e : 2.536, Q_e : 0.086, new_measure : 3.735, k_curr : 0.063503\n",
      "D_e : 3.449, D_real_e : 3.602, D_fake_e : 2.472, G_e : 2.522, Q_e : 0.085, new_measure : 3.718, k_curr : 0.058427\n",
      "D_e : 3.428, D_real_e : 3.593, D_fake_e : 2.458, G_e : 2.516, Q_e : 0.084, new_measure : 3.700, k_curr : 0.056522\n",
      "D_e : 3.425, D_real_e : 3.597, D_fake_e : 2.455, G_e : 2.512, Q_e : 0.083, new_measure : 3.711, k_curr : 0.084379\n",
      "D_e : 3.421, D_real_e : 3.584, D_fake_e : 2.460, G_e : 2.516, Q_e : 0.082, new_measure : 3.698, k_curr : 0.049583\n",
      "D_e : 3.399, D_real_e : 3.547, D_fake_e : 2.429, G_e : 2.480, Q_e : 0.081, new_measure : 3.653, k_curr : 0.065422\n",
      "D_e : 3.406, D_real_e : 3.544, D_fake_e : 2.430, G_e : 2.482, Q_e : 0.080, new_measure : 3.653, k_curr : 0.060230\n",
      "D_e : 3.396, D_real_e : 3.530, D_fake_e : 2.421, G_e : 2.472, Q_e : 0.079, new_measure : 3.643, k_curr : 0.058972\n",
      "D_e : 3.384, D_real_e : 3.531, D_fake_e : 2.416, G_e : 2.469, Q_e : 0.078, new_measure : 3.643, k_curr : 0.072698\n",
      "D_e : 3.348, D_real_e : 3.516, D_fake_e : 2.406, G_e : 2.463, Q_e : 0.077, new_measure : 3.625, k_curr : 0.066793\n",
      "D_e : 3.341, D_real_e : 3.502, D_fake_e : 2.399, G_e : 2.454, Q_e : 0.077, new_measure : 3.609, k_curr : 0.055268\n",
      "D_e : 3.344, D_real_e : 3.500, D_fake_e : 2.395, G_e : 2.449, Q_e : 0.076, new_measure : 3.606, k_curr : 0.058998\n",
      "D_e : 3.335, D_real_e : 3.490, D_fake_e : 2.391, G_e : 2.441, Q_e : 0.075, new_measure : 3.596, k_curr : 0.068951\n",
      "D_e : 3.324, D_real_e : 3.468, D_fake_e : 2.380, G_e : 2.429, Q_e : 0.074, new_measure : 3.578, k_curr : 0.058331\n",
      "D_e : 3.303, D_real_e : 3.458, D_fake_e : 2.370, G_e : 2.419, Q_e : 0.073, new_measure : 3.558, k_curr : 0.068928\n",
      "D_e : 3.302, D_real_e : 3.449, D_fake_e : 2.370, G_e : 2.415, Q_e : 0.073, new_measure : 3.551, k_curr : 0.063077\n",
      "D_e : 3.312, D_real_e : 3.446, D_fake_e : 2.366, G_e : 2.413, Q_e : 0.072, new_measure : 3.555, k_curr : 0.058922\n",
      "D_e : 3.294, D_real_e : 3.436, D_fake_e : 2.358, G_e : 2.406, Q_e : 0.071, new_measure : 3.540, k_curr : 0.055495\n",
      "D_e : 3.290, D_real_e : 3.430, D_fake_e : 2.353, G_e : 2.402, Q_e : 0.070, new_measure : 3.536, k_curr : 0.051007\n",
      "D_e : 3.266, D_real_e : 3.407, D_fake_e : 2.340, G_e : 2.387, Q_e : 0.070, new_measure : 3.506, k_curr : 0.043703\n",
      "D_e : 3.273, D_real_e : 3.404, D_fake_e : 2.334, G_e : 2.380, Q_e : 0.069, new_measure : 3.502, k_curr : 0.058373\n",
      "D_e : 3.261, D_real_e : 3.390, D_fake_e : 2.327, G_e : 2.374, Q_e : 0.068, new_measure : 3.490, k_curr : 0.055062\n",
      "total time :  13945.760412931442\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f93cfb39ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.set_random_seed(int(time.time()))\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))) as sess :\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    np.random.seed(int(time.time()))\n",
    "\n",
    "    \n",
    "    one_hot = np.eye(c_size)\n",
    "    temp2 = np.array([1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4])\n",
    "    test_c = one_hot[temp2].reshape([-1,1,1,c_size])\n",
    "    test_z = np.random.uniform(-1,1,size=(16,1,1,z_size))\n",
    "    mnist_4by4_save(np.reshape(test_normal_data[0:16],(-1,64,64,1)),file_name + '/D_origin.png')    \n",
    "    mnist_4by4_save(np.reshape(test_anomalous_data[0:16],(-1,64,64,1)),file_name + '/anomalous.png')    \n",
    "    log_txt = open(file_name +'/log.txt','w')\n",
    "\n",
    "    hist_G = []\n",
    "    hist_D = []\n",
    "    G_error = []\n",
    "    D_error = []\n",
    "    Q_error=[]\n",
    "    E_error = []\n",
    "    D_fake_error = []\n",
    "    D_real_error = []\n",
    "    new_measure = []\n",
    "    new_k = []\n",
    "    \n",
    "    start = time.time()\n",
    "    for epoch in range(train_epoch) :\n",
    "        \n",
    "        train_normal_data = idx_shuffle(train_normal_data) \n",
    "        \n",
    "        for iteration in range(train_normal_data.shape[0] // batch_size) : \n",
    "        \n",
    "            \n",
    "            train_images = train_normal_data[iteration*batch_size : (iteration+1)*batch_size]      \n",
    "            u_ = np.reshape(train_images,(-1,64,64,1)) \n",
    "            z_ = np.random.uniform(-1,1,size=(batch_size,1,1,z_size))\n",
    "            temp1 = np.random.randint(0,10,(batch_size))                                                                                                                                     \n",
    "            c_ = one_hot[temp1].reshape([-1,1,1,c_size])\n",
    "        \n",
    "            _ , D_e,D_real_e,D_fake_e = sess.run([D_optim, D_loss,D_real_loss,D_fake_loss], {u : u_, z : z_, c : c_, k : k_curr,isTrain : True})\n",
    "            D_error.append(D_e)\n",
    "            D_real_error.append(np.maximum(0.0, D_real_e))\n",
    "            D_fake_error.append(np.maximum(0.0,D_fake_e))\n",
    "\n",
    "            #    train_images,train_labels = mnist.train.next_batch(100)    \n",
    "            #    u_ = np.reshape(train_images,(-1,64,64,1)) \n",
    "            #    z_ = np.random.normal(0,1,size=(100,1,1,100))\n",
    "   \n",
    "            _ , G_e,Q_e = sess.run([G_optim, G_loss,Q_loss], {u : u_, z : z_, c : c_, k : k_curr, isTrain : True}) \n",
    "            G_error.append(G_e)\n",
    "            Q_error.append(Q_e)\n",
    "\n",
    "            \n",
    "            k_curr = k_curr + lam * (gamma*D_real_e - G_e)\n",
    "            \n",
    "\n",
    "            \n",
    "            measure = D_real_e + np.abs(gamma*D_real_e - G_e)\n",
    "            \n",
    "            new_measure.append(measure)\n",
    "            new_k.append(k_curr)\n",
    "        hist_D.append(np.mean(D_error)) \n",
    "        hist_G.append(np.mean(G_error))\n",
    "\n",
    "        print('D_e : %.3f, D_real_e : %.3f, D_fake_e : %.3f, G_e : %.3f, Q_e : %.3f, new_measure : %.3f, k_curr : %3f'\n",
    "              %(np.mean(D_error), np.mean(D_real_error),np.mean(D_fake_error), np.mean(G_error),\n",
    "                np.mean(Q_error),np.mean(new_measure),k_curr))\n",
    "        log_txt.write('D_e : %.6f, D_real_e : %.6f, D_fake_e : %.6f, G_e : %.6f\\n'%(np.mean(D_error),\n",
    "            np.mean(D_real_error), np.mean(D_fake_error), np.mean(G_error)))\n",
    "      \n",
    "        r = sess.run([G_sample],feed_dict={z : test_z, c : test_c, isTrain : False})       \n",
    "        mnist_4by4_save(np.reshape(r,(-1,64,64,1)),file_name + '/result_{}.png'.format(str(epoch).zfill(3)))\n",
    "\n",
    "        r = sess.run([D_real],feed_dict={u : test_normal_data[0:16], isTrain : False})        \n",
    "        mnist_4by4_save(np.reshape(r,(-1,64,64,1)),file_name + '/D_{}.png'.format(str(epoch).zfill(3)))\n",
    "        \n",
    "        \n",
    "        \n",
    "        np.random.seed(int(time.time()))\n",
    "\n",
    "\n",
    "        G_error = []\n",
    "        D_error = []       \n",
    "        D_fake_error = []     \n",
    "        D_real_error = []\n",
    "        new_measure = []\n",
    "    \n",
    "    \n",
    "    log_txt.close()\n",
    "    gan_loss_graph_save(G_loss = hist_G,D_loss=hist_D,path = file_name + '/loss_graph.png')   \n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess,file_name + '/para.cktp')\n",
    "\n",
    "    end = time.time()-start\n",
    "\n",
    "    print(\"total time : \",end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## network load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "321px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
