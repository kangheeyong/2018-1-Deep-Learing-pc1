{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": [
     17,
     21,
     25,
     29,
     33,
     44
    ]
   },
   "source": [
    "# Boundary Equilibrimum infoGANs for Fault Detection example\n",
    "\n",
    "## 초기 설정들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     17,
     21,
     25,
     33,
     44,
     63
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_normal_data :  (1009, 64, 64, 1)\n",
      "test_anomalous_data :  (8991, 64, 64, 1)\n",
      "train_normal_data :  (5454, 64, 64, 1)\n",
      "train_anomalous_data :  (49546, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec \n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "file_dir = 'anoGANs_MNIST_data/'\n",
    "\n",
    "with gzip.open(file_dir + 'test_normal_data_exp_9.pickle.gzip','rb') as f :\n",
    "    test_normal_data = pickle.load(f)\n",
    "    print('test_normal_data : ' ,test_normal_data.shape)\n",
    "\n",
    "with gzip.open(file_dir + 'test_anomalous_data_exp_9.pickle.gzip','rb') as f :\n",
    "    test_anomalous_data = pickle.load(f)\n",
    "    print('test_anomalous_data : ',test_anomalous_data.shape)\n",
    "    \n",
    "with gzip.open(file_dir + 'train_normal_data_exp_9.pickle.gzip','rb') as f :\n",
    "    train_normal_data = pickle.load(f)\n",
    "    print('train_normal_data : ', train_normal_data.shape)\n",
    "    \n",
    "with gzip.open(file_dir + 'train_anomalous_data_exp_9.pickle.gzip','rb') as f :\n",
    "    train_anomalous_data = pickle.load(f)\n",
    "    print('train_anomalous_data : ',train_anomalous_data.shape )\n",
    "\n",
    "def idx_shuffle(x) : \n",
    "    l = x.shape[0]\n",
    "    idx = np.arange(l)\n",
    "    np.random.shuffle(idx)\n",
    "    shuffled_x = np.empty(x.shape)\n",
    "\n",
    "    for i in range(l):\n",
    "        shuffled_x[idx[i]] = x[i]\n",
    "    \n",
    "    return shuffled_x\n",
    "\n",
    "def mnist_4by4_save(samples,path):\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    gs = gridspec.GridSpec(4, 4)    \n",
    "    gs.update(wspace=0.05, hspace=0.05) #이미지 사이간격 조절\n",
    "  \n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')    \n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "   \n",
    "        plt.imshow(sample.reshape(64, 64), cmap='Greys_r',clim=(0.0,1.0))\n",
    "    plt.colorbar()\n",
    "    plt.savefig(path, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "   \n",
    "    return None\n",
    "\n",
    "def gan_loss_graph_save(G_loss,D_loss,path):\n",
    "    x1 = range(len(G_loss))\n",
    "    x2 = range(len(D_loss))\n",
    "      \n",
    "    y1 = G_loss\n",
    "    y2 = D_loss\n",
    "  \n",
    "      \n",
    "    plt.plot(x1,y1,label='G_loss') \n",
    "    plt.plot(x2,y2,label='D_loss') \n",
    "  \n",
    "    plt.xlabel('weight per update')\n",
    "    plt.ylabel('loss')             \n",
    "    plt.legend(loc=4)              \n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "  \n",
    "    plt.savefig(path)              \n",
    "\n",
    "    return None\n",
    "\n",
    "file_name = 'ex_BE_infoGANs_for_bench_marking'\n",
    "\n",
    "if not os.path.isdir(file_name) :\n",
    "    os.mkdir(file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네트워크 정의\n",
    "\n",
    "D부분을 encoder와 discriminator로 나눈 이유는 encoder를 나중에 feature map으로 쓰기 위해서 편의상 나누어서 정의함\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     123
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_epoch = 50\n",
    "batch_size = 100\n",
    "z_size = 100\n",
    "lam = 0.01\n",
    "gamma = 0.7\n",
    "k_curr = 0.0\n",
    "c_size = 10\n",
    "\n",
    "\n",
    "def G(x,c,isTrain = True, reuse = False, name = 'G') : #input = (minibatch * w * h * ch)\n",
    "    \n",
    "    # out size = (in size + 2*padding - kenel)/strides + 1    \n",
    "    w_init = tf.truncated_normal_initializer(mean= 0.0, stddev=0.02)\n",
    "    b_init = tf.constant_initializer(0.0)\n",
    "\n",
    "    with tf.variable_scope('G',reuse=reuse)  :\n",
    "        \n",
    "        #x = (-1, 1, 1, 100)\n",
    "        x_concat = tf.concat([x,c],3)\n",
    "        conv1 = tf.layers.conv2d_transpose(x_concat,512,[4,4], strides=(1,1),padding = 'valid',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init) \n",
    "        r1 = tf.nn.elu(tf.layers.batch_normalization(conv1,training=isTrain))#4*4*512\n",
    "        \n",
    "        conv2 = tf.layers.conv2d_transpose(r1,256,[5,5], strides=(2,2),padding = 'same',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r2 = tf.nn.elu(tf.layers.batch_normalization(conv2,training=isTrain))#8*8*256\n",
    "                \n",
    "        conv3 = tf.layers.conv2d_transpose(r2,128,[5,5], strides=(2,2),padding = 'same',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r3 = tf.nn.elu(tf.layers.batch_normalization(conv3,training=isTrain))#16*16*128\n",
    "\n",
    "        conv4 = tf.layers.conv2d_transpose(r3,64,[5,5], strides=(2,2),padding = 'same',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r4 = tf.nn.elu(tf.layers.batch_normalization(conv4,training=isTrain))#32*32*64\n",
    "\n",
    "        conv5 = tf.layers.conv2d_transpose(r4,1,[5,5], strides=(2,2),padding = 'same',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init) #64*64*1\n",
    "        \n",
    "    r5= tf.nn.tanh(conv5,name=name)#64*64*1\n",
    "  \n",
    "    return r5\n",
    "\n",
    "def E(x,isTrain = True, reuse = False, name = 'E') : #input = (minibatch * w * h * ch)\n",
    "    \n",
    "    # out size = (in size + 2*padding - kenel)/strides + 1    \n",
    "    w_init = tf.truncated_normal_initializer(mean= 0.0, stddev=0.02)\n",
    "    b_init = tf.constant_initializer(0.0)\n",
    "\n",
    "    with tf.variable_scope('E',reuse=reuse)  :\n",
    "        \n",
    "        #x = (-1, 64, 64, 1)\n",
    "\n",
    "        conv1 = tf.layers.conv2d(x,64,[5,5], strides=(2,2),padding = 'same',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init) \n",
    "        r1 = tf.nn.elu(conv1)#32*32*64\n",
    "        \n",
    "        conv2 = tf.layers.conv2d(r1,128,[5,5], strides=(2,2),padding = 'same',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r2 = tf.nn.elu(tf.layers.batch_normalization(conv2,training=isTrain))#16*16*128\n",
    "                \n",
    "        conv3 = tf.layers.conv2d(r2,256,[5,5], strides=(2,2),padding = 'same',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r3 = tf.nn.elu(tf.layers.batch_normalization(conv3,training=isTrain))#8*8*256\n",
    "\n",
    "        conv4 = tf.layers.conv2d(r3,512,[5,5], strides=(2,2),padding = 'same',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r4 = tf.nn.elu(tf.layers.batch_normalization(conv4,training=isTrain))#4*4*512\n",
    "\n",
    "        conv5 = tf.layers.conv2d(r4,100,[4,4], strides=(1,1),padding = 'valid',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init) #1*1*100\n",
    "        \n",
    "        #\n",
    "        \n",
    "        fc0  = tf.reshape(conv4, (-1, 4*4*512))\n",
    "        \n",
    "        w1 = tf.get_variable('w1',[4*4*512, c_size],initializer=w_init)\n",
    "        b1 = tf.get_variable('b1',[c_size],initializer=b_init)\n",
    "        \n",
    "                                          \n",
    "        fc1 = tf.nn.softmax(tf.matmul(fc0,w1) + b1, name = name)\n",
    "        \n",
    "        \n",
    "    r5 = tf.nn.tanh(tf.layers.batch_normalization(conv5,training=isTrain), name = name)#4*4*512\n",
    "  \n",
    "  \n",
    "    return r5, tf.reshape(fc1,(-1,1,1,c_size))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def D_enc(x,isTrain=True,reuse = False, name = 'D_enc') :\n",
    "    \n",
    "    w_init = tf.truncated_normal_initializer(mean= 0.0, stddev=0.02)\n",
    "    b_init = tf.constant_initializer(0.0)\n",
    "    with tf.variable_scope('D_enc', reuse=reuse) :\n",
    "        \n",
    "        #x = (-1,64,64,1)\n",
    "        # out size = (in size + 2*padding - kenel)/strides + 1   \n",
    "\n",
    "        conv1 = tf.layers.conv2d(x,64,[5,5], strides=(2,2),padding = 'same',\n",
    "                                kernel_initializer=w_init, bias_initializer=b_init) \n",
    "        r1 = tf.nn.elu(conv1)#32*32*64\n",
    "\n",
    "   \n",
    "        conv2 = tf.layers.conv2d(r1,128,[5,5], strides=(2,2),padding = 'same',\n",
    "                                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r2 = tf.nn.elu(tf.layers.batch_normalization(conv2,training=isTrain))#16*16*128\n",
    "\n",
    "  \n",
    "        conv3 = tf.layers.conv2d(r2,256,[5,5], strides=(2,2),padding = 'same',\n",
    "                                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r3 = tf.nn.elu(tf.layers.batch_normalization(conv3,training=isTrain))#8*8*256\n",
    "        \n",
    "        conv4 = tf.layers.conv2d(r3,512,[5,5], strides=(2,2),padding = 'same',\n",
    "                                kernel_initializer=w_init, bias_initializer=b_init)    \n",
    "        r4 = tf.nn.elu(tf.layers.batch_normalization(conv4,training=isTrain), name = name)#4*4*512\n",
    "        \n",
    "        conv5 = tf.layers.conv2d(r4,100,[4,4], strides=(1,1),padding = 'valid',\n",
    "                                kernel_initializer=w_init, bias_initializer=b_init)    \n",
    "        r5 = tf.layers.batch_normalization(conv5,training=isTrain)\n",
    "    return tf.add(r5,0,name=name)\n",
    "\n",
    "def D_dec(x,isTrain=True,reuse = False, name = 'D_dec') :\n",
    "    \n",
    "    w_init = tf.truncated_normal_initializer(mean= 0.0, stddev=0.02)\n",
    "    b_init = tf.constant_initializer(0.0)\n",
    "    with tf.variable_scope('D_dec', reuse=reuse) :\n",
    "        \n",
    "        #x = (-1,64,64,1)\n",
    "        # out size = (in size + 2*padding - kenel)/strides + 1   \n",
    "        # 256*16*16\n",
    "        # 128*32*32\n",
    "        # 1*64*64\n",
    "        conv6 = tf.layers.conv2d_transpose(x,512,[4,4], strides=(1,1),padding = 'valid',\n",
    "                                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r6 = tf.nn.elu(tf.layers.batch_normalization(conv6,training=isTrain))#4*4*256\n",
    "        \n",
    "        conv7 = tf.layers.conv2d_transpose(r6,256,[5,5], strides=(2,2),padding = 'same',\n",
    "                                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r7 = tf.nn.elu(tf.layers.batch_normalization(conv7,training=isTrain))#8*8*256\n",
    "\n",
    "\n",
    "        conv8 = tf.layers.conv2d_transpose(r7,128,[5,5], strides=(2,2),padding = 'same',\n",
    "                                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r8 = tf.nn.elu(tf.layers.batch_normalization(conv8,training=isTrain))#16*16*128\n",
    "             \n",
    "        conv9 = tf.layers.conv2d_transpose(r8,64,[5,5], strides=(2,2),padding = 'same',\n",
    "                                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r9 = tf.nn.elu(tf.layers.batch_normalization(conv9,training=isTrain))#32*32*64\n",
    "          \n",
    "        conv10 = tf.layers.conv2d_transpose(r9,1,[5,5], strides=(2,2),padding = 'same',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init) #64*64*1\n",
    "        \n",
    "    r10= tf.nn.tanh(conv10,name=name)#64*64*1\n",
    "    \n",
    "    return r10\n",
    "def Q_cat(x,reuse = False, name = 'Q_cat') :\n",
    "    \n",
    "    w_init = tf.truncated_normal_initializer(mean= 0.0, stddev=0.02)\n",
    "    b_init = tf.constant_initializer(0.0)\n",
    "    with tf.variable_scope('Q_cat', reuse=reuse) :\n",
    "        \n",
    "        #x = (-1,64,64,1)\n",
    "        # out size = (in size + 2*padding - kenel)/strides + 1   \n",
    "        fc0  = tf.reshape(x, (-1, 100))\n",
    "        \n",
    "        w1 = tf.get_variable('w1',[100, c_size],initializer=w_init)\n",
    "        b1 = tf.get_variable('b1',[c_size],initializer=b_init)\n",
    "        \n",
    "                                          \n",
    "    fc1 = tf.nn.softmax(tf.matmul(fc0,w1) + b1, name = name)\n",
    "    \n",
    "    return tf.reshape(fc1, (-1,1,1,c_size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네트워크 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "z = tf.placeholder(tf.float32,shape=(None,1,1,z_size),name = 'z')    #x_z = G(z)\n",
    "c = tf.placeholder(tf.float32,shape=(None,1,1,c_size),name = 'c')    #x_z = G(z,c)\n",
    "\n",
    "u = tf.placeholder(tf.float32, shape = (None, 64,64,1),name='u')      #u = x\n",
    "k = tf.placeholder(tf.float32, name = 'k')\n",
    "\n",
    "\n",
    "isTrain = tf.placeholder(dtype=tf.bool,name='isTrain')  # BN 설정 parameter\n",
    "\n",
    "\n",
    "G_sample = G(z,c,name='G_sample') # G(z)\n",
    "E_z, E_c = E(u,isTrain,name = 'E_z') \n",
    "\n",
    "re_image = G(E_z,E_c, isTrain, reuse=True, name ='re_image')\n",
    "re_z, re_c = E(G_sample, isTrain, reuse=True, name ='re_z')\n",
    "\n",
    "\n",
    "\n",
    "re_z_loss = tf.reduce_mean(tf.sqrt(tf.reduce_sum((re_z - z)**2, axis=[1,2,3])) , name = 're_z_loss') \n",
    "re_c_loss = tf.reduce_mean(tf.reduce_sum(-c*tf.log(re_c + 1e-8), axis = [1,2,3]),name = 're_c_loss')\n",
    "re_image_loss = tf.reduce_mean(tf.sqrt(tf.reduce_sum((re_image - u)**2, axis=[1,2,3])) , name = 're_image_loss') \n",
    "\n",
    "\n",
    "E_loss = tf.add(re_z_loss, re_c_loss, name = 'E_loss')                       \n",
    "\n",
    "\n",
    "D_real = D_dec(D_enc(u, isTrain,reuse=False), isTrain, reuse=False, name = 'D_real')                       # D(x)\n",
    "D_fake = D_dec(D_enc(G_sample, isTrain,reuse=True), isTrain, reuse=True, name = 'D_fake')         # D(G(z))\n",
    "Q_fake = Q_cat(D_enc(G_sample, isTrain,reuse=True), reuse=False, name='Q_fake')\n",
    "\n",
    "#input = (minibatch * w * h * ch)\n",
    "D_real_loss = tf.reduce_mean(tf.sqrt(tf.reduce_sum((D_real-u)**2, axis=[1,2,3])) , name = 'D_real_loss')             \n",
    "\n",
    "D_fake_loss = tf.reduce_mean(tf.sqrt(tf.reduce_sum((D_fake - G_sample)**2, axis=[1,2,3])),  name = 'D_fake_loss' )\n",
    "\n",
    "D_loss =  tf.add(D_real_loss, -k*D_fake_loss, name='D_loss')                                        \n",
    "\n",
    "G_loss =  tf.reduce_mean(tf.sqrt(tf.reduce_sum((D_fake - G_sample)**2, axis=[1,2,3])), name='G_loss')                             # E[-log(D(G(z)))]\n",
    "Q_loss = tf.reduce_mean(tf.reduce_sum(-c*tf.log(Q_fake + 1e-8), axis = [1,2,3]),name = 'Q_loss')\n",
    "\n",
    "                                                                                                                                \n",
    "T_vars = tf.trainable_variables()\n",
    "D_vars = [var for var in T_vars if var.name.startswith('D_dec') or var.name.startswith('D_enc')]\n",
    "G_vars = [var for var in T_vars if var.name.startswith('G')]\n",
    "E_vars = [var for var in T_vars if var.name.startswith('E')]\n",
    "Q_vars = [var for var in T_vars if var.name.startswith('Q')]\n",
    "\n",
    "    # When using the batchnormalization layers,\n",
    "    # it is necessary to manually add the update operations\n",
    "    # because the moving averages are not included in the graph\n",
    "with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)) :        \n",
    "    D_optim = tf.train.AdamOptimizer(2e-5,beta1=0.5).minimize(D_loss, var_list=D_vars, name='D_optim') \n",
    "    G_optim = tf.train.AdamOptimizer(2e-4,beta1=0.5).minimize(G_loss + Q_loss, var_list=G_vars+Q_vars, name='G_optim')\n",
    "    E_optim = tf.train.AdamOptimizer(2e-4,beta1=0.1).minimize(E_loss, var_list=E_vars, name='E_optim')\n",
    "    E_AE_optim = tf.train.AdamOptimizer(2e-4,beta1=0.1).minimize(re_image_loss, var_list=E_vars, name='E_AE_optim')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D_e : -63.453, D_real_e : 56.477, D_fake_e : 19.989, G_e : 20.577, Q_e : 1.752, new_measure : 75.434, k_curr : 10.236844\n",
      "D_e : -315.131, D_real_e : 50.528, D_fake_e : 44.921, G_e : 45.954, Q_e : 1.859, new_measure : 61.431, k_curr : 4.521277\n",
      "D_e : 31.399, D_real_e : 44.357, D_fake_e : 44.909, G_e : 44.533, Q_e : 1.915, new_measure : 58.561, k_curr : -2.759889\n",
      "D_e : 54.552, D_real_e : 42.410, D_fake_e : 21.758, G_e : 22.898, Q_e : 1.994, new_measure : 58.427, k_curr : 0.905833\n",
      "D_e : 45.166, D_real_e : 40.778, D_fake_e : 29.412, G_e : 30.842, Q_e : 2.036, new_measure : 52.897, k_curr : -0.334758\n",
      "D_e : 23.345, D_real_e : 40.174, D_fake_e : 24.376, G_e : 25.021, Q_e : 2.055, new_measure : 43.407, k_curr : 1.339864\n",
      "D_e : 24.033, D_real_e : 41.658, D_fake_e : 30.568, G_e : 30.944, Q_e : 2.065, new_measure : 44.709, k_curr : 0.377123\n",
      "D_e : 26.334, D_real_e : 39.441, D_fake_e : 26.802, G_e : 27.666, Q_e : 2.069, new_measure : 40.867, k_curr : 0.346162\n",
      "D_e : 24.833, D_real_e : 38.541, D_fake_e : 25.566, G_e : 26.713, Q_e : 2.071, new_measure : 40.104, k_curr : 0.489691\n",
      "D_e : 26.196, D_real_e : 37.538, D_fake_e : 25.021, G_e : 26.245, Q_e : 2.073, new_measure : 38.838, k_curr : 0.506595\n",
      "D_e : 23.913, D_real_e : 36.852, D_fake_e : 24.318, G_e : 25.655, Q_e : 2.073, new_measure : 38.382, k_curr : 0.582896\n",
      "D_e : 24.048, D_real_e : 36.099, D_fake_e : 24.193, G_e : 25.421, Q_e : 2.071, new_measure : 37.529, k_curr : 0.500925\n",
      "D_e : 23.307, D_real_e : 35.023, D_fake_e : 23.557, G_e : 24.599, Q_e : 2.066, new_measure : 36.073, k_curr : 0.455958\n",
      "D_e : 25.466, D_real_e : 33.826, D_fake_e : 22.773, G_e : 23.787, Q_e : 2.061, new_measure : 35.610, k_curr : 0.397407\n",
      "D_e : 24.125, D_real_e : 32.841, D_fake_e : 22.126, G_e : 23.140, Q_e : 2.054, new_measure : 34.234, k_curr : 0.315917\n",
      "D_e : 24.846, D_real_e : 31.512, D_fake_e : 20.954, G_e : 21.927, Q_e : 2.043, new_measure : 33.214, k_curr : 0.387039\n",
      "D_e : 23.009, D_real_e : 30.742, D_fake_e : 20.768, G_e : 21.706, Q_e : 2.031, new_measure : 32.229, k_curr : 0.286100\n",
      "D_e : 22.548, D_real_e : 29.824, D_fake_e : 20.029, G_e : 20.893, Q_e : 2.017, new_measure : 31.170, k_curr : 0.277437\n",
      "D_e : 23.405, D_real_e : 29.043, D_fake_e : 19.627, G_e : 20.393, Q_e : 2.000, new_measure : 30.352, k_curr : 0.243200\n",
      "D_e : 21.850, D_real_e : 28.218, D_fake_e : 18.473, G_e : 19.239, Q_e : 1.981, new_measure : 29.817, k_curr : 0.520401\n",
      "D_e : 20.331, D_real_e : 27.700, D_fake_e : 18.909, G_e : 19.682, Q_e : 1.960, new_measure : 29.057, k_curr : 0.362805\n",
      "D_e : 22.753, D_real_e : 26.371, D_fake_e : 18.523, G_e : 18.980, Q_e : 1.936, new_measure : 28.176, k_curr : 0.082082\n",
      "D_e : 20.454, D_real_e : 25.548, D_fake_e : 17.061, G_e : 17.462, Q_e : 1.910, new_measure : 27.042, k_curr : 0.309484\n",
      "D_e : 19.970, D_real_e : 24.716, D_fake_e : 16.799, G_e : 17.222, Q_e : 1.882, new_measure : 25.967, k_curr : 0.351903\n",
      "D_e : 19.539, D_real_e : 23.725, D_fake_e : 16.177, G_e : 16.545, Q_e : 1.853, new_measure : 25.231, k_curr : 0.385286\n",
      "D_e : 18.842, D_real_e : 23.182, D_fake_e : 16.492, G_e : 16.958, Q_e : 1.825, new_measure : 24.907, k_curr : -0.009539\n",
      "D_e : 22.461, D_real_e : 22.093, D_fake_e : 15.032, G_e : 15.007, Q_e : 1.797, new_measure : 24.547, k_curr : 0.237967\n",
      "D_e : 17.955, D_real_e : 21.088, D_fake_e : 14.328, G_e : 14.721, Q_e : 1.768, new_measure : 22.850, k_curr : 0.259697\n",
      "D_e : 17.559, D_real_e : 20.673, D_fake_e : 14.315, G_e : 14.693, Q_e : 1.739, new_measure : 22.212, k_curr : 0.139755\n",
      "D_e : 18.049, D_real_e : 19.730, D_fake_e : 13.230, G_e : 13.541, Q_e : 1.710, new_measure : 22.138, k_curr : 0.285829\n",
      "D_e : 17.741, D_real_e : 19.249, D_fake_e : 13.437, G_e : 13.842, Q_e : 1.682, new_measure : 21.069, k_curr : 0.087247\n",
      "D_e : 16.933, D_real_e : 18.710, D_fake_e : 12.861, G_e : 13.171, Q_e : 1.654, new_measure : 20.651, k_curr : 0.047350\n",
      "D_e : 17.487, D_real_e : 17.935, D_fake_e : 12.213, G_e : 12.294, Q_e : 1.627, new_measure : 19.662, k_curr : 0.188128\n",
      "D_e : 15.737, D_real_e : 17.563, D_fake_e : 11.874, G_e : 12.103, Q_e : 1.599, new_measure : 19.509, k_curr : 0.291102\n",
      "D_e : 19.621, D_real_e : 17.073, D_fake_e : 13.194, G_e : 13.089, Q_e : 1.572, new_measure : 19.899, k_curr : -0.323350\n",
      "D_e : 16.478, D_real_e : 16.800, D_fake_e : 10.668, G_e : 10.830, Q_e : 1.545, new_measure : 19.387, k_curr : 0.178731\n",
      "D_e : 13.660, D_real_e : 16.338, D_fake_e : 11.387, G_e : 11.792, Q_e : 1.518, new_measure : 18.207, k_curr : -0.012979\n",
      "D_e : 14.435, D_real_e : 16.015, D_fake_e : 10.463, G_e : 10.730, Q_e : 1.492, new_measure : 17.540, k_curr : 0.246360\n",
      "D_e : 13.521, D_real_e : 15.629, D_fake_e : 11.111, G_e : 11.393, Q_e : 1.467, new_measure : 17.436, k_curr : 0.001771\n",
      "D_e : 15.413, D_real_e : 15.298, D_fake_e : 10.526, G_e : 10.632, Q_e : 1.443, new_measure : 17.222, k_curr : 0.043350\n",
      "D_e : 12.908, D_real_e : 14.429, D_fake_e : 9.866, G_e : 10.108, Q_e : 1.419, new_measure : 15.913, k_curr : 0.039335\n",
      "D_e : 14.212, D_real_e : 14.408, D_fake_e : 9.812, G_e : 9.922, Q_e : 1.396, new_measure : 15.800, k_curr : 0.127819\n",
      "D_e : 12.171, D_real_e : 13.831, D_fake_e : 9.305, G_e : 9.506, Q_e : 1.373, new_measure : 14.938, k_curr : 0.222894\n",
      "D_e : 12.842, D_real_e : 13.493, D_fake_e : 9.625, G_e : 9.845, Q_e : 1.351, new_measure : 14.819, k_curr : 0.007140\n",
      "D_e : 12.298, D_real_e : 12.981, D_fake_e : 8.706, G_e : 8.771, Q_e : 1.330, new_measure : 13.983, k_curr : 0.177526\n",
      "D_e : 11.606, D_real_e : 12.540, D_fake_e : 9.024, G_e : 9.303, Q_e : 1.309, new_measure : 13.934, k_curr : -0.105981\n",
      "D_e : 12.695, D_real_e : 12.238, D_fake_e : 8.654, G_e : 8.650, Q_e : 1.288, new_measure : 13.654, k_curr : -0.151216\n",
      "D_e : 13.066, D_real_e : 11.810, D_fake_e : 8.412, G_e : 8.201, Q_e : 1.269, new_measure : 13.226, k_curr : -0.115595\n",
      "D_e : 12.617, D_real_e : 11.869, D_fake_e : 8.257, G_e : 8.159, Q_e : 1.250, new_measure : 13.168, k_curr : -0.034611\n",
      "D_e : 11.563, D_real_e : 11.391, D_fake_e : 7.808, G_e : 7.872, Q_e : 1.231, new_measure : 12.613, k_curr : 0.020553\n",
      "total time :  835.5003161430359\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f916c7ba5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.set_random_seed(int(time.time()))\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))) as sess :\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    np.random.seed(int(time.time()))\n",
    "\n",
    "    \n",
    "    one_hot = np.eye(c_size)\n",
    "    temp2 = np.array([1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4])\n",
    "    test_c = one_hot[temp2].reshape([-1,1,1,c_size])\n",
    "    test_z = np.random.uniform(-1,1,size=(16,1,1,z_size))\n",
    "    mnist_4by4_save(np.reshape(test_normal_data[0:16],(-1,64,64,1)),file_name + '/D_origin.png')    \n",
    "    mnist_4by4_save(np.reshape(test_anomalous_data[0:16],(-1,64,64,1)),file_name + '/anomalous.png')    \n",
    "    log_txt = open(file_name +'/log.txt','w')\n",
    "\n",
    "    hist_G = []\n",
    "    hist_D = []\n",
    "    G_error = []\n",
    "    D_error = []\n",
    "    Q_error=[]\n",
    "    E_error = []\n",
    "    D_fake_error = []\n",
    "    D_real_error = []\n",
    "    new_measure = []\n",
    "    new_k = []\n",
    "    \n",
    "    start = time.time()\n",
    "    for epoch in range(train_epoch) :\n",
    "        \n",
    "        train_normal_data = idx_shuffle(train_normal_data) \n",
    "        \n",
    "        for iteration in range(train_normal_data.shape[0] // batch_size) : \n",
    "        \n",
    "            \n",
    "            train_images = train_normal_data[iteration*batch_size : (iteration+1)*batch_size]      \n",
    "            u_ = np.reshape(train_images,(-1,64,64,1)) \n",
    "            z_ = np.random.uniform(-1,1,size=(batch_size,1,1,z_size))\n",
    "            temp1 = np.random.randint(0,10,(batch_size))                                                                                                                                     \n",
    "            c_ = one_hot[temp1].reshape([-1,1,1,c_size])\n",
    "        \n",
    "            _ , D_e,D_real_e,D_fake_e = sess.run([D_optim, D_loss,D_real_loss,D_fake_loss], {u : u_, z : z_, c : c_, k : k_curr,isTrain : True})\n",
    "            D_error.append(D_e)\n",
    "            D_real_error.append(np.maximum(0.0, D_real_e))\n",
    "            D_fake_error.append(np.maximum(0.0,D_fake_e))\n",
    "\n",
    "            #    train_images,train_labels = mnist.train.next_batch(100)    \n",
    "            #    u_ = np.reshape(train_images,(-1,64,64,1)) \n",
    "            #    z_ = np.random.normal(0,1,size=(100,1,1,100))\n",
    "   \n",
    "            _ , G_e,Q_e = sess.run([G_optim, G_loss,Q_loss], {u : u_, z : z_, c : c_, k : k_curr, isTrain : True}) \n",
    "            G_error.append(G_e)\n",
    "            Q_error.append(Q_e)\n",
    "\n",
    "            \n",
    "            k_curr = k_curr + lam * (gamma*D_real_e - G_e)\n",
    "            \n",
    "\n",
    "            \n",
    "            measure = D_real_e + np.abs(gamma*D_real_e - G_e)\n",
    "            \n",
    "            new_measure.append(measure)\n",
    "            new_k.append(k_curr)\n",
    "        hist_D.append(np.mean(D_error)) \n",
    "        hist_G.append(np.mean(G_error))\n",
    "\n",
    "        print('D_e : %.3f, D_real_e : %.3f, D_fake_e : %.3f, G_e : %.3f, Q_e : %.3f, new_measure : %.3f, k_curr : %3f'\n",
    "              %(np.mean(D_error), np.mean(D_real_error),np.mean(D_fake_error), np.mean(G_error),\n",
    "                np.mean(Q_error),np.mean(new_measure),k_curr))\n",
    "        log_txt.write('D_e : %.6f, D_real_e : %.6f, D_fake_e : %.6f, G_e : %.6f\\n'%(np.mean(D_error),\n",
    "            np.mean(D_real_error), np.mean(D_fake_error), np.mean(G_error)))\n",
    "      \n",
    "        r = sess.run([G_sample],feed_dict={z : test_z, c : test_c, isTrain : False})       \n",
    "        mnist_4by4_save(np.reshape(r,(-1,64,64,1)),file_name + '/result_{}.png'.format(str(epoch).zfill(3)))\n",
    "\n",
    "        r = sess.run([D_real],feed_dict={u : test_normal_data[0:16], isTrain : False})        \n",
    "        mnist_4by4_save(np.reshape(r,(-1,64,64,1)),file_name + '/D_{}.png'.format(str(epoch).zfill(3)))\n",
    "        \n",
    "        \n",
    "        \n",
    "        np.random.seed(int(time.time()))\n",
    "\n",
    "\n",
    "        G_error = []\n",
    "        D_error = []       \n",
    "        D_fake_error = []     \n",
    "        D_real_error = []\n",
    "        new_measure = []\n",
    "    \n",
    "    \n",
    "    log_txt.close()\n",
    "    gan_loss_graph_save(G_loss = hist_G,D_loss=hist_D,path = file_name + '/loss_graph.png')   \n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess,file_name + '/para.cktp')\n",
    "\n",
    "    end = time.time()-start\n",
    "\n",
    "    print(\"total time : \",end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## network load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "321px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
