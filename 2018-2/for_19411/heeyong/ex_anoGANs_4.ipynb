{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add some tips\n",
    "\n",
    "https://medium.com/@utk.is.here/keep-calm-and-train-a-gan-pitfalls-and-tips-on-training-generative-adversarial-networks-edd529764aa9\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     28,
     42,
     61
    ]
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec \n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "def my_mnist_train_batch(size) :\n",
    "    m = 500\n",
    "    data = []\n",
    "    for i in range(1000) :\n",
    "        number = number = np.random.randint(5)\n",
    "        image, label = mnist.train.next_batch(m)       \n",
    "        for j in range(len(label)) : \n",
    "            \n",
    "            if np.argmax(label[j])==number :\n",
    "                data.append(image[j])\n",
    "                number = number = np.random.randint(5)\n",
    "            if len(data) == size :\n",
    "                break\n",
    "        if len(data) == size :\n",
    "            break\n",
    "    return data\n",
    "\n",
    "def my_mnist_test_batch(size, number = 0) :\n",
    "    m = 500\n",
    "    data = []\n",
    "    for i in range(1000) :\n",
    "        image, label = mnist.test.next_batch(m)       \n",
    "        for j in range(len(label)) : \n",
    "            if np.argmax(label[j])==number :\n",
    "                data.append(image[j])              \n",
    "            if len(data) == size :\n",
    "                break\n",
    "        if len(data) == size :\n",
    "            break\n",
    "    return data\n",
    "\n",
    "def mnist_4by4_save(samples,path):\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    gs = gridspec.GridSpec(4, 4)    \n",
    "    gs.update(wspace=0.05, hspace=0.05) #이미지 사이간격 조절\n",
    "  \n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')    \n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "   \n",
    "        plt.imshow(sample.reshape(28, 28), cmap='Greys_r',clim=(0.0,1.0))\n",
    "    plt.colorbar()\n",
    "    plt.savefig(path, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "   \n",
    "    return None\n",
    "\n",
    "def gan_loss_graph_save(G_loss,D_loss,path):\n",
    "    x1 = range(len(G_loss))\n",
    "    x2 = range(len(D_loss))\n",
    "      \n",
    "    y1 = G_loss\n",
    "    y2 = D_loss\n",
    "  \n",
    "      \n",
    "    plt.plot(x1,y1,label='G_loss') \n",
    "    plt.plot(x2,y2,label='D_loss') \n",
    "  \n",
    "    plt.xlabel('weight per update')\n",
    "    plt.ylabel('loss')             \n",
    "    plt.legend(loc=4)              \n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "  \n",
    "    plt.savefig(path)              \n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     7,
     44
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"../MNIST_data\", one_hot=True)\n",
    "\n",
    "file_name = 'ex_anoGANs_4'\n",
    "\n",
    "if not os.path.isdir(file_name) :\n",
    "    os.mkdir(file_name)\n",
    "def simple_G(x,isTrain = True, reuse = False, name = 'G_out') : #input = (minibatch * w * h * ch)\n",
    "    \n",
    "    # out size = (in size + 2*padding - kenel)/strides + 1    \n",
    "    w_init = tf.truncated_normal_initializer(mean= 0.0, stddev=0.02)\n",
    "    b_init = tf.constant_initializer(0.0)\n",
    "\n",
    "\n",
    "    with tf.variable_scope('G',reuse=reuse)  :\n",
    "        \n",
    "        #x = (-1, 1, 1, 100)\n",
    "\n",
    "        conv1 = tf.layers.conv2d_transpose(x,2048,[4,4], strides=(1,1),padding = 'valid',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init) \n",
    "        r1 = tf.nn.elu(tf.layers.batch_normalization(conv1,training=isTrain))#1024*4*4\n",
    "        \n",
    "        conv2 = tf.layers.conv2d_transpose(r1,1024,[4,4], strides=(2,2),padding = 'same',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r2 = tf.nn.elu(tf.layers.batch_normalization(conv2,training=isTrain))#512*8*8\n",
    "                \n",
    "        conv3 = tf.layers.conv2d_transpose(r2,512,[4,4], strides=(2,2),padding = 'same',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r3 = tf.nn.elu(tf.layers.batch_normalization(conv3,training=isTrain))#256*16*16\n",
    "\n",
    "        conv4 = tf.layers.conv2d_transpose(r3,256,[4,4], strides=(2,2),padding = 'same',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r4 = tf.nn.elu(tf.layers.batch_normalization(conv4,training=isTrain))#128*32*32\n",
    "\n",
    "        conv5 = tf.layers.conv2d(r4,128,[3,3], strides=(1,1),padding = 'valid',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r5 = tf.nn.elu(tf.layers.batch_normalization(conv5,training=isTrain))#64*30*30\n",
    "\n",
    "        conv6 = tf.layers.conv2d(r5,1,[3,3], strides=(1,1),padding = 'valid',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "    r6 = tf.nn.sigmoid(conv6,name=name)#1*28*28\n",
    "  \n",
    "\n",
    "    return r6\n",
    "def residual_loss_G(x,isTrain = False, reuse = True, name = 'residual_loss_out') : #input = (minibatch * w * h * ch)\n",
    "    \n",
    "    # out size = (in size + 2*padding - kenel)/strides + 1    \n",
    "\n",
    "\n",
    "    with tf.variable_scope('G',reuse=reuse) as scope :\n",
    "        scope.reuse_variables()\n",
    "        #x = (-1, 1, 1, 100)\n",
    "\n",
    "\n",
    "        conv1 = tf.layers.conv2d_transpose(x,2048,[4,4], strides=(1,1),padding = 'valid')\n",
    "        r1 = tf.nn.elu(tf.layers.batch_normalization(conv1,training=isTrain))#1024*4*4\n",
    "        \n",
    "        conv2 = tf.layers.conv2d_transpose(r1,1024,[4,4], strides=(2,2),padding = 'same')\n",
    "        r2 = tf.nn.elu(tf.layers.batch_normalization(conv2,training=isTrain))#512*8*8\n",
    "                \n",
    "        conv3 = tf.layers.conv2d_transpose(r2,512,[4,4], strides=(2,2),padding = 'same')\n",
    "        r3 = tf.nn.elu(tf.layers.batch_normalization(conv3,training=isTrain))#256*16*16\n",
    "\n",
    "        conv4 = tf.layers.conv2d_transpose(r3,256,[4,4], strides=(2,2),padding = 'same')\n",
    "        r4 = tf.nn.elu(tf.layers.batch_normalization(conv4,training=isTrain))#128*32*32\n",
    "\n",
    "        conv5 = tf.layers.conv2d(r4,128,[3,3], strides=(1,1),padding = 'valid')\n",
    "        r5 = tf.nn.elu(tf.layers.batch_normalization(conv5,training=isTrain))#64*30*30\n",
    "\n",
    "        conv6 = tf.layers.conv2d(r5,1,[3,3], strides=(1,1),padding = 'valid')\n",
    "    r6 = tf.nn.sigmoid(conv6,name=name)#1*28*28\n",
    "  \n",
    "\n",
    "    return r6\n",
    "def simple_D(x,isTrain=True,reuse = False) :\n",
    "    \n",
    "    w_init = tf.truncated_normal_initializer(mean= 0.0, stddev=0.02)\n",
    "    b_init = tf.constant_initializer(0.0)\n",
    "    with tf.variable_scope('D', reuse=reuse) :\n",
    "        \n",
    "        #x = (-1,28,28,1)\n",
    "        # out size = (in size + 2*padding - kenel)/strides + 1   \n",
    "\n",
    "        conv1 = tf.layers.conv2d(x,128,[5,5], strides=(1,1),padding = 'valid',\n",
    "                                kernel_initializer=w_init, bias_initializer=b_init) \n",
    "        r1 = tf.nn.elu(conv1)#64*24*24\n",
    "\n",
    "   \n",
    "        conv2 = tf.layers.conv2d(r1,256,[5,5], strides=(1,1),padding = 'valid',\n",
    "                                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r2 = tf.nn.elu(tf.layers.batch_normalization(conv2,training=isTrain))#128*20*20\n",
    "\n",
    "  \n",
    "        conv3 = tf.layers.conv2d(r2,512,[5,5], strides=(1,1),padding = 'valid',\n",
    "                                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r3 = tf.nn.elu(tf.layers.batch_normalization(conv3,training=isTrain))#256*16*16\n",
    "\n",
    " \n",
    "        conv4 = tf.layers.conv2d(r3,1024,[4,4], strides=(2,2),padding = 'same',\n",
    "                                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r4 = tf.nn.elu(tf.layers.batch_normalization(conv4,training=isTrain))#512*8*8\n",
    "\n",
    "\n",
    "        conv5 = tf.layers.conv2d(r4,2048,[4,4], strides=(2,2),padding = 'same',\n",
    "                                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r5 = tf.nn.elu(tf.layers.batch_normalization(conv5,training=isTrain))#1024*4*4\n",
    "\n",
    "       \n",
    "        conv6 = tf.layers.conv2d(r5,1,[4,4], strides=(1,1),padding = 'valid',\n",
    "                                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "    r6 = tf.nn.sigmoid(conv6)#1*1*1\n",
    "\n",
    "\n",
    "    return r6\n",
    "def feature_extractor_D(x,isTrain=False,reuse = True, name='feature_out') :\n",
    "    \n",
    "    with tf.variable_scope('D', reuse=reuse) as scope :\n",
    "        scope.reuse_variables()\n",
    "        #x = (-1,28,28,1)\n",
    "\n",
    "        conv1 = tf.layers.conv2d(x,128,[5,5], strides=(1,1),padding = 'valid')\n",
    "        r1 = tf.nn.elu(conv1)#64*24*24\n",
    "\n",
    "   \n",
    "        conv2 = tf.layers.conv2d(r1,256,[5,5], strides=(1,1),padding = 'valid')\n",
    "        r2 = tf.nn.elu(tf.layers.batch_normalization(conv2,training=isTrain))#128*20*20\n",
    "\n",
    "  \n",
    "        conv3 = tf.layers.conv2d(r2,512,[5,5], strides=(1,1),padding = 'valid')\n",
    "    r3 = tf.nn.elu(tf.layers.batch_normalization(conv3,training=isTrain),name = name)#256*16*16\n",
    "\n",
    " \n",
    "        #conv4 = tf.layers.conv2d(r3,1024,[4,4], strides=(2,2),padding = 'same')\n",
    "        #r4 = tf.nn.lrelu(tf.layers.batch_normalization(conv4,training=isTrain),0.2)#512*8*8\n",
    "\n",
    "\n",
    "        #conv5 = tf.layers.conv2d(r4,2048,[4,4], strides=(2,2),padding = 'same')\n",
    "        #r5 = tf.nn.lrelu(tf.layers.batch_normalization(conv5,training=isTrain),0.2)#1024*4*4\n",
    "\n",
    "\n",
    "    return r3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'grad_z/G_1/conv2d_transpose/conv2d_transpose_grad/Conv2D:0' shape=(?, 1, 1, 100) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "\n",
    "z_size = 100\n",
    "\n",
    "\n",
    "z = tf.placeholder(tf.float32,shape=(None,1,1,z_size),name = 'z')    \n",
    "u = tf.placeholder(tf.float32, shape = (None, 28,28,1),name='u')\n",
    "\n",
    "noise = tf.placeholder(tf.float32, shape = (None, 28,28,1),name='noise')\n",
    "\n",
    "test_u = tf.placeholder(tf.float32, shape = (None, 28,28,1),name='test_u')\n",
    "latent_z = tf.placeholder(tf.float32,shape=(None,1,1,z_size),name = 'latent_z')    \n",
    "\n",
    "isTrain = tf.placeholder(dtype=tf.bool,name='isTrain') \n",
    "\n",
    "soft_one = tf.placeholder(tf.float32, shape = (None, 1,1,1),name='soft_one') # 0.9~1.0\n",
    "soft_zero = tf.placeholder(tf.float32, shape = (None, 1,1,1),name='soft_zero') # 0.0~0.1\n",
    "\n",
    "ramda = tf.placeholder(tf.float32,name='ramda') # 0.0~0.1\n",
    "\n",
    "G_z = simple_G(z,name='G_z')\n",
    "\n",
    "D_real = simple_D(u +noise, isTrain)\n",
    "D_fake = simple_D(G_z+noise ,isTrain,reuse=True)\n",
    "\n",
    "query_z =  residual_loss_G(latent_z, reuse = True,name ='query_z')\n",
    "\n",
    "\n",
    "discrimination_from_query_z= simple_D(query_z,isTrain=False,reuse=True)\n",
    "\n",
    "feature_u = feature_extractor_D(test_u, reuse = True, name ='feature_y')\n",
    "feature_z = feature_extractor_D(query_z, reuse = True, name ='feature_z')\n",
    "\n",
    "\n",
    "D_real_loss = tf.reduce_mean(-(soft_one*tf.log(D_real + 1e-8) + (1-soft_one)*tf.log(1- D_real + 1e-8)),name = 'D_real_loss')\n",
    "D_fake_loss = tf.reduce_mean(-(soft_zero*tf.log(D_fake + 1e-8) + (1-soft_zero)*tf.log(1 - D_fake + 1e-8)),name = 'D_fake_loss')\n",
    "\n",
    "\n",
    "D_loss =  tf.add(D_real_loss,D_fake_loss,name='D_loss')\n",
    "G_loss =  tf.reduce_mean(-tf.log(D_fake + 1e-8),name='G_loss')\n",
    "\n",
    "residual_loss = tf.reduce_mean(tf.abs(query_z - test_u),axis = (1,2,3), name = 'residual_loss')\n",
    "feature_loss = tf.reduce_mean(tf.abs(feature_u-feature_z),axis = (1,2,3),name = 'feature_loss')\n",
    "discrimination_loss = tf.reduce_mean(-tf.log(discrimination_from_query_z+ 1e-8),name = 'discrimination_loss')\n",
    "\n",
    "\n",
    "mapping_loss = tf.add((1-ramda)*residual_loss, ramda*feature_loss,name = 'mapping_loss') \n",
    "\n",
    "T_vars = tf.trainable_variables()\n",
    "D_vars = [var for var in T_vars if var.name.startswith('D')]\n",
    "G_vars = [var for var in T_vars if var.name.startswith('G')]\n",
    "    # When using the batchnormalization layers,\n",
    "    # it is necessary to manually add the update operations\n",
    "    # because the moving averages are not included in the graph\n",
    "\n",
    "with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)) :        \n",
    "    D_optim = tf.train.AdamOptimizer(0.001,beta1=0.5).minimize(D_loss, var_list=D_vars, name='D_optim') \n",
    "    G_optim = tf.train.AdamOptimizer(0.001,beta1=0.5).minimize(G_loss, var_list=G_vars, name='G_optim')\n",
    "    \n",
    "grad_z = tf.gradients(mapping_loss, latent_z, name ='grad_z')\n",
    "print(grad_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D_e : 2.591442, D_real_e : 0.845602, D_fake_e : 1.745840, G_e : 18.417387\n",
      "D_e : 9.579892, D_real_e : 3.499685, D_fake_e : 6.150091, G_e : 9.588696\n",
      "D_e : 6.523324, D_real_e : 1.754813, D_fake_e : 1.681376, G_e : 6.818246\n",
      "D_e : 5.235751, D_real_e : 1.352307, D_fake_e : 1.295423, G_e : 5.290993\n",
      "D_e : 4.509069, D_real_e : 1.190465, D_fake_e : 1.131295, G_e : 4.432310\n",
      "D_e : 4.036157, D_real_e : 1.052113, D_fake_e : 1.087663, G_e : 3.897573\n",
      "D_e : 3.698044, D_real_e : 1.019021, D_fake_e : 0.985077, G_e : 3.530277\n",
      "D_e : 3.452210, D_real_e : 0.989050, D_fake_e : 0.985705, G_e : 3.262070\n",
      "D_e : 3.257141, D_real_e : 0.947567, D_fake_e : 0.942132, G_e : 3.055889\n",
      "D_e : 3.102889, D_real_e : 0.946593, D_fake_e : 0.920735, G_e : 2.890675\n",
      "D_e : 2.975569, D_real_e : 0.916478, D_fake_e : 0.911947, G_e : 2.755398\n",
      "D_e : 2.865843, D_real_e : 0.894117, D_fake_e : 0.873363, G_e : 2.642398\n",
      "D_e : 2.762482, D_real_e : 0.818331, D_fake_e : 0.806145, G_e : 2.535531\n",
      "D_e : 2.681235, D_real_e : 0.862243, D_fake_e : 0.843222, G_e : 2.451939\n",
      "D_e : 2.611295, D_real_e : 0.863879, D_fake_e : 0.837498, G_e : 2.376928\n",
      "D_e : 2.542868, D_real_e : 0.799497, D_fake_e : 0.784706, G_e : 2.301250\n",
      "D_e : 2.482353, D_real_e : 0.787892, D_fake_e : 0.786131, G_e : 2.237018\n",
      "D_e : 2.431192, D_real_e : 0.803742, D_fake_e : 0.808355, G_e : 2.175417\n",
      "D_e : 2.384271, D_real_e : 0.800040, D_fake_e : 0.786114, G_e : 2.119054\n",
      "D_e : 2.340564, D_real_e : 0.782034, D_fake_e : 0.771376, G_e : 2.066484\n",
      "D_e : 2.299461, D_real_e : 0.763600, D_fake_e : 0.754487, G_e : 2.015435\n",
      "D_e : 2.263691, D_real_e : 0.777187, D_fake_e : 0.770734, G_e : 1.971294\n",
      "D_e : 2.230866, D_real_e : 0.772323, D_fake_e : 0.768893, G_e : 1.930400\n",
      "D_e : 2.202829, D_real_e : 0.792494, D_fake_e : 0.793233, G_e : 1.893957\n",
      "D_e : 2.173707, D_real_e : 0.752158, D_fake_e : 0.751457, G_e : 1.856098\n",
      "D_e : 2.147528, D_real_e : 0.763614, D_fake_e : 0.755360, G_e : 1.820145\n",
      "D_e : 2.122914, D_real_e : 0.758236, D_fake_e : 0.749094, G_e : 1.787043\n",
      "D_e : 2.102064, D_real_e : 0.781893, D_fake_e : 0.777855, G_e : 1.758164\n",
      "D_e : 2.080884, D_real_e : 0.754068, D_fake_e : 0.754729, G_e : 1.728379\n",
      "D_e : 2.060002, D_real_e : 0.740269, D_fake_e : 0.734837, G_e : 1.700270\n",
      "D_e : 2.042578, D_real_e : 0.768238, D_fake_e : 0.768865, G_e : 1.675350\n",
      "D_e : 2.025155, D_real_e : 0.752958, D_fake_e : 0.749328, G_e : 1.650671\n",
      "D_e : 2.009287, D_real_e : 0.759859, D_fake_e : 0.757365, G_e : 1.627770\n",
      "D_e : 1.993727, D_real_e : 0.745306, D_fake_e : 0.750355, G_e : 1.604905\n",
      "D_e : 1.980277, D_real_e : 0.773052, D_fake_e : 0.763224, G_e : 1.585514\n",
      "D_e : 1.966621, D_real_e : 0.753467, D_fake_e : 0.748719, G_e : 1.565810\n",
      "D_e : 1.954561, D_real_e : 0.768008, D_fake_e : 0.764351, G_e : 1.548334\n",
      "D_e : 1.942721, D_real_e : 0.760064, D_fake_e : 0.756308, G_e : 1.530198\n",
      "D_e : 1.930800, D_real_e : 0.745595, D_fake_e : 0.743997, G_e : 1.513666\n",
      "D_e : 1.919597, D_real_e : 0.745096, D_fake_e : 0.748676, G_e : 1.497462\n",
      "D_e : 1.907902, D_real_e : 0.725875, D_fake_e : 0.725778, G_e : 1.482340\n",
      "D_e : 1.898378, D_real_e : 0.762865, D_fake_e : 0.754448, G_e : 1.468127\n",
      "D_e : 1.888651, D_real_e : 0.745139, D_fake_e : 0.744614, G_e : 1.453414\n",
      "D_e : 1.878905, D_real_e : 0.737987, D_fake_e : 0.731518, G_e : 1.439634\n",
      "D_e : 1.869780, D_real_e : 0.735863, D_fake_e : 0.741429, G_e : 1.427120\n",
      "D_e : 1.861191, D_real_e : 0.741514, D_fake_e : 0.741698, G_e : 1.413955\n",
      "D_e : 1.853089, D_real_e : 0.747543, D_fake_e : 0.740875, G_e : 1.401326\n",
      "D_e : 1.845536, D_real_e : 0.745771, D_fake_e : 0.752228, G_e : 1.389991\n",
      "D_e : 1.837410, D_real_e : 0.727651, D_fake_e : 0.727739, G_e : 1.378130\n",
      "D_e : 1.830052, D_real_e : 0.738092, D_fake_e : 0.738755, G_e : 1.367154\n",
      "D_e : 1.822693, D_real_e : 0.730344, D_fake_e : 0.731673, G_e : 1.356225\n",
      "D_e : 1.815708, D_real_e : 0.734225, D_fake_e : 0.732172, G_e : 1.345801\n",
      "D_e : 1.809220, D_real_e : 0.737780, D_fake_e : 0.740484, G_e : 1.336294\n",
      "D_e : 1.802624, D_real_e : 0.734664, D_fake_e : 0.724893, G_e : 1.326836\n",
      "D_e : 1.796331, D_real_e : 0.733732, D_fake_e : 0.728973, G_e : 1.317504\n",
      "D_e : 1.790235, D_real_e : 0.731498, D_fake_e : 0.729481, G_e : 1.308251\n",
      "D_e : 1.784380, D_real_e : 0.731067, D_fake_e : 0.731294, G_e : 1.299416\n",
      "D_e : 1.778587, D_real_e : 0.725920, D_fake_e : 0.728190, G_e : 1.290453\n",
      "D_e : 1.773579, D_real_e : 0.748739, D_fake_e : 0.739333, G_e : 1.282635\n",
      "D_e : 1.767913, D_real_e : 0.719995, D_fake_e : 0.719224, G_e : 1.274008\n",
      "D_e : 1.762955, D_real_e : 0.735024, D_fake_e : 0.735343, G_e : 1.267214\n",
      "D_e : 1.757641, D_real_e : 0.723875, D_fake_e : 0.714890, G_e : 1.259623\n",
      "D_e : 1.752626, D_real_e : 0.725284, D_fake_e : 0.721381, G_e : 1.251938\n",
      "D_e : 1.747361, D_real_e : 0.708830, D_fake_e : 0.712058, G_e : 1.244475\n",
      "D_e : 1.742487, D_real_e : 0.719339, D_fake_e : 0.715997, G_e : 1.237349\n",
      "D_e : 1.737698, D_real_e : 0.717171, D_fake_e : 0.714032, G_e : 1.230251\n",
      "D_e : 1.733186, D_real_e : 0.720621, D_fake_e : 0.719186, G_e : 1.223562\n",
      "D_e : 1.728632, D_real_e : 0.714010, D_fake_e : 0.714038, G_e : 1.216715\n",
      "D_e : 1.724211, D_real_e : 0.715244, D_fake_e : 0.712676, G_e : 1.210747\n",
      "D_e : 1.719697, D_real_e : 0.708149, D_fake_e : 0.704612, G_e : 1.204002\n",
      "D_e : 1.715390, D_real_e : 0.709403, D_fake_e : 0.708732, G_e : 1.197673\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))) as sess :\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    np.random.seed(int(time.time()))\n",
    "\n",
    "    test_z = np.random.normal(0,1,size=(16,1,1,z_size))\n",
    "\n",
    "    \n",
    "    log_txt = open(file_name +'/log.txt','w')\n",
    "\n",
    "    hist_G = []\n",
    "    hist_D = []\n",
    "    G_error = []\n",
    "    D_error = []\n",
    "    D_fake_error = []\n",
    "    D_real_error = []\n",
    "    \n",
    "    start = time.time()\n",
    "    for i in range(50000) :\n",
    "        \n",
    "        train_images = my_mnist_train_batch(100) \n",
    "        u_ = np.reshape(train_images,(-1,28,28,1)) \n",
    "        z_ = np.random.normal(0,1,size=(100,1,1,z_size))\n",
    "        noise_ = np.random.normal(0,0.1,size=(100,28,28,1))\n",
    "        zeros_ = np.zeros([100,28,28,1])\n",
    "        soft_one_ = np.random.uniform(0.9,1.0,(100,1,1,1))\n",
    "        soft_zero_ = np.random.uniform(0.0,0.1,(100,1,1,1))\n",
    "        \n",
    "        _ , D_e,D_real_e,D_fake_e = sess.run([D_optim, D_loss,D_real_loss,D_fake_loss], {u : u_, z : z_, isTrain : True,\n",
    "                                                                                         noise : noise_, soft_one : soft_one_, soft_zero : soft_zero_})\n",
    "        D_error.append(D_e)\n",
    "        D_real_error.append(D_real_e)\n",
    "        D_fake_error.append(D_fake_e)\n",
    "\n",
    "\n",
    "    #    train_images,train_labels = mnist.train.next_batch(100)    \n",
    "    #    u_ = np.reshape(train_images,(-1,28,28,1)) \n",
    "    #    z_ = np.random.normal(0,1,size=(100,1,1,100))\n",
    "   \n",
    "        _ , G_e = sess.run([G_optim, G_loss], {u : u_, z : z_,noise : zeros_, isTrain : True}) \n",
    "        G_error.append(G_e)\n",
    "        \n",
    "        if i%100 == 0:\n",
    "\n",
    "            hist_D.append(np.mean(D_error)) \n",
    "            hist_G.append(np.mean(G_error))\n",
    "\n",
    "            print('D_e : %.6f, D_real_e : %.6f, D_fake_e : %.6f, G_e : %.6f'%(np.mean(D_error), np.mean(D_real_error),\n",
    "                np.mean(D_fake_error), np.mean(G_error)))\n",
    "            log_txt.write('D_e : %.6f, D_real_e : %.6f, D_fake_e : %.6f, G_e : %.6f\\n'%(np.mean(D_error),\n",
    "                np.mean(D_real_error), np.mean(D_fake_error), np.mean(G_error)))\n",
    "      \n",
    "            r = sess.run([G_z],feed_dict={z : test_z, isTrain : False})        \n",
    "            mnist_4by4_save(np.reshape(r,(-1,28,28,1)),file_name + '/result_{}.png'.format(str(i).zfill(3)))\n",
    "\n",
    "            np.random.seed(int(time.time()))\n",
    "\n",
    "            G_errer = []\n",
    "            D_errer = []\n",
    "            D_fake_error = []\n",
    "            D_real_error = []\n",
    "\n",
    "\n",
    "    log_txt.close()\n",
    "    gan_loss_graph_save(G_loss = hist_G,D_loss=hist_D,path = file_name + '/loss_graph.png')   \n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess,file_name + '/para.cktp')\n",
    "\n",
    "    end = time.time()-start\n",
    "\n",
    "    print(\"total time : \",end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ex_anoGANs_4/para.cktp\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if not os.path.isdir(file_name) :\n",
    "    os.mkdir(file_name)\n",
    "\n",
    "    \n",
    "sess = tf.InteractiveSession()\n",
    "    \n",
    "new_saver = tf.train.import_meta_graph(file_name + '/para.cktp.meta')\n",
    "new_saver.restore(sess, tf.train.latest_checkpoint(file_name + '/'))\n",
    "\n",
    "\n",
    "z = sess.graph.get_tensor_by_name(\"z:0\")\n",
    "u = sess.graph.get_tensor_by_name(\"u:0\")\n",
    "\n",
    "noise = sess.graph.get_tensor_by_name(\"noise:0\")\n",
    "\n",
    "test_u = sess.graph.get_tensor_by_name(\"test_u:0\")\n",
    "latent_z = sess.graph.get_tensor_by_name(\"latent_z:0\")\n",
    "\n",
    "isTrain = sess.graph.get_tensor_by_name(\"isTrain:0\")\n",
    "\n",
    "soft_one =sess.graph.get_tensor_by_name(\"soft_one:0\") # 0.9~1.0\n",
    "soft_zero = sess.graph.get_tensor_by_name(\"soft_zero:0\") # 0.0~0.1\n",
    "\n",
    "ramda = sess.graph.get_tensor_by_name(\"ramda:0\")\n",
    "\n",
    "G_z = sess.graph.get_tensor_by_name(\"G_z:0\")\n",
    "query_z = sess.graph.get_tensor_by_name(\"query_z:0\")\n",
    "\n",
    "\n",
    "feature_u = sess.graph.get_tensor_by_name('feature_y:0')\n",
    "feature_z = sess.graph.get_tensor_by_name('feature_z:0')\n",
    "\n",
    "D_real_loss = sess.graph.get_tensor_by_name('D_real_loss:0')\n",
    "D_fake_loss = sess.graph.get_tensor_by_name('D_fake_loss:0')\n",
    "\n",
    "D_loss = sess.graph.get_tensor_by_name(\"D_loss:0\")\n",
    "G_loss = sess.graph.get_tensor_by_name(\"G_loss:0\")\n",
    "\n",
    "residual_loss = sess.graph.get_tensor_by_name(\"residual_loss:0\")\n",
    "feature_loss = sess.graph.get_tensor_by_name(\"feature_loss:0\")\n",
    "discrimination_loss = sess.graph.get_tensor_by_name(\"discrimination_loss:0\")\n",
    "mapping_loss = sess.graph.get_tensor_by_name(\"mapping_loss:0\")\n",
    "\n",
    "D_optim = sess.graph.get_operation_by_name(\"D_optim\")\n",
    "G_optim = sess.graph.get_operation_by_name(\"G_optim\")\n",
    "\n",
    "grad_z =  sess.graph.get_tensor_by_name(\"grad_z/G_1/conv2d_transpose/conv2d_transpose_grad/Conv2D:0\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAADjJJREFUeJzt3X+MVfWZx/HPI9KIAw4OuJOJwIIN0TRoZDOaNSELZlfCmpqx/mFq1GBsOlU6yTZZk1Wr2SGbNWQtrmtIasCSwtqVNtEGUjbbdnGj09g0DqQFf9DiEpBBhA5TKf5Ehmf/mDPbAed+z3Dvuffc8Xm/ksnce557znly4TPn3Ps9937N3QUgngvKbgBAOQg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgLmzkzsyMywmBOnN3m8jjajrym9kKM/utmb1lZg/Wsi0AjWXVXttvZlMk/U7STZIGJL0q6Q53fyOxDkd+oM4aceS/XtJb7r7f3U9J2iKpq4btAWigWsJ/uaRDY+4PZMvOYmbdZtZvZv017AtAwer+hp+7r5e0XuK0H2gmtRz5D0uaO+b+nGwZgEmglvC/KmmhmS0wsy9I+qqkbcW0BaDeqj7td/fTZtYj6aeSpkja6O6vF9YZgLqqeqivqp3xmh+ou4Zc5ANg8iL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gqKqn6JYkMzsg6aSkYUmn3b2ziKYA1F9N4c/c6O6DBWwHQANx2g8EVWv4XdLPzGynmXUX0RCAxqj1tH+Jux82sz+T9HMz2+vuL499QPZHgT8MQJMxdy9mQ2a9kt539+8kHlPMzgBU5O42kcdVfdpvZi1mNmP0tqTlkl6rdnsAGquW0/52ST82s9Ht/Ie7/1chXQGou8JO+ye0syY+7e/r60vW33vvvYq1q666Krnu0NBQVT2NamtrS9Y//fTTirVPPvkkuW5/f3+y/tRTTyXre/fuTdZTvaE+6n7aD2ByI/xAUIQfCIrwA0ERfiAowg8EFWaob//+/cn63Llzk/UpU6YU2c5ZhoeHa9p3av28f98LL6ztCu8nn3wyWV+3bl3FWt6/CarDUB+AJMIPBEX4gaAIPxAU4QeCIvxAUIQfCCrMOP/q1auT9YceeihZT41Jb9++Pbnuvn37kvWtW7cm611dXcn6Sy+9VLH29ttvJ9e9++67k/Xu7vQ3sC1atChZz77vYVxXXHFFct1Dhw4l6xgf4/wAkgg/EBThB4Ii/EBQhB8IivADQRF+IKgw4/x5Zs2alayfOHGiYu306dNFt9M0Wltbk/WBgYFkvaWlpWJt8+bNyXXvueeeZB3jY5wfQBLhB4Ii/EBQhB8IivADQRF+ICjCDwSV+6XtZrZR0pclHXP3RdmyNkk/lDRf0gFJt7v7H+rXZv0dP3687BbqIu87/1etWpWs9/b2Juupcfw8e/bsqXpd1G4iR/7vS1pxzrIHJe1w94WSdmT3AUwiueF395clDZ2zuEvSpuz2Jkm3FtwXgDqr9jV/u7sfyW6/K6m9oH4ANEhtE7VJcndPXbNvZt2S0l8EB6Dhqj3yHzWzDknKfh+r9EB3X+/une7eWeW+ANRBteHfJmlldnulpPTXzwJoOrnhN7PnJP1S0pVmNmBmX5O0RtJNZrZP0t9k9wFMInye/3Ng2bJlFWv33ntvct277rqr4G7O9thjj1WsPfLII3Xdd1R8nh9AEuEHgiL8QFCEHwiK8ANBEX4gqJov70Xt5s2bl6w//fTTyfry5csr1i64oLa/788++2yy/sADDyTrg4ODNe0f9cORHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeC4iO9DbB48eJkva+vL1m/+OKLi2znvAwNnfvdrWfbu3dvsn7q1KmKtauvvjq57rp165L11atXJ+tR8ZFeAEmEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4/wN0NramqznfV7/sssuS9bfeeedirWDBw8m173hhhuSdbP0kPGSJUuS9alTpybrKalrBCRp//79yfqLL75YsdbT01NVT5MB4/wAkgg/EBThB4Ii/EBQhB8IivADQRF+IKjccX4z2yjpy5KOufuibFmvpK9L+n32sIfd/T9zdxZ0nB/ju+2225L1O++8M1lfunRpsj5r1qyKtS1btiTXzZuvYPv27cl6mYoc5/++pBXjLP9Xd782+8kNPoDmkht+d39ZUvrrXABMOrW85u8xs91mttHMLi2sIwANUW34vyvpi5KulXRE0tpKDzSzbjPrN7P+KvcFoA6qCr+7H3X3YXc/I2mDpOsTj13v7p3u3lltkwCKV1X4zaxjzN2vSHqtmHYANEruFN1m9pykZZJmm9mApH+UtMzMrpXkkg5I+kYdewRQB3yefxLI+z6ANWvWVKz19vYm1z169Gg1LTWF9vb2ZH3jxo0VaytWjDd6/ScnT55M1mfOnJmsl4nP8wNIIvxAUIQfCIrwA0ERfiAowg8ExVBfE5g2bVqyvmvXrmR9+vTpFWtXXnllct0PP/wwWf+8euaZZ5L1lStXJusbNmxI1letWnXePRWFoT4ASYQfCIrwA0ERfiAowg8ERfiBoAg/EFTu5/lRfzNmzEjW88bqH3300Yq1qOP4kjRv3ryKtbxpz6dMmZKs33jjjVX11Ew48gNBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIzzN4Frrrmm7BYmpY6OjmS9p6enYu2WW25Jrjs8PJys532efzLgyA8ERfiBoAg/EBThB4Ii/EBQhB8IivADQeWO85vZXEmbJbVLcknr3f3fzKxN0g8lzZd0QNLt7v6H+rX6+bV79+6a1r/uuusq1lpaWpLrfvDBB8n61KlTk/UzZ84k65dccknV277//vuT9fvuuy9ZT03hndf3zp07k/UnnngiWZ8MJnLkPy3p7939S5L+UtI3zexLkh6UtMPdF0rakd0HMEnkht/dj7j7ruz2SUlvSrpcUpekTdnDNkm6tV5NAijeeb3mN7P5khZL+pWkdnc/kpXe1cjLAgCTxISv7Tez6ZKel/Qtd/+j2Z+mA3N3rzQPn5l1S+qutVEAxZrQkd/Mpmok+D9w9xeyxUfNrCOrd0g6Nt667r7e3TvdvbOIhgEUIzf8NnKI/56kN9197Fuc2ySNTmW6UtLW4tsDUC+5U3Sb2RJJfZL2SBodH3lYI6/7fyRpnqSDGhnqG8rZFlN0j6O1tTVZz5uie8GCBRVrx48fT6576NChZH3mzJnJ+kcffZSsp3q76KKLkuvWU19fX7K+dOnSBnVSvIlO0Z37mt/dfyGp0sb++nyaAtA8uMIPCIrwA0ERfiAowg8ERfiBoAg/EFTuOH+hO2Ocvyp500U//vjjFWtdXV3JdfOuMWhra0vWazE4OJisDwwMJOtr1qxJ1hcuXFixtnbt2uS6H3/8cbLezCY6zs+RHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCYpw/uLzP68+ZMydZnz17drI+bdq0irVXXnklue6JEyeSdYyPcX4ASYQfCIrwA0ERfiAowg8ERfiBoAg/EBTj/MDnDOP8AJIIPxAU4QeCIvxAUIQfCIrwA0ERfiCo3PCb2Vwz+x8ze8PMXjezv8uW95rZYTP7dfZzc/3bBVCU3It8zKxDUoe77zKzGZJ2SrpV0u2S3nf370x4Z1zkA9TdRC/yuXACGzoi6Uh2+6SZvSnp8traA1C283rNb2bzJS2W9KtsUY+Z7TazjWZ2aYV1us2s38z6a+oUQKEmfG2/mU2X9JKkf3b3F8ysXdKgJJf0Txp5aXBvzjY47QfqbKKn/RMKv5lNlfQTST919yfGqc+X9BN3X5SzHcIP1FlhH+wxM5P0PUlvjg1+9kbgqK9Ieu18mwRQnom8279EUp+kPZLOZIsflnSHpGs1ctp/QNI3sjcHU9viyA/UWaGn/UUh/ED98Xl+AEmEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoHK/wLNgg5IOjrk/O1vWjJq1t2btS6K3ahXZ259P9IEN/Tz/Z3Zu1u/unaU1kNCsvTVrXxK9Vaus3jjtB4Ii/EBQZYd/fcn7T2nW3pq1L4neqlVKb6W+5gdQnrKP/ABKUkr4zWyFmf3WzN4yswfL6KESMztgZnuymYdLnWIsmwbtmJm9NmZZm5n93Mz2Zb/HnSatpN6aYubmxMzSpT53zTbjdcNP+81siqTfSbpJ0oCkVyXd4e5vNLSRCszsgKROdy99TNjM/krS+5I2j86GZGb/ImnI3ddkfzgvdfd/aJLeenWeMzfXqbdKM0vfoxKfuyJnvC5CGUf+6yW95e773f2UpC2Sukroo+m5+8uShs5Z3CVpU3Z7k0b+8zRchd6agrsfcfdd2e2TkkZnli71uUv0VYoywn+5pENj7g+ouab8dkk/M7OdZtZddjPjaB8zM9K7ktrLbGYcuTM3N9I5M0s3zXNXzYzXReMNv89a4u5/IelvJX0zO71tSj7ymq2Zhmu+K+mLGpnG7YiktWU2k80s/bykb7n7H8fWynzuxumrlOetjPAfljR3zP052bKm4O6Hs9/HJP1YIy9TmsnR0UlSs9/HSu7n/7n7UXcfdvczkjaoxOcum1n6eUk/cPcXssWlP3fj9VXW81ZG+F+VtNDMFpjZFyR9VdK2Evr4DDNryd6IkZm1SFqu5pt9eJukldntlZK2ltjLWZpl5uZKM0ur5Oeu6Wa8dveG/0i6WSPv+P+vpG+X0UOFvq6Q9Jvs5/Wye5P0nEZOAz/VyHsjX5M0S9IOSfsk/bektibq7d81Mpvzbo0EraOk3pZo5JR+t6RfZz83l/3cJfoq5XnjCj8gKN7wA4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8Q1P8BdTqlIWtsnZ4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe104c8af28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe104c8d908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAELVJREFUeJzt3X2MVFWax/HfIyAiiMgqSBgUnYBmYuIbMb6FjO5qxIzgS2I0JrAyLCpDonETF93ExWw2TtbVjYlK0ioKm1mcTdRIzGZnXEUUsxkBMysiOqKCQwMiQR0m0mJ3P/tHXzYtcp/T1Nut5nw/Saer6qlTdbjVP25VnXvuMXcXgPwcVXUHAFSD8AOZIvxApgg/kCnCD2SK8AOZIvxApgg/kCnCD2RqaCufzMw4nBBoMne3gdyvrj2/mV1lZh+a2WYzW1TPYwFoLav12H4zGyLpD5KukLRN0lpJN7v7+0Eb9vxAk7Viz3+BpM3u/om775f0nKRZdTwegBaqJ/wTJf2x3/VtxW3fY2bzzWydma2r47kANFjTv/Bz9w5JHRJv+4F2Us+ev1PSpH7Xf1TcBmAQqCf8ayVNMbPTzOxoSTdJWtmYbgFotprf9rt7t5ktlPQbSUMkLXX3jQ3rGYBDGjVqVGntm2++GfDj1DzUVws+8wP1S4W/p6en+Qf5ABi8CD+QKcIPZIrwA5ki/ECmCD+QqZbO5wdQv66urtJab2/vgB+HPT+QKcIPZIrwA5ki/ECmCD+QKcIPZIqhviPAkCFDSmvDhw8P20bDRtLhDR2hNXp6ehryOOz5gUwRfiBThB/IFOEHMkX4gUwRfiBThB/IFOP8g0A0ji/FY/ntPI4/cuTIsP7VV1+F9Y8//jisn3nmmYfdpwPM4hPgtvKs1weL/h66u7sH/Djs+YFMEX4gU4QfyBThBzJF+IFMEX4gU4QfyFRd4/xmtkXSXkk9krrdfVojOjXYpMaEjzoq/j82NdZeT/uq5+NH22bVqlVh26FD4z/P0aNHh/VoPDw1J77KcfyURs3nb8RBPpe5++4GPA6AFuJtP5CpesPvkn5rZuvNbH4jOgSgNep923+pu3ea2ThJr5jZB+7+Rv87FP8p8B8D0Gbq2vO7e2fxe5ekFyVdcIj7dLj7tFy/DATaVc3hN7ORZnbcgcuSrpT0XqM6BqC56nnbP17Si8VQzlBJ/+7u/9WQXgFouprD7+6fSDq7gX2p1Jo1a8L6l19+WVpLzRvfvTseCU0dJzB27NiwHs3h3r9/f9h23bp1Yf3RRx8N6x988EFYP/vs8j+R888/P2ybsmnTprDeqPHwdhP9vRzO8QkM9QGZIvxApgg/kCnCD2SK8AOZIvxApqyVUxfNrLJ5kp9++mlYnzRpUliPpofWuw1TQ1KpU3fXM6V32LBhYT3l4YcfDuuXXXZZaS0aBpTSpx0/44wzwnpnZ2dYP1K5ezx2XGDPD2SK8AOZIvxApgg/kCnCD2SK8AOZIvxAptpqie7U1NZIaqx9+fLlYf3ee+8N65s3by6tvfTSS2HbDz/8MKy//PLLYX3mzJlhPZqO/Nlnn4VtZ8+eHdbnz4/PwLZjx46wPm1a+QmcUktwL1iwIKxv3749rB+pmNILoC6EH8gU4QcyRfiBTBF+IFOEH8gU4Qcy1Vbz+VNzy6N57/UuRZ06PfbXX39dWkstoZ3axs08xXS9r+/RRx8d1keOHBnW9+3bV1qbNWtW2Hb16tVhfefOnWH9SHXssceW1rq6utTT08N8fgDlCD+QKcIPZIrwA5ki/ECmCD+QKcIPZCo5n9/Mlkr6maRd7n5WcdtYSb+WNFnSFkk3unv5GtYDFC013Wx79uypuW1qLD11noKhQ+OXIXUcQPT8qWMQbrvttrA+efLksL5o0aKwHj1/amnz1HkSmin1mrXy+JiDpV7TAT/OAO7zrKSrDrptkaRX3X2KpFeL6wAGkWT43f0NSQfvFmdJWlZcXibp2gb3C0CT1fr+Yby7Hzh/005J4xvUHwAtUvc5/Nzdo2P2zWy+pPhEcABartY9/+dmNkGSit+7yu7o7h3uPs3dy8/kCKDlag3/SklzistzJFX3tSyAmiTDb2YrJP2PpDPMbJuZ/VzSLyVdYWYfSfqr4jqAQaTl8/mjMcp6xrvrnROfGtetZ02BlCFDhoT11L/tkksuKa3NnTs3bHvTTTeF9RkzZoT1119/PaxH6yVMnTo1bBv9u6T0donmve/fvz9smzq3RHSegmYbMWJEaa2rq0u9vb3M5wdQjvADmSL8QKYIP5Apwg9kivADmWr5Et31TD+NhnbqHaqrZ1puqt+p01+PGjUqrD/11FNh/corryytpYYRU1OZL7744rCeWl48GlJLDfWlhvJSr2k9w3GpYecqp/w2apiRPT+QKcIPZIrwA5ki/ECmCD+QKcIPZIrwA5lqq3H+b7/9NmwbjafXezrj1LhsPeO2p556alhfu3ZtWI+mpkrx8uSpsfIlS5aE9eeeey6sf/HFF2H92WefLa1t3749bPvYY4+F9QceeCCs1zMNu6urq+a2gwV7fiBThB/IFOEHMkX4gUwRfiBThB/IFOEHMtXyU3c38bHral/PfP7UnPnU3PDUeHZqmezOzs7S2vr168O2u3fvDuvDhw8P66njAN56663S2rnnnhu2TR33sXnz5rD+2muvldbuuuuusG3quJHo2IqB1JvJ3Tl1N4ByhB/IFOEHMkX4gUwRfiBThB/IFOEHMpUc5zezpZJ+JmmXu59V3LZY0t9IOjCZ+z53/8/kkyXG+esZq69nnL4R7euROm//3r17w3rUt8cffzxsO2/evJofW5K2bt0a1qdMmVJau+6668K2t9xyS1ifPn16WD/xxBNLaytWrAjbPvPMM2F91apVYb27uzusN1Mjx/mflXTVIW7/V3c/p/hJBh9Ae0mG393fkBQv6wJg0KnnM/9CM3vXzJaa2QkN6xGAlqg1/Esk/VjSOZJ2SHq47I5mNt/M1pnZuhqfC0AT1BR+d//c3XvcvVfSk5IuCO7b4e7T3H1arZ0E0Hg1hd/MJvS7ep2k9xrTHQCtkjx1t5mtkPRTSSea2TZJ/yDpp2Z2jiSXtEXSbU3sI4AmaKv5/Kl58VFfU/Onm7meerPPJXDccceF9blz55bWUvPWTzrppLCeOn/9/fffH9afeOKJsF6PcePGhfVorH7GjBlh29SxFWPGjAnrzcxVdK6B3t5e5vMDiBF+IFOEH8gU4QcyRfiBTBF+IFNtNdRX7+mSB6sRI0aE9dTpt2+99dbS2urVq8O2qdOKb9y4MaynTr/drq/Z008/HdZnz54d1p988smwvmDBgsPu00Ax1AegLoQfyBThBzJF+IFMEX4gU4QfyBThBzKVnM/fSu06JtxsxxxzTFgfO3ZsWL/zzjtLa6lx/JSlS5eG9XZ+zU455ZTSWmoqc2q7XX755TX1qRGiqe+Hc9wOe34gU4QfyBThBzJF+IFMEX4gU4QfyBThBzLVVuP8uUqNOd99991h/frrry+tpcZ9Ozs7w/qSJUvCepVOPvnksL5w4cLS2jXXXBO27enpCesdHR1hvZkatVw8e34gU4QfyBThBzJF+IFMEX4gU4QfyBThBzKVHOc3s0mSlksaL8kldbj7o2Y2VtKvJU2WtEXSje7+ZfO6euSaOnVqWF+5cmVYnzBhQmntoosuCtvec889YT01Xz+1rPro0aNLa8OGDQvb3nHHHWH99ttvD+vRcQCpcfzUWgmPPPJIWG+m7u7u0lqj5/N3S/pbd/+JpAsl/cLMfiJpkaRX3X2KpFeL6wAGiWT43X2Hu79TXN4raZOkiZJmSVpW3G2ZpGub1UkAjXdYn/nNbLKkcyX9TtJ4d99RlHaq72MBgEFiwMf2m9koSc9Lusvd/9T/+GJ397J1+MxsvqT59XYUQGMNaM9vZsPUF/xfufsLxc2fm9mEoj5B0q5DtXX3Dnef5u7TGtFhAI2RDL/17eKflrTJ3ft/xblS0pzi8hxJLzW+ewCaJblEt5ldKulNSRskHRj3uU99n/v/Q9Ipkraqb6hvT+KxWrce+CDyyiuvhPV58+aF9d27d5fWbrjhhrBtdNpvKX3a8H379oX10047rbSWOmV5M7355pthffr06S3qSeMNdInu5Gd+d18jqezB/vJwOgWgfXCEH5Apwg9kivADmSL8QKYIP5Apwg9kKjnO39Any3Scf8yYMWF969atYT2awilJixcvLq3NnDkzbHveeeeF9dQ4fz2i4xMkadu2bWH9wQcfDOtTpkwprT300ENh2/3794f1djbQcX72/ECmCD+QKcIPZIrwA5ki/ECmCD+QKcIPZIpx/gZILZl8+umnh/W33347rKfmvV944YWltQ0bNoRtjz/++LA+ceLEsD5u3LiwPmLEiNLamjVrwrZ79+4N682Uek1bmZvDxTg/gBDhBzJF+IFMEX4gU4QfyBThBzJF+IFMMc4PHGEY5wcQIvxApgg/kCnCD2SK8AOZIvxApgg/kKlk+M1skpmtMrP3zWyjmd1Z3L7YzDrN7PfFz9XN7y6ARkke5GNmEyRNcPd3zOw4SeslXSvpRkl/dvd/GfCTcZAP0HQDPchn6AAeaIekHcXlvWa2SVJ8ehcAbe+wPvOb2WRJ50r6XXHTQjN718yWmtkJJW3mm9k6M1tXV08BNNSAj+03s1GSVkv6J3d/wczGS9otySX9o/o+GsxNPAZv+4EmG+jb/gGF38yGSXpZ0m/c/ZFD1CdLetndz0o8DuEHmqxhE3us7zSmT0va1D/4xReBB1wn6b3D7SSA6gzk2/5LJb0paYOk3uLm+yTdLOkc9b3t3yLptuLLweix2PMDTdbQt/2NQviB5mM+P4AQ4QcyRfiBTBF+IFOEH8gU4QcylZzY00rDhg0L6999912LegIc+djzA5ki/ECmCD+QKcIPZIrwA5ki/ECmCD+QqVaP8++WtLXf9ROL2yS13Tj+9/rWRtq1XxJ9q1Uj+3bqQO/Y0vn8P3hys3XuPq2yDgTatW/t2i+JvtWqqr7xth/IFOEHMlV1+Dsqfv5Iu/atXfsl0bdaVdK3Sj/zA6hO1Xt+ABWpJPxmdpWZfWhmm81sURV9KGNmW8xsQ7HycKVLjBXLoO0ys/f63TbWzF4xs4+K34dcJq2ivrXFys3BytKVbrt2W/G65W/7zWyIpD9IukLSNklrJd3s7u+3tCMlzGyLpGnuXvmYsJlNl/RnScsPrIZkZv8saY+7/7L4j/MEd/+7NunbYh3mys1N6lvZytJ/rQq3XSNXvG6EKvb8F0ja7O6fuPt+Sc9JmlVBP9qeu78hac9BN8+StKy4vEx9fzwtV9K3tuDuO9z9neLyXkkHVpaudNsF/apEFeGfKOmP/a5vU3st+e2Sfmtm681sftWdOYTx/VZG2ilpfJWdOYTkys2tdNDK0m2z7WpZ8brR+MLvhy519/MkzZD0i+LtbVvyvs9s7TRcs0TSj9W3jNsOSQ9X2ZliZennJd3l7n/qX6ty2x2iX5VstyrC3ylpUr/rPypuawvu3ln83iXpRfV9TGknnx9YJLX4vavi/vw/d//c3XvcvVfSk6pw2xUrSz8v6Vfu/kJxc+Xb7lD9qmq7VRH+tZKmmNlpZna0pJskraygHz9gZiOLL2JkZiMlXan2W314paQ5xeU5kl6qsC/f0y4rN5etLK2Kt13brXjt7i3/kXS1+r7x/1jS31fRh5J+nS7pf4ufjVX3TdIK9b0N/E593438XNJfSHpV0keS/lvS2Dbq27+pbzXnd9UXtAkV9e1S9b2lf1fS74ufq6vedkG/KtluHOEHZIov/IBMEX4gU4QfyBThBzJF+IFMEX4gU4QfyBThBzL1f5HPxDvneZIiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe102c397f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.75918102] [ 26.28343964] [ 0.1453744]\n",
      "[ 2.75918102] [ 26.28343964] [ 0.1453744]\n",
      "[ 2.61479044] [ 24.94898415] [ 0.13321316]\n",
      "[ 2.60355163] [ 24.84417152] [ 0.13237169]\n",
      "[ 2.59604168] [ 24.77354813] [ 0.13187449]\n",
      "[ 2.58679628] [ 24.68047333] [ 0.13194314]\n",
      "[ 2.57595921] [ 24.57143974] [ 0.13201699]\n",
      "[ 2.56860805] [ 24.50211334] [ 0.13155183]\n",
      "[ 2.56241608] [ 24.44916344] [ 0.130555]\n",
      "[ 2.55495572] [ 24.38205338] [ 0.12972239]\n",
      "[ 2.55042386] [ 24.33951569] [ 0.12941362]\n",
      "[ 2.5471642] [ 24.30867004] [ 0.12921907]\n",
      "[ 2.54445124] [ 24.28365707] [ 0.12898393]\n",
      "[ 2.54216218] [ 24.26272583] [ 0.12876607]\n",
      "[ 2.54006839] [ 24.24382973] [ 0.12853934]\n",
      "[ 2.53807759] [ 24.22541046] [ 0.12837391]\n",
      "[ 2.5362227] [ 24.20853043] [ 0.12818833]\n",
      "[ 2.53446484] [ 24.19249725] [ 0.12801665]\n",
      "[ 2.53272367] [ 24.17677307] [ 0.12782906]\n",
      "[ 2.53093958] [ 24.16080666] [ 0.12762105]\n",
      "[ 2.52913737] [ 24.14459229] [ 0.12742005]\n",
      "[ 2.52750897] [ 24.12914085] [ 0.12732771]\n",
      "[ 2.52539968] [ 24.11091805] [ 0.12700884]\n",
      "[ 2.52326965] [ 24.09207916] [ 0.12673503]\n",
      "[ 2.52078319] [ 24.07013321] [ 0.12641092]\n",
      "[ 2.5182035] [ 24.04509544] [ 0.12632667]\n",
      "[ 2.51569271] [ 24.022892] [ 0.12600397]\n",
      "[ 2.51368642] [ 24.00391769] [ 0.12588286]\n",
      "[ 2.51184154] [ 23.98682594] [ 0.12573205]\n",
      "[ 2.51062346] [ 23.9735775] [ 0.12585078]\n",
      "[ 2.50858831] [ 23.95561981] [ 0.12558492]\n",
      "[ 2.50715613] [ 23.94216537] [ 0.12548836]\n",
      "[ 2.50579906] [ 23.93006516] [ 0.1253249]\n",
      "[ 2.50451159] [ 23.91778946] [ 0.12525859]\n",
      "[ 2.50323367] [ 23.90605545] [ 0.1251422]\n",
      "[ 2.50213218] [ 23.89486313] [ 0.12516199]\n",
      "[ 2.50085878] [ 23.88408279] [ 0.12494479]\n",
      "[ 2.49993944] [ 23.87460518] [ 0.12497653]\n",
      "[ 2.49865556] [ 23.86346054] [ 0.12478831]\n",
      "[ 2.49770927] [ 23.85407829] [ 0.12477923]\n",
      "[ 2.49665618] [ 23.8445549] [ 0.12466751]\n",
      "[ 2.49568439] [ 23.83586884] [ 0.12455288]\n",
      "[ 2.49477315] [ 23.82707024] [ 0.12451791]\n",
      "[ 2.49385834] [ 23.81946945] [ 0.12434587]\n",
      "[ 2.49306369] [ 23.81159973] [ 0.12433732]\n"
     ]
    }
   ],
   "source": [
    "####\n",
    "test_batch = 1\n",
    "ramda_ = 0.1\n",
    "z_size = 100\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "\n",
    "#latent_z_ = np.random.normal(0,1,size=(test_batch,1,1,z_size))\n",
    "latent_z_ = np.random.uniform(-1.0,1.0,(test_batch,1,1,z_size))\n",
    "####\n",
    "\n",
    "\n",
    "im = my_mnist_test_batch(test_batch, number = 3) \n",
    "plt.imshow(np.reshape(im,(28, 28)), cmap='Greys_r')\n",
    "plt.show()\n",
    "    \n",
    "\n",
    "im_fake = sess.run([query_z],{latent_z : latent_z_}) \n",
    "plt.imshow(np.reshape(im_fake,(28, 28)), cmap='Greys_r')\n",
    "plt.show()\n",
    "\n",
    "ano_gap  = np.abs(np.reshape(im_fake,(28, 28)) - np.reshape(im,(28, 28)))\n",
    "plt.imshow(ano_gap, cmap='Greys_r')\n",
    "plt.show()  \n",
    "\n",
    "\n",
    "############################################\n",
    "\n",
    "\n",
    "#latent_z_ = np.random.normal(0,1,size=(test_batch,1,1,z_size))\n",
    "map_loss, fea_loss, res_loss = sess.run([mapping_loss, feature_loss,residual_loss], \n",
    "                                        {test_u : np.reshape(im,(1,28, 28,1)), latent_z : latent_z_, ramda : ramda_ })\n",
    "adam_m = np.zeros((test_batch,1,1,z_size))\n",
    "adam_v = np.zeros((test_batch,1,1,z_size))\n",
    "beta1 = 0.1\n",
    "beta2 = 0.999\n",
    "lr = 0.001\n",
    "beta1_t = beta1\n",
    "beta2_t = beta2\n",
    "\n",
    "print(map_loss, fea_loss, res_loss)\n",
    "\n",
    "for i in range(5000) :\n",
    "     \n",
    "    grad,map_loss, fea_loss, res_loss = sess.run([grad_z,mapping_loss, feature_loss,residual_loss],\n",
    "                                                 {test_u : np.reshape(im,(-1,28, 28,1)), latent_z : latent_z_, ramda : ramda_ })\n",
    "    \n",
    "    lr_t = lr*np.sqrt(1-beta2_t)/(1-beta1_t)\n",
    "    adam_m = beta1*adam_m + (1-beta1)*grad\n",
    "    adam_v = beta2*adam_v + (1-beta2)*grad*grad\n",
    "    latent_z_ = latent_z_ - lr*adam_m/(np.sqrt(adam_v)+1e-8)\n",
    "    beta1_t = beta1_t*beta1\n",
    "    beta2_t = beta2_t*beta2\n",
    "    \n",
    "    if  i % 100 == 0 : \n",
    "        print(map_loss, fea_loss, res_loss)\n",
    "        \n",
    "###########################################        \n",
    "plt.imshow(np.reshape(im,(28, 28)), cmap='Greys_r')\n",
    "plt.show()\n",
    "    \n",
    "\n",
    "im_fake = sess.run([query_z],{latent_z : latent_z_}) \n",
    "plt.imshow(np.reshape(im_fake,(28, 28)), cmap='Greys_r')\n",
    "plt.show()\n",
    "\n",
    "ano_gap  = np.abs(np.reshape(im_fake,(28, 28)) - np.reshape(im,(28, 28)))\n",
    "plt.imshow(ano_gap, cmap='Greys_r')\n",
    "plt.show()  \n",
    "\n",
    "map_loss, fea_loss, res_loss = sess.run([mapping_loss, feature_loss,residual_loss], \n",
    "                                        {test_u : np.reshape(im,(-1,28, 28,1)), latent_z : latent_z_, ramda : ramda_ })\n",
    "\n",
    "\n",
    "print(map_loss, fea_loss, res_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 : [ 1.26591396] [ 12.19823456] [ 0.05121164]\n",
    "\n",
    "1 : [ 0.40030429] [ 3.88526249] [ 0.01308668]\n",
    "\n",
    "2 : [ 0.71741045] [ 6.90383625] [ 0.03002984]\n",
    "\n",
    "3 : [ 0.67283332] [ 6.48380566] [ 0.02716969]\n",
    "\n",
    "4 : [ 0.58003438] [ 5.63718367] [ 0.01812886]\n",
    "\n",
    "5 : 0.3318850, 2.439910, 0.0976591\n",
    "\n",
    "6 : 0.2591080, 2.049630, 0.0601610\n",
    "\n",
    "7 : 0.4255990, 3.156960, 0.122114\n",
    "\n",
    "8 : 0.1010440, 0.703177, 0.0341403\n",
    "\n",
    "9 : 0.0975575, 0.704314, 0.0301401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 26.99393654  22.59328461  25.50518227] [ 26.99393654  22.59328461  25.50518227] [ 0.16063157  0.18925853  0.18590234]\n",
      "[ 26.99393654  22.5932827   25.50518227] [ 26.99393654  22.5932827   25.50518227] [ 0.16063155  0.18925853  0.18590233]\n",
      "[ 17.52194214  21.63160706  25.06342888] [ 17.52194214  21.63160706  25.06342888] [ 0.09651834  0.18894972  0.17890891]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-8f129c9e62f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     grad,map_loss, fea_loss, res_loss = sess.run([grad_z,mapping_loss, feature_loss,residual_loss],\n\u001b[0;32m---> 29\u001b[0;31m                                                  {test_u : np.reshape(im,(-1,28, 28,1)), latent_z : latent_z_, ramda : ramda_ })\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mlr_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbeta2_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbeta1_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "####\n",
    "test_batch = 3\n",
    "latent_z_ = np.random.normal(0,1,size=(test_batch,1,1,z_size))\n",
    "####\n",
    "\n",
    "im = my_mnist_test_batch(test_batch, number = 5) \n",
    "\n",
    "\n",
    "############################################\n",
    "\n",
    "ramda_ = 1.0\n",
    "z_size = 100\n",
    "#latent_z_ = np.random.normal(0,1,size=(test_batch,1,1,z_size))\n",
    "map_loss, fea_loss, res_loss = sess.run([mapping_loss, feature_loss,residual_loss], \n",
    "                                        {test_u : np.reshape(im,(-1,28, 28,1)), latent_z : latent_z_, ramda : ramda_ })\n",
    "adam_m = np.zeros((test_batch,1,1,z_size))\n",
    "adam_v = np.zeros((test_batch,1,1,z_size))\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999\n",
    "lr = 0.001\n",
    "beta1_t = beta1\n",
    "beta2_t = beta2\n",
    "\n",
    "print(map_loss, fea_loss, res_loss)\n",
    "\n",
    "for i in range(1000) :\n",
    "     \n",
    "    grad,map_loss, fea_loss, res_loss = sess.run([grad_z,mapping_loss, feature_loss,residual_loss],\n",
    "                                                 {test_u : np.reshape(im,(-1,28, 28,1)), latent_z : latent_z_, ramda : ramda_ })\n",
    "    \n",
    "    lr_t = lr*np.sqrt(1-beta2_t)/(1-beta1_t)\n",
    "    adam_m = beta1*adam_m + (1-beta1)*grad\n",
    "    adam_v = beta2*adam_v + (1-beta2)*grad*grad\n",
    "    latent_z_ = latent_z_ - lr*adam_m/(np.sqrt(adam_v)+1e-8)\n",
    "    beta1_t = beta1_t*beta1\n",
    "    beta2_t = beta2_t*beta2\n",
    "    \n",
    "    if  i % 100 == 0 : \n",
    "        print(map_loss, fea_loss, res_loss)\n",
    "        \n",
    "###########################################        \n",
    "\n",
    "    \n",
    "\n",
    "map_loss, fea_loss, res_loss = sess.run([mapping_loss, feature_loss,residual_loss], \n",
    "                                        {test_u : np.reshape(im,(-1,28, 28,1)), latent_z : latent_z_, ramda : ramda_ })\n",
    "\n",
    "print('ddd')\n",
    "print(map_loss, fea_loss, res_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.reshape(im[2],(28,28)), cmap='Greys_r')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_fake = sess.run([query_z],{latent_z : latent_z_[2].reshape(1,1,1,100)}) \n",
    "plt.imshow(np.reshape(im_fake,(28, 28)), cmap='Greys_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_z_[0].reshape(1,1,1,100).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122,
   "position": {
    "height": "40px",
    "left": "1010px",
    "right": "20px",
    "top": "120px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
