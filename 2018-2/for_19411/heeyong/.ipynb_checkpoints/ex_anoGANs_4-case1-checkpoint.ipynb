{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add some tips\n",
    "\n",
    "https://medium.com/@utk.is.here/keep-calm-and-train-a-gan-pitfalls-and-tips-on-training-generative-adversarial-networks-edd529764aa9\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     28,
     42,
     61
    ]
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec \n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "def my_mnist_train_batch(size) :\n",
    "    m = 500\n",
    "    data = []\n",
    "    for i in range(1000) :\n",
    "        number = number = np.random.randint(5)\n",
    "        image, label = mnist.train.next_batch(m)       \n",
    "        for j in range(len(label)) : \n",
    "            \n",
    "            if np.argmax(label[j])==number :\n",
    "                data.append(image[j])\n",
    "                number = number = np.random.randint(5)\n",
    "            if len(data) == size :\n",
    "                break\n",
    "        if len(data) == size :\n",
    "            break\n",
    "    return data\n",
    "\n",
    "def my_mnist_test_batch(size, number = 0) :\n",
    "    m = 500\n",
    "    data = []\n",
    "    for i in range(1000) :\n",
    "        image, label = mnist.test.next_batch(m)       \n",
    "        for j in range(len(label)) : \n",
    "            if np.argmax(label[j])==number :\n",
    "                data.append(image[j])              \n",
    "            if len(data) == size :\n",
    "                break\n",
    "        if len(data) == size :\n",
    "            break\n",
    "    return data\n",
    "\n",
    "def mnist_4by4_save(samples,path):\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    gs = gridspec.GridSpec(4, 4)    \n",
    "    gs.update(wspace=0.05, hspace=0.05) #이미지 사이간격 조절\n",
    "  \n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')    \n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "   \n",
    "        plt.imshow(sample.reshape(28, 28), cmap='Greys_r',clim=(0.0,1.0))\n",
    "    plt.colorbar()\n",
    "    plt.savefig(path, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "   \n",
    "    return None\n",
    "\n",
    "def gan_loss_graph_save(G_loss,D_loss,path):\n",
    "    x1 = range(len(G_loss))\n",
    "    x2 = range(len(D_loss))\n",
    "      \n",
    "    y1 = G_loss\n",
    "    y2 = D_loss\n",
    "  \n",
    "      \n",
    "    plt.plot(x1,y1,label='G_loss') \n",
    "    plt.plot(x2,y2,label='D_loss') \n",
    "  \n",
    "    plt.xlabel('weight per update')\n",
    "    plt.ylabel('loss')             \n",
    "    plt.legend(loc=4)              \n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "  \n",
    "    plt.savefig(path)              \n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     7,
     44
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"../MNIST_data\", one_hot=True)\n",
    "\n",
    "file_name = 'ex_anoGANs_4'\n",
    "\n",
    "if not os.path.isdir(file_name) :\n",
    "    os.mkdir(file_name)\n",
    "def simple_G(x,isTrain = True, reuse = False, name = 'G_out') : #input = (minibatch * w * h * ch)\n",
    "    \n",
    "    # out size = (in size + 2*padding - kenel)/strides + 1    \n",
    "    w_init = tf.truncated_normal_initializer(mean= 0.0, stddev=0.02)\n",
    "    b_init = tf.constant_initializer(0.0)\n",
    "\n",
    "\n",
    "    with tf.variable_scope('G',reuse=reuse)  :\n",
    "        \n",
    "        #x = (-1, 1, 1, 100)\n",
    "\n",
    "        conv1 = tf.layers.conv2d_transpose(x,2048,[4,4], strides=(1,1),padding = 'valid',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init) \n",
    "        r1 = tf.nn.elu(tf.layers.batch_normalization(conv1,training=isTrain))#1024*4*4\n",
    "        \n",
    "        conv2 = tf.layers.conv2d_transpose(r1,1024,[4,4], strides=(2,2),padding = 'same',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r2 = tf.nn.elu(tf.layers.batch_normalization(conv2,training=isTrain))#512*8*8\n",
    "                \n",
    "        conv3 = tf.layers.conv2d_transpose(r2,512,[4,4], strides=(2,2),padding = 'same',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r3 = tf.nn.elu(tf.layers.batch_normalization(conv3,training=isTrain))#256*16*16\n",
    "\n",
    "        conv4 = tf.layers.conv2d_transpose(r3,256,[4,4], strides=(2,2),padding = 'same',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r4 = tf.nn.elu(tf.layers.batch_normalization(conv4,training=isTrain))#128*32*32\n",
    "\n",
    "        conv5 = tf.layers.conv2d(r4,128,[3,3], strides=(1,1),padding = 'valid',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r5 = tf.nn.elu(tf.layers.batch_normalization(conv5,training=isTrain))#64*30*30\n",
    "\n",
    "        conv6 = tf.layers.conv2d(r5,1,[3,3], strides=(1,1),padding = 'valid',\n",
    "                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "    r6 = tf.nn.sigmoid(conv6,name=name)#1*28*28\n",
    "  \n",
    "\n",
    "    return r6\n",
    "def residual_loss_G(x,isTrain = False, reuse = True, name = 'residual_loss_out') : #input = (minibatch * w * h * ch)\n",
    "    \n",
    "    # out size = (in size + 2*padding - kenel)/strides + 1    \n",
    "\n",
    "\n",
    "    with tf.variable_scope('G',reuse=reuse) as scope :\n",
    "        scope.reuse_variables()\n",
    "        #x = (-1, 1, 1, 100)\n",
    "\n",
    "\n",
    "        conv1 = tf.layers.conv2d_transpose(x,2048,[4,4], strides=(1,1),padding = 'valid')\n",
    "        r1 = tf.nn.elu(tf.layers.batch_normalization(conv1,training=isTrain))#1024*4*4\n",
    "        \n",
    "        conv2 = tf.layers.conv2d_transpose(r1,1024,[4,4], strides=(2,2),padding = 'same')\n",
    "        r2 = tf.nn.elu(tf.layers.batch_normalization(conv2,training=isTrain))#512*8*8\n",
    "                \n",
    "        conv3 = tf.layers.conv2d_transpose(r2,512,[4,4], strides=(2,2),padding = 'same')\n",
    "        r3 = tf.nn.elu(tf.layers.batch_normalization(conv3,training=isTrain))#256*16*16\n",
    "\n",
    "        conv4 = tf.layers.conv2d_transpose(r3,256,[4,4], strides=(2,2),padding = 'same')\n",
    "        r4 = tf.nn.elu(tf.layers.batch_normalization(conv4,training=isTrain))#128*32*32\n",
    "\n",
    "        conv5 = tf.layers.conv2d(r4,128,[3,3], strides=(1,1),padding = 'valid')\n",
    "        r5 = tf.nn.elu(tf.layers.batch_normalization(conv5,training=isTrain))#64*30*30\n",
    "\n",
    "        conv6 = tf.layers.conv2d(r5,1,[3,3], strides=(1,1),padding = 'valid')\n",
    "    r6 = tf.nn.sigmoid(conv6,name=name)#1*28*28\n",
    "  \n",
    "\n",
    "    return r6\n",
    "def simple_D(x,isTrain=True,reuse = False) :\n",
    "    \n",
    "    w_init = tf.truncated_normal_initializer(mean= 0.0, stddev=0.02)\n",
    "    b_init = tf.constant_initializer(0.0)\n",
    "    with tf.variable_scope('D', reuse=reuse) :\n",
    "        \n",
    "        #x = (-1,28,28,1)\n",
    "        # out size = (in size + 2*padding - kenel)/strides + 1   \n",
    "\n",
    "        conv1 = tf.layers.conv2d(x,128,[5,5], strides=(1,1),padding = 'valid',\n",
    "                                kernel_initializer=w_init, bias_initializer=b_init) \n",
    "        r1 = tf.nn.elu(conv1)#64*24*24\n",
    "\n",
    "   \n",
    "        conv2 = tf.layers.conv2d(r1,256,[5,5], strides=(1,1),padding = 'valid',\n",
    "                                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r2 = tf.nn.elu(tf.layers.batch_normalization(conv2,training=isTrain))#128*20*20\n",
    "\n",
    "  \n",
    "        conv3 = tf.layers.conv2d(r2,512,[5,5], strides=(1,1),padding = 'valid',\n",
    "                                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r3 = tf.nn.elu(tf.layers.batch_normalization(conv3,training=isTrain))#256*16*16\n",
    "\n",
    " \n",
    "        conv4 = tf.layers.conv2d(r3,1024,[4,4], strides=(2,2),padding = 'same',\n",
    "                                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r4 = tf.nn.elu(tf.layers.batch_normalization(conv4,training=isTrain))#512*8*8\n",
    "\n",
    "\n",
    "        conv5 = tf.layers.conv2d(r4,2048,[4,4], strides=(2,2),padding = 'same',\n",
    "                                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "        r5 = tf.nn.elu(tf.layers.batch_normalization(conv5,training=isTrain))#1024*4*4\n",
    "\n",
    "       \n",
    "        conv6 = tf.layers.conv2d(r5,1,[4,4], strides=(1,1),padding = 'valid',\n",
    "                                kernel_initializer=w_init, bias_initializer=b_init)\n",
    "    r6 = tf.nn.sigmoid(conv6)#1*1*1\n",
    "\n",
    "\n",
    "    return r6\n",
    "def feature_extractor_D(x,isTrain=False,reuse = True, name='feature_out') :\n",
    "    \n",
    "    with tf.variable_scope('D', reuse=reuse) as scope :\n",
    "        scope.reuse_variables()\n",
    "        #x = (-1,28,28,1)\n",
    "\n",
    "        conv1 = tf.layers.conv2d(x,128,[5,5], strides=(1,1),padding = 'valid')\n",
    "        r1 = tf.nn.elu(conv1)#64*24*24\n",
    "\n",
    "   \n",
    "        conv2 = tf.layers.conv2d(r1,256,[5,5], strides=(1,1),padding = 'valid')\n",
    "        r2 = tf.nn.elu(tf.layers.batch_normalization(conv2,training=isTrain))#128*20*20\n",
    "\n",
    "  \n",
    "        conv3 = tf.layers.conv2d(r2,512,[5,5], strides=(1,1),padding = 'valid')\n",
    "    r3 = tf.nn.elu(tf.layers.batch_normalization(conv3,training=isTrain),name = name)#256*16*16\n",
    "\n",
    " \n",
    "        #conv4 = tf.layers.conv2d(r3,1024,[4,4], strides=(2,2),padding = 'same')\n",
    "        #r4 = tf.nn.lrelu(tf.layers.batch_normalization(conv4,training=isTrain),0.2)#512*8*8\n",
    "\n",
    "\n",
    "        #conv5 = tf.layers.conv2d(r4,2048,[4,4], strides=(2,2),padding = 'same')\n",
    "        #r5 = tf.nn.lrelu(tf.layers.batch_normalization(conv5,training=isTrain),0.2)#1024*4*4\n",
    "\n",
    "\n",
    "    return r3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'grad_z/G_1/conv2d_transpose/conv2d_transpose_grad/Conv2D:0' shape=(?, 1, 1, 100) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "\n",
    "z_size = 100\n",
    "\n",
    "\n",
    "z = tf.placeholder(tf.float32,shape=(None,1,1,z_size),name = 'z')    \n",
    "u = tf.placeholder(tf.float32, shape = (None, 28,28,1),name='u')\n",
    "\n",
    "noise = tf.placeholder(tf.float32, shape = (None, 28,28,1),name='noise')\n",
    "\n",
    "test_u = tf.placeholder(tf.float32, shape = (None, 28,28,1),name='test_u')\n",
    "latent_z = tf.placeholder(tf.float32,shape=(None,1,1,z_size),name = 'latent_z')    \n",
    "\n",
    "isTrain = tf.placeholder(dtype=tf.bool,name='isTrain') \n",
    "\n",
    "soft_one = tf.placeholder(tf.float32, shape = (None, 1,1,1),name='soft_one') # 0.9~1.0\n",
    "soft_zero = tf.placeholder(tf.float32, shape = (None, 1,1,1),name='soft_zero') # 0.0~0.1\n",
    "\n",
    "ramda = tf.placeholder(tf.float32,name='ramda') # 0.0~0.1\n",
    "\n",
    "G_z = simple_G(z,name='G_z')\n",
    "\n",
    "D_real = simple_D(u +noise, isTrain)\n",
    "D_fake = simple_D(G_z+noise ,isTrain,reuse=True)\n",
    "\n",
    "query_z =  residual_loss_G(latent_z, reuse = True,name ='query_z')\n",
    "\n",
    "\n",
    "discrimination_from_query_z= simple_D(query_z,isTrain=False,reuse=True)\n",
    "\n",
    "feature_u = feature_extractor_D(test_u, reuse = True, name ='feature_y')\n",
    "feature_z = feature_extractor_D(query_z, reuse = True, name ='feature_z')\n",
    "\n",
    "\n",
    "D_real_loss = tf.reduce_mean(-(soft_one*tf.log(D_real + 1e-8) + (1-soft_one)*tf.log(1- D_real + 1e-8)),name = 'D_real_loss')\n",
    "D_fake_loss = tf.reduce_mean(-(soft_zero*tf.log(D_fake + 1e-8) + (1-soft_zero)*tf.log(1 - D_fake + 1e-8)),name = 'D_fake_loss')\n",
    "\n",
    "\n",
    "D_loss =  tf.add(D_real_loss,D_fake_loss,name='D_loss')\n",
    "G_loss =  tf.reduce_mean(-tf.log(D_fake + 1e-8),name='G_loss')\n",
    "\n",
    "residual_loss = tf.reduce_mean(tf.abs(query_z - test_u),axis = (1,2,3), name = 'residual_loss')\n",
    "feature_loss = tf.reduce_mean(tf.abs(feature_u-feature_z),axis = (1,2,3),name = 'feature_loss')\n",
    "discrimination_loss = tf.reduce_mean(-tf.log(discrimination_from_query_z+ 1e-8),name = 'discrimination_loss')\n",
    "\n",
    "\n",
    "mapping_loss = tf.add((1-ramda)*residual_loss, ramda*feature_loss,name = 'mapping_loss') \n",
    "\n",
    "T_vars = tf.trainable_variables()\n",
    "D_vars = [var for var in T_vars if var.name.startswith('D')]\n",
    "G_vars = [var for var in T_vars if var.name.startswith('G')]\n",
    "    # When using the batchnormalization layers,\n",
    "    # it is necessary to manually add the update operations\n",
    "    # because the moving averages are not included in the graph\n",
    "\n",
    "with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)) :        \n",
    "    D_optim = tf.train.AdamOptimizer(0.001,beta1=0.5).minimize(D_loss, var_list=D_vars, name='D_optim') \n",
    "    G_optim = tf.train.AdamOptimizer(0.001,beta1=0.5).minimize(G_loss, var_list=G_vars, name='G_optim')\n",
    "    \n",
    "grad_z = tf.gradients(mapping_loss, latent_z, name ='grad_z')\n",
    "print(grad_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D_e : 2.591442, D_real_e : 0.845602, D_fake_e : 1.745840, G_e : 18.417387\n",
      "D_e : 9.579892, D_real_e : 3.499685, D_fake_e : 6.150091, G_e : 9.588696\n",
      "D_e : 6.523324, D_real_e : 1.754813, D_fake_e : 1.681376, G_e : 6.818246\n",
      "D_e : 5.235751, D_real_e : 1.352307, D_fake_e : 1.295423, G_e : 5.290993\n",
      "D_e : 4.509069, D_real_e : 1.190465, D_fake_e : 1.131295, G_e : 4.432310\n",
      "D_e : 4.036157, D_real_e : 1.052113, D_fake_e : 1.087663, G_e : 3.897573\n",
      "D_e : 3.698044, D_real_e : 1.019021, D_fake_e : 0.985077, G_e : 3.530277\n",
      "D_e : 3.452210, D_real_e : 0.989050, D_fake_e : 0.985705, G_e : 3.262070\n",
      "D_e : 3.257141, D_real_e : 0.947567, D_fake_e : 0.942132, G_e : 3.055889\n",
      "D_e : 3.102889, D_real_e : 0.946593, D_fake_e : 0.920735, G_e : 2.890675\n",
      "D_e : 2.975569, D_real_e : 0.916478, D_fake_e : 0.911947, G_e : 2.755398\n",
      "D_e : 2.865843, D_real_e : 0.894117, D_fake_e : 0.873363, G_e : 2.642398\n",
      "D_e : 2.762482, D_real_e : 0.818331, D_fake_e : 0.806145, G_e : 2.535531\n",
      "D_e : 2.681235, D_real_e : 0.862243, D_fake_e : 0.843222, G_e : 2.451939\n",
      "D_e : 2.611295, D_real_e : 0.863879, D_fake_e : 0.837498, G_e : 2.376928\n",
      "D_e : 2.542868, D_real_e : 0.799497, D_fake_e : 0.784706, G_e : 2.301250\n",
      "D_e : 2.482353, D_real_e : 0.787892, D_fake_e : 0.786131, G_e : 2.237018\n",
      "D_e : 2.431192, D_real_e : 0.803742, D_fake_e : 0.808355, G_e : 2.175417\n",
      "D_e : 2.384271, D_real_e : 0.800040, D_fake_e : 0.786114, G_e : 2.119054\n",
      "D_e : 2.340564, D_real_e : 0.782034, D_fake_e : 0.771376, G_e : 2.066484\n",
      "D_e : 2.299461, D_real_e : 0.763600, D_fake_e : 0.754487, G_e : 2.015435\n",
      "D_e : 2.263691, D_real_e : 0.777187, D_fake_e : 0.770734, G_e : 1.971294\n",
      "D_e : 2.230866, D_real_e : 0.772323, D_fake_e : 0.768893, G_e : 1.930400\n",
      "D_e : 2.202829, D_real_e : 0.792494, D_fake_e : 0.793233, G_e : 1.893957\n",
      "D_e : 2.173707, D_real_e : 0.752158, D_fake_e : 0.751457, G_e : 1.856098\n",
      "D_e : 2.147528, D_real_e : 0.763614, D_fake_e : 0.755360, G_e : 1.820145\n",
      "D_e : 2.122914, D_real_e : 0.758236, D_fake_e : 0.749094, G_e : 1.787043\n",
      "D_e : 2.102064, D_real_e : 0.781893, D_fake_e : 0.777855, G_e : 1.758164\n",
      "D_e : 2.080884, D_real_e : 0.754068, D_fake_e : 0.754729, G_e : 1.728379\n",
      "D_e : 2.060002, D_real_e : 0.740269, D_fake_e : 0.734837, G_e : 1.700270\n",
      "D_e : 2.042578, D_real_e : 0.768238, D_fake_e : 0.768865, G_e : 1.675350\n",
      "D_e : 2.025155, D_real_e : 0.752958, D_fake_e : 0.749328, G_e : 1.650671\n",
      "D_e : 2.009287, D_real_e : 0.759859, D_fake_e : 0.757365, G_e : 1.627770\n",
      "D_e : 1.993727, D_real_e : 0.745306, D_fake_e : 0.750355, G_e : 1.604905\n",
      "D_e : 1.980277, D_real_e : 0.773052, D_fake_e : 0.763224, G_e : 1.585514\n",
      "D_e : 1.966621, D_real_e : 0.753467, D_fake_e : 0.748719, G_e : 1.565810\n",
      "D_e : 1.954561, D_real_e : 0.768008, D_fake_e : 0.764351, G_e : 1.548334\n",
      "D_e : 1.942721, D_real_e : 0.760064, D_fake_e : 0.756308, G_e : 1.530198\n",
      "D_e : 1.930800, D_real_e : 0.745595, D_fake_e : 0.743997, G_e : 1.513666\n",
      "D_e : 1.919597, D_real_e : 0.745096, D_fake_e : 0.748676, G_e : 1.497462\n",
      "D_e : 1.907902, D_real_e : 0.725875, D_fake_e : 0.725778, G_e : 1.482340\n",
      "D_e : 1.898378, D_real_e : 0.762865, D_fake_e : 0.754448, G_e : 1.468127\n",
      "D_e : 1.888651, D_real_e : 0.745139, D_fake_e : 0.744614, G_e : 1.453414\n",
      "D_e : 1.878905, D_real_e : 0.737987, D_fake_e : 0.731518, G_e : 1.439634\n",
      "D_e : 1.869780, D_real_e : 0.735863, D_fake_e : 0.741429, G_e : 1.427120\n",
      "D_e : 1.861191, D_real_e : 0.741514, D_fake_e : 0.741698, G_e : 1.413955\n",
      "D_e : 1.853089, D_real_e : 0.747543, D_fake_e : 0.740875, G_e : 1.401326\n",
      "D_e : 1.845536, D_real_e : 0.745771, D_fake_e : 0.752228, G_e : 1.389991\n",
      "D_e : 1.837410, D_real_e : 0.727651, D_fake_e : 0.727739, G_e : 1.378130\n",
      "D_e : 1.830052, D_real_e : 0.738092, D_fake_e : 0.738755, G_e : 1.367154\n",
      "D_e : 1.822693, D_real_e : 0.730344, D_fake_e : 0.731673, G_e : 1.356225\n",
      "D_e : 1.815708, D_real_e : 0.734225, D_fake_e : 0.732172, G_e : 1.345801\n",
      "D_e : 1.809220, D_real_e : 0.737780, D_fake_e : 0.740484, G_e : 1.336294\n",
      "D_e : 1.802624, D_real_e : 0.734664, D_fake_e : 0.724893, G_e : 1.326836\n",
      "D_e : 1.796331, D_real_e : 0.733732, D_fake_e : 0.728973, G_e : 1.317504\n",
      "D_e : 1.790235, D_real_e : 0.731498, D_fake_e : 0.729481, G_e : 1.308251\n",
      "D_e : 1.784380, D_real_e : 0.731067, D_fake_e : 0.731294, G_e : 1.299416\n",
      "D_e : 1.778587, D_real_e : 0.725920, D_fake_e : 0.728190, G_e : 1.290453\n",
      "D_e : 1.773579, D_real_e : 0.748739, D_fake_e : 0.739333, G_e : 1.282635\n",
      "D_e : 1.767913, D_real_e : 0.719995, D_fake_e : 0.719224, G_e : 1.274008\n",
      "D_e : 1.762955, D_real_e : 0.735024, D_fake_e : 0.735343, G_e : 1.267214\n",
      "D_e : 1.757641, D_real_e : 0.723875, D_fake_e : 0.714890, G_e : 1.259623\n",
      "D_e : 1.752626, D_real_e : 0.725284, D_fake_e : 0.721381, G_e : 1.251938\n",
      "D_e : 1.747361, D_real_e : 0.708830, D_fake_e : 0.712058, G_e : 1.244475\n",
      "D_e : 1.742487, D_real_e : 0.719339, D_fake_e : 0.715997, G_e : 1.237349\n",
      "D_e : 1.737698, D_real_e : 0.717171, D_fake_e : 0.714032, G_e : 1.230251\n",
      "D_e : 1.733186, D_real_e : 0.720621, D_fake_e : 0.719186, G_e : 1.223562\n",
      "D_e : 1.728632, D_real_e : 0.714010, D_fake_e : 0.714038, G_e : 1.216715\n",
      "D_e : 1.724211, D_real_e : 0.715244, D_fake_e : 0.712676, G_e : 1.210747\n",
      "D_e : 1.719697, D_real_e : 0.708149, D_fake_e : 0.704612, G_e : 1.204002\n",
      "D_e : 1.715390, D_real_e : 0.709403, D_fake_e : 0.708732, G_e : 1.197673\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))) as sess :\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    np.random.seed(int(time.time()))\n",
    "\n",
    "    test_z = np.random.normal(0,1,size=(16,1,1,z_size))\n",
    "\n",
    "    \n",
    "    log_txt = open(file_name +'/log.txt','w')\n",
    "\n",
    "    hist_G = []\n",
    "    hist_D = []\n",
    "    G_error = []\n",
    "    D_error = []\n",
    "    D_fake_error = []\n",
    "    D_real_error = []\n",
    "    \n",
    "    start = time.time()\n",
    "    for i in range(50000) :\n",
    "        \n",
    "        train_images = my_mnist_train_batch(100) \n",
    "        u_ = np.reshape(train_images,(-1,28,28,1)) \n",
    "        z_ = np.random.normal(0,1,size=(100,1,1,z_size))\n",
    "        noise_ = np.random.normal(0,0.1,size=(100,28,28,1))\n",
    "        zeros_ = np.zeros([100,28,28,1])\n",
    "        soft_one_ = np.random.uniform(0.9,1.0,(100,1,1,1))\n",
    "        soft_zero_ = np.random.uniform(0.0,0.1,(100,1,1,1))\n",
    "        \n",
    "        _ , D_e,D_real_e,D_fake_e = sess.run([D_optim, D_loss,D_real_loss,D_fake_loss], {u : u_, z : z_, isTrain : True,\n",
    "                                                                                         noise : noise_, soft_one : soft_one_, soft_zero : soft_zero_})\n",
    "        D_error.append(D_e)\n",
    "        D_real_error.append(D_real_e)\n",
    "        D_fake_error.append(D_fake_e)\n",
    "\n",
    "\n",
    "    #    train_images,train_labels = mnist.train.next_batch(100)    \n",
    "    #    u_ = np.reshape(train_images,(-1,28,28,1)) \n",
    "    #    z_ = np.random.normal(0,1,size=(100,1,1,100))\n",
    "   \n",
    "        _ , G_e = sess.run([G_optim, G_loss], {u : u_, z : z_,noise : zeros_, isTrain : True}) \n",
    "        G_error.append(G_e)\n",
    "        \n",
    "        if i%100 == 0:\n",
    "\n",
    "            hist_D.append(np.mean(D_error)) \n",
    "            hist_G.append(np.mean(G_error))\n",
    "\n",
    "            print('D_e : %.6f, D_real_e : %.6f, D_fake_e : %.6f, G_e : %.6f'%(np.mean(D_error), np.mean(D_real_error),\n",
    "                np.mean(D_fake_error), np.mean(G_error)))\n",
    "            log_txt.write('D_e : %.6f, D_real_e : %.6f, D_fake_e : %.6f, G_e : %.6f\\n'%(np.mean(D_error),\n",
    "                np.mean(D_real_error), np.mean(D_fake_error), np.mean(G_error)))\n",
    "      \n",
    "            r = sess.run([G_z],feed_dict={z : test_z, isTrain : False})        \n",
    "            mnist_4by4_save(np.reshape(r,(-1,28,28,1)),file_name + '/result_{}.png'.format(str(i).zfill(3)))\n",
    "\n",
    "            np.random.seed(int(time.time()))\n",
    "\n",
    "            G_errer = []\n",
    "            D_errer = []\n",
    "            D_fake_error = []\n",
    "            D_real_error = []\n",
    "\n",
    "\n",
    "    log_txt.close()\n",
    "    gan_loss_graph_save(G_loss = hist_G,D_loss=hist_D,path = file_name + '/loss_graph.png')   \n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess,file_name + '/para.cktp')\n",
    "\n",
    "    end = time.time()-start\n",
    "\n",
    "    print(\"total time : \",end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ex_anoGANs_4/para.cktp\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if not os.path.isdir(file_name) :\n",
    "    os.mkdir(file_name)\n",
    "\n",
    "    \n",
    "sess = tf.InteractiveSession()\n",
    "    \n",
    "new_saver = tf.train.import_meta_graph(file_name + '/para.cktp.meta')\n",
    "new_saver.restore(sess, tf.train.latest_checkpoint(file_name + '/'))\n",
    "\n",
    "\n",
    "z = sess.graph.get_tensor_by_name(\"z:0\")\n",
    "u = sess.graph.get_tensor_by_name(\"u:0\")\n",
    "\n",
    "noise = sess.graph.get_tensor_by_name(\"noise:0\")\n",
    "\n",
    "test_u = sess.graph.get_tensor_by_name(\"test_u:0\")\n",
    "latent_z = sess.graph.get_tensor_by_name(\"latent_z:0\")\n",
    "\n",
    "isTrain = sess.graph.get_tensor_by_name(\"isTrain:0\")\n",
    "\n",
    "soft_one =sess.graph.get_tensor_by_name(\"soft_one:0\") # 0.9~1.0\n",
    "soft_zero = sess.graph.get_tensor_by_name(\"soft_zero:0\") # 0.0~0.1\n",
    "\n",
    "ramda = sess.graph.get_tensor_by_name(\"ramda:0\")\n",
    "\n",
    "G_z = sess.graph.get_tensor_by_name(\"G_z:0\")\n",
    "query_z = sess.graph.get_tensor_by_name(\"query_z:0\")\n",
    "\n",
    "\n",
    "feature_u = sess.graph.get_tensor_by_name('feature_y:0')\n",
    "feature_z = sess.graph.get_tensor_by_name('feature_z:0')\n",
    "\n",
    "D_real_loss = sess.graph.get_tensor_by_name('D_real_loss:0')\n",
    "D_fake_loss = sess.graph.get_tensor_by_name('D_fake_loss:0')\n",
    "\n",
    "D_loss = sess.graph.get_tensor_by_name(\"D_loss:0\")\n",
    "G_loss = sess.graph.get_tensor_by_name(\"G_loss:0\")\n",
    "\n",
    "residual_loss = sess.graph.get_tensor_by_name(\"residual_loss:0\")\n",
    "feature_loss = sess.graph.get_tensor_by_name(\"feature_loss:0\")\n",
    "discrimination_loss = sess.graph.get_tensor_by_name(\"discrimination_loss:0\")\n",
    "mapping_loss = sess.graph.get_tensor_by_name(\"mapping_loss:0\")\n",
    "\n",
    "D_optim = sess.graph.get_operation_by_name(\"D_optim\")\n",
    "G_optim = sess.graph.get_operation_by_name(\"G_optim\")\n",
    "\n",
    "grad_z =  sess.graph.get_tensor_by_name(\"grad_z/G_1/conv2d_transpose/conv2d_transpose_grad/Conv2D:0\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe1053c25f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe104e9d240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe104ec1c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.39552879] [ 26.2231369] [ 0.18862659]\n",
      "[ 5.39552879] [ 26.2231369] [ 0.18862656]\n",
      "[ 4.85206699] [ 23.64230728] [ 0.15450642]\n",
      "[ 4.83778] [ 23.57127953] [ 0.15440521]\n",
      "[ 4.82678175] [ 23.51887131] [ 0.15375918]\n",
      "[ 4.81843376] [ 23.48134995] [ 0.15270467]\n",
      "[ 4.81015873] [ 23.44496536] [ 0.15145715]\n",
      "[ 4.80626392] [ 23.42736053] [ 0.15098988]\n",
      "[ 4.80347633] [ 23.41437912] [ 0.15075015]\n",
      "[ 4.80102062] [ 23.40299034] [ 0.15052785]\n",
      "[ 4.79873228] [ 23.39225006] [ 0.15035294]\n",
      "[ 4.79655838] [ 23.38204384] [ 0.15018679]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-c2a8bf762d73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     grad,map_loss, fea_loss, res_loss = sess.run([grad_z,mapping_loss, feature_loss,residual_loss],\n\u001b[0;32m---> 47\u001b[0;31m                                                  {test_u : np.reshape(im,(-1,28, 28,1)), latent_z : latent_z_, ramda : ramda_ })\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mlr_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbeta2_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbeta1_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "####\n",
    "test_batch = 1\n",
    "ramda_ = 0.5\n",
    "z_size = 100\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "\n",
    "#latent_z_ = np.random.normal(0,1,size=(test_batch,1,1,z_size))\n",
    "latent_z_ = np.random.uniform(-1.0,1.0,(test_batch,1,1,z_size))\n",
    "####\n",
    "\n",
    "\n",
    "im = my_mnist_test_batch(test_batch, number = 3) \n",
    "plt.imshow(np.reshape(im,(28, 28)), cmap='Greys_r')\n",
    "plt.show()\n",
    "    \n",
    "\n",
    "im_fake = sess.run([query_z],{latent_z : latent_z_}) \n",
    "plt.imshow(np.reshape(im_fake,(28, 28)), cmap='Greys_r')\n",
    "plt.show()\n",
    "\n",
    "ano_gap  = np.abs(np.reshape(im_fake,(28, 28)) - np.reshape(im,(28, 28)))\n",
    "plt.imshow(ano_gap, cmap='Greys_r')\n",
    "plt.show()  \n",
    "\n",
    "\n",
    "############################################\n",
    "\n",
    "\n",
    "#latent_z_ = np.random.normal(0,1,size=(test_batch,1,1,z_size))\n",
    "map_loss, fea_loss, res_loss = sess.run([mapping_loss, feature_loss,residual_loss], \n",
    "                                        {test_u : np.reshape(im,(1,28, 28,1)), latent_z : latent_z_, ramda : ramda_ })\n",
    "adam_m = np.zeros((test_batch,1,1,z_size))\n",
    "adam_v = np.zeros((test_batch,1,1,z_size))\n",
    "beta1 = 0.1\n",
    "beta2 = 0.999\n",
    "lr = 0.001\n",
    "beta1_t = beta1\n",
    "beta2_t = beta2\n",
    "\n",
    "print(map_loss, fea_loss, res_loss)\n",
    "\n",
    "for i in range(5000) :\n",
    "     \n",
    "    grad,map_loss, fea_loss, res_loss = sess.run([grad_z,mapping_loss, feature_loss,residual_loss],\n",
    "                                                 {test_u : np.reshape(im,(-1,28, 28,1)), latent_z : latent_z_, ramda : ramda_ })\n",
    "    \n",
    "    lr_t = lr*np.sqrt(1-beta2_t)/(1-beta1_t)\n",
    "    adam_m = beta1*adam_m + (1-beta1)*grad\n",
    "    adam_v = beta2*adam_v + (1-beta2)*grad*grad\n",
    "    latent_z_ = latent_z_ - lr*adam_m/(np.sqrt(adam_v)+1e-8)\n",
    "    beta1_t = beta1_t*beta1\n",
    "    beta2_t = beta2_t*beta2\n",
    "    \n",
    "    if  i % 100 == 0 : \n",
    "        print(map_loss, fea_loss, res_loss)\n",
    "        \n",
    "###########################################        \n",
    "plt.imshow(np.reshape(im,(28, 28)), cmap='Greys_r')\n",
    "plt.show()\n",
    "    \n",
    "\n",
    "im_fake = sess.run([query_z],{latent_z : latent_z_}) \n",
    "plt.imshow(np.reshape(im_fake,(28, 28)), cmap='Greys_r')\n",
    "plt.show()\n",
    "\n",
    "ano_gap  = np.abs(np.reshape(im_fake,(28, 28)) - np.reshape(im,(28, 28)))\n",
    "plt.imshow(ano_gap, cmap='Greys_r')\n",
    "plt.show()  \n",
    "\n",
    "map_loss, fea_loss, res_loss = sess.run([mapping_loss, feature_loss,residual_loss], \n",
    "                                        {test_u : np.reshape(im,(-1,28, 28,1)), latent_z : latent_z_, ramda : ramda_ })\n",
    "\n",
    "\n",
    "print(map_loss, fea_loss, res_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 : [ 1.26591396] [ 12.19823456] [ 0.05121164]\n",
    "\n",
    "1 : [ 0.40030429] [ 3.88526249] [ 0.01308668]\n",
    "\n",
    "2 : [ 0.71741045] [ 6.90383625] [ 0.03002984]\n",
    "\n",
    "3 : [ 0.67283332] [ 6.48380566] [ 0.02716969]\n",
    "\n",
    "4 : [ 0.58003438] [ 5.63718367] [ 0.01812886]\n",
    "\n",
    "5 : 0.3318850, 2.439910, 0.0976591\n",
    "\n",
    "6 : 0.2591080, 2.049630, 0.0601610\n",
    "\n",
    "7 : 0.4255990, 3.156960, 0.122114\n",
    "\n",
    "8 : 0.1010440, 0.703177, 0.0341403\n",
    "\n",
    "9 : 0.0975575, 0.704314, 0.0301401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 26.99393654  22.59328461  25.50518227] [ 26.99393654  22.59328461  25.50518227] [ 0.16063157  0.18925853  0.18590234]\n",
      "[ 26.99393654  22.5932827   25.50518227] [ 26.99393654  22.5932827   25.50518227] [ 0.16063155  0.18925853  0.18590233]\n",
      "[ 17.52194214  21.63160706  25.06342888] [ 17.52194214  21.63160706  25.06342888] [ 0.09651834  0.18894972  0.17890891]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-8f129c9e62f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     grad,map_loss, fea_loss, res_loss = sess.run([grad_z,mapping_loss, feature_loss,residual_loss],\n\u001b[0;32m---> 29\u001b[0;31m                                                  {test_u : np.reshape(im,(-1,28, 28,1)), latent_z : latent_z_, ramda : ramda_ })\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mlr_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbeta2_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbeta1_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "####\n",
    "test_batch = 3\n",
    "latent_z_ = np.random.normal(0,1,size=(test_batch,1,1,z_size))\n",
    "####\n",
    "\n",
    "im = my_mnist_test_batch(test_batch, number = 5) \n",
    "\n",
    "\n",
    "############################################\n",
    "\n",
    "ramda_ = 1.0\n",
    "z_size = 100\n",
    "#latent_z_ = np.random.normal(0,1,size=(test_batch,1,1,z_size))\n",
    "map_loss, fea_loss, res_loss = sess.run([mapping_loss, feature_loss,residual_loss], \n",
    "                                        {test_u : np.reshape(im,(-1,28, 28,1)), latent_z : latent_z_, ramda : ramda_ })\n",
    "adam_m = np.zeros((test_batch,1,1,z_size))\n",
    "adam_v = np.zeros((test_batch,1,1,z_size))\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999\n",
    "lr = 0.001\n",
    "beta1_t = beta1\n",
    "beta2_t = beta2\n",
    "\n",
    "print(map_loss, fea_loss, res_loss)\n",
    "\n",
    "for i in range(1000) :\n",
    "     \n",
    "    grad,map_loss, fea_loss, res_loss = sess.run([grad_z,mapping_loss, feature_loss,residual_loss],\n",
    "                                                 {test_u : np.reshape(im,(-1,28, 28,1)), latent_z : latent_z_, ramda : ramda_ })\n",
    "    \n",
    "    lr_t = lr*np.sqrt(1-beta2_t)/(1-beta1_t)\n",
    "    adam_m = beta1*adam_m + (1-beta1)*grad\n",
    "    adam_v = beta2*adam_v + (1-beta2)*grad*grad\n",
    "    latent_z_ = latent_z_ - lr*adam_m/(np.sqrt(adam_v)+1e-8)\n",
    "    beta1_t = beta1_t*beta1\n",
    "    beta2_t = beta2_t*beta2\n",
    "    \n",
    "    if  i % 100 == 0 : \n",
    "        print(map_loss, fea_loss, res_loss)\n",
    "        \n",
    "###########################################        \n",
    "\n",
    "    \n",
    "\n",
    "map_loss, fea_loss, res_loss = sess.run([mapping_loss, feature_loss,residual_loss], \n",
    "                                        {test_u : np.reshape(im,(-1,28, 28,1)), latent_z : latent_z_, ramda : ramda_ })\n",
    "\n",
    "print('ddd')\n",
    "print(map_loss, fea_loss, res_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.reshape(im[2],(28,28)), cmap='Greys_r')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_fake = sess.run([query_z],{latent_z : latent_z_[2].reshape(1,1,1,100)}) \n",
    "plt.imshow(np.reshape(im_fake,(28, 28)), cmap='Greys_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_z_[0].reshape(1,1,1,100).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122,
   "position": {
    "height": "40px",
    "left": "1010px",
    "right": "20px",
    "top": "120px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
