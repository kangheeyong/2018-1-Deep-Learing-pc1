{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "import random\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Power Pressure Gas1 Gas2\n",
    "data = pd.read_excel('2nd.xlsx') # MLMH\n",
    "data = data.values\n",
    "RealOESdata = data[151:251,1:]\n",
    "data = pd.read_excel('4th.xlsx') # LMHM\n",
    "data = data.values\n",
    "RealOESdata = np.vstack((RealOESdata, data[151:251,1:]))\n",
    "data = pd.read_excel('6th.xlsx') # HMMH\n",
    "data = data.values\n",
    "RealOESdata = np.vstack((RealOESdata, data[151:251,1:]))\n",
    "data = pd.read_excel('8th.xlsx') # HMMM\n",
    "data = data.values\n",
    "RealOESdata = np.vstack((RealOESdata, data[151:251,1:]))\n",
    "data = pd.read_excel('10th.xlsx') # MLLM\n",
    "data = data.values\n",
    "RealOESdata = np.vstack((RealOESdata, data[151:251,1:]))\n",
    "data = pd.read_excel('12th.xlsx') # LMML\n",
    "data = data.values\n",
    "RealOESdata = np.vstack((RealOESdata, data[151:251,1:]))\n",
    "data = pd.read_excel('14th.xlsx') # MLHM\n",
    "data = data.values\n",
    "RealOESdata = np.vstack((RealOESdata, data[151:251,1:]))\n",
    "data = pd.read_excel('16th.xlsx') # HMML\n",
    "data = data.values\n",
    "RealOESdata = np.vstack((RealOESdata, data[151:251,1:]))\n",
    "data = pd.read_excel('17th.xlsx') # LMLM\n",
    "data = data.values\n",
    "RealOESdata = np.vstack((RealOESdata, data[151:251,1:]))\n",
    "data = pd.read_excel('21th.xlsx') # HMHM\n",
    "data = data.values\n",
    "RealOESdata = np.vstack((RealOESdata, data[151:251,1:]))\n",
    "data = pd.read_excel('23th.xlsx') # MLML\n",
    "data = data.values\n",
    "RealOESdata = np.vstack((RealOESdata, data[151:251,1:]))\n",
    "data = pd.read_excel('24th.xlsx') # HMLM\n",
    "data = data.values\n",
    "RealOESdata = np.vstack((RealOESdata, data[151:251,1:]))\n",
    "data = pd.read_excel('25th.xlsx') # LMMH\n",
    "data = data.values\n",
    "RealOESdata = np.vstack((RealOESdata, data[151:251,1:]))\n",
    "####\n",
    "data = pd.read_excel('1st.xlsx') # MMHH\n",
    "data = data.values\n",
    "RealOESdata = np.vstack((RealOESdata, data[151:251,1:]))\n",
    "data = pd.read_excel('7th.xlsx') # MMLH\n",
    "data = data.values\n",
    "RealOESdata = np.vstack((RealOESdata, data[151:251,1:]))\n",
    "data = pd.read_excel('15th.xlsx') # LHMM\n",
    "data = data.values\n",
    "RealOESdata = np.vstack((RealOESdata, data[151:251,1:]))\n",
    "data = pd.read_excel('22th.xlsx') # MHLM\n",
    "data = data.values\n",
    "RealOESdata = np.vstack((RealOESdata, data[151:251,1:]))\n",
    "data = pd.read_excel('26th.xlsx') # MMMM\n",
    "data = data.values\n",
    "RealOESdata = np.vstack((RealOESdata, data[151:251,1:]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_ClassifiedResult = np.array([1, 0, 1, 2])\n",
    "for k in range(99):\n",
    "    Y_ClassifiedResult = np.vstack((Y_ClassifiedResult,np.array([1, 0, 1, 2])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult = np.vstack((Y_ClassifiedResult,np.array([0, 1, 2, 1])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult = np.vstack((Y_ClassifiedResult,np.array([2, 1, 1, 2])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult = np.vstack((Y_ClassifiedResult,np.array([2, 1, 1, 1])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult = np.vstack((Y_ClassifiedResult,np.array([1, 0, 0, 1])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult = np.vstack((Y_ClassifiedResult,np.array([0, 1, 1, 0])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult = np.vstack((Y_ClassifiedResult,np.array([1, 0, 2, 1])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult = np.vstack((Y_ClassifiedResult,np.array([2, 1, 1, 0])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult = np.vstack((Y_ClassifiedResult,np.array([0, 1, 0, 1])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult = np.vstack((Y_ClassifiedResult,np.array([2, 1, 2, 1])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult = np.vstack((Y_ClassifiedResult,np.array([1, 0, 1, 0])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult = np.vstack((Y_ClassifiedResult,np.array([2, 1, 0, 1])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult = np.vstack((Y_ClassifiedResult,np.array([0, 1, 1, 2])))\n",
    "##############################################\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult = np.vstack((Y_ClassifiedResult,np.array([1, 1, 2, 2])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult = np.vstack((Y_ClassifiedResult,np.array([1, 1, 0, 2])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult = np.vstack((Y_ClassifiedResult,np.array([0, 2, 1, 1])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult = np.vstack((Y_ClassifiedResult,np.array([1, 2, 0, 1])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult = np.vstack((Y_ClassifiedResult,np.array([1, 1, 1, 1])))\n",
    "\n",
    "Sequence = np.array([0])\n",
    "for k in range(179):\n",
    "    Sequence = np.hstack((Sequence, np.array([k+1])))\n",
    "\n",
    "Sequence\n",
    "#Y_ClassifiedResult = np.array([[1, 0, 1, 2],\n",
    "#                            [0, 1, 2, 1],\n",
    "#                            [2, 1, 1, 2],\n",
    "#                            [2, 1, 1, 1],\n",
    "#                            [1, 0, 0, 1],\n",
    "#                            [0, 1, 1, 0],\n",
    "#                            [1, 0, 2, 1],\n",
    "#                            [2, 1, 1, 0],\n",
    "#                            [0, 1, 0, 1],\n",
    "#                            [2, 1, 2, 1],\n",
    "#                            [1, 0, 1, 0],\n",
    "#                            [2, 1, 0, 1],\n",
    "#                            [0, 1, 1, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.00001\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "batchsize = 10\n",
    "\n",
    "n_InputUnit = 3648\n",
    "n_1stHiddenUnit = 500\n",
    "n_2ndHiddenUnit = 300\n",
    "n_3rdHiddenUnit = 250\n",
    "n_4thHiddenUnit = 150\n",
    "n_5thHiddenUnit = 50\n",
    "n_OutputUnit = 4\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([n_InputUnit, n_1stHiddenUnit],stddev=0.01))\n",
    "W2 = tf.Variable(tf.random_normal([n_1stHiddenUnit, n_2ndHiddenUnit],stddev=0.01))\n",
    "W3 = tf.Variable(tf.random_normal([n_2ndHiddenUnit, n_3rdHiddenUnit],stddev=0.01))\n",
    "W4 = tf.Variable(tf.random_normal([n_3rdHiddenUnit, n_4thHiddenUnit],stddev=0.01))\n",
    "W5 = tf.Variable(tf.random_normal([n_4thHiddenUnit, n_5thHiddenUnit],stddev=0.01))\n",
    "W6 = tf.Variable(tf.random_normal([n_5thHiddenUnit, n_OutputUnit],stddev=0.01))\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([n_1stHiddenUnit], stddev=0.01))\n",
    "b2 = tf.Variable(tf.random_normal([n_2ndHiddenUnit], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([n_3rdHiddenUnit], stddev=0.01))\n",
    "b4 = tf.Variable(tf.random_normal([n_4thHiddenUnit], stddev=0.01))\n",
    "b5 = tf.Variable(tf.random_normal([n_5thHiddenUnit], stddev=0.01))\n",
    "b6 = tf.Variable(tf.random_normal([n_OutputUnit], stddev=0.01))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_InputUnit]) # tensorflow의 placeholder라는 변수를 선언\n",
    "Y = tf.placeholder(tf.float32, [None, n_OutputUnit])\n",
    "\n",
    "L1 = tf.nn.elu(tf.matmul(X, W1) + b1)\n",
    "L2 = tf.nn.elu(tf.matmul(L1, W2) + b2)\n",
    "L3 = tf.nn.elu(tf.matmul(L2, W3) + b3)\n",
    "L4 = tf.nn.elu(tf.matmul(L3, W4) + b4)\n",
    "L5 = tf.nn.elu(tf.matmul(L4, W5) + b5)\n",
    "Hypothesis = tf.nn.elu(tf.matmul(L5, W6) + b6)\n",
    "\n",
    "cost = tf.reduce_mean(tf.pow(Y - Hypothesis, 2))\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=0.5).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Minibatch Loss: 1.426475\n",
      "Step 1000: Minibatch Loss: 0.369576\n",
      "Step 2000: Minibatch Loss: 0.698929\n",
      "Step 3000: Minibatch Loss: 0.251952\n",
      "Step 4000: Minibatch Loss: 0.561715\n",
      "Step 5000: Minibatch Loss: 0.200661\n",
      "Step 6000: Minibatch Loss: 0.033980\n",
      "Step 7000: Minibatch Loss: 0.357324\n",
      "Step 8000: Minibatch Loss: 0.376493\n",
      "Step 9000: Minibatch Loss: 0.370053\n",
      "Step 10000: Minibatch Loss: 0.144300\n",
      "Step 11000: Minibatch Loss: 0.285669\n",
      "Step 12000: Minibatch Loss: 0.550256\n",
      "Step 13000: Minibatch Loss: 0.510445\n",
      "Step 14000: Minibatch Loss: 0.118805\n",
      "Step 15000: Minibatch Loss: 0.193578\n",
      "Step 16000: Minibatch Loss: 0.125188\n",
      "Step 17000: Minibatch Loss: 0.022496\n",
      "Step 18000: Minibatch Loss: 0.017064\n",
      "Step 19000: Minibatch Loss: 0.001726\n",
      "Step 20000: Minibatch Loss: 0.118823\n",
      "Step 21000: Minibatch Loss: 0.009016\n",
      "Step 22000: Minibatch Loss: 0.004236\n",
      "Step 23000: Minibatch Loss: 0.097961\n",
      "Step 24000: Minibatch Loss: 0.067290\n",
      "Step 25000: Minibatch Loss: 0.045555\n",
      "Step 26000: Minibatch Loss: 0.005163\n",
      "Step 27000: Minibatch Loss: 0.000314\n",
      "Step 28000: Minibatch Loss: 0.145771\n",
      "Step 29000: Minibatch Loss: 0.001650\n",
      "Step 30000: Minibatch Loss: 0.014434\n",
      "Step 31000: Minibatch Loss: 0.335803\n",
      "Step 32000: Minibatch Loss: 0.053148\n",
      "Step 33000: Minibatch Loss: 0.020422\n",
      "Step 34000: Minibatch Loss: 0.037036\n",
      "Step 35000: Minibatch Loss: 0.024810\n",
      "Step 36000: Minibatch Loss: 0.008121\n",
      "Step 37000: Minibatch Loss: 0.012237\n",
      "Step 38000: Minibatch Loss: 0.013979\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(100001):\n",
    "        Order = Sequence[step % 170]\n",
    "        \n",
    "        batch_X = np.reshape(RealOESdata[Order*batchsize: (Order+1)*batchsize,:],\n",
    "                             (batchsize, n_InputUnit)) #25개\n",
    "        \n",
    "        batch_Y = np.reshape(Y_ClassifiedResult[Order*batchsize: (Order+1)*batchsize,:],\n",
    "                             (batchsize, n_OutputUnit))\n",
    "        \n",
    "        _, MinibatchLoss = session.run([train, cost], feed_dict ={X: batch_X, Y: batch_Y})\n",
    "        #####################################\n",
    "        #print ('Step %i: Minibatch Loss: %f' % (step, MinibatchLoss))\n",
    "        \n",
    "        #####################################\n",
    "        if step % 1000 == 0:\n",
    "            print ('Step %i: Minibatch Loss: %f' % (step, MinibatchLoss))\n",
    "            \n",
    "        if step % 170 == 0:\n",
    "            random.shuffle(Sequence)\n",
    "            \n",
    "            \n",
    "    for i in range(170):\n",
    "        Result_batch_X = np.reshape(RealOESdata[i*batchsize: (i+1)*batchsize,:],\n",
    "                                    (batchsize, n_InputUnit))\n",
    "        PredictedBatchData = session.run(Hypothesis, feed_dict = {X : Result_batch_X})\n",
    "        Y_ClassifiedResult_Reshaped = np.reshape(Y_ClassifiedResult[i*batchsize: (i+1)*batchsize,:],\n",
    "                                                 (batchsize, n_OutputUnit))\n",
    "        \n",
    "        print(i)\n",
    "        print(\"Result of predicting EntireData\")\n",
    "        print(PredictedBatchData)\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(\"Result of Rounded off EntireData\")\n",
    "            print(np.rint(PredictedBatchData))\n",
    "            print(\"Original Data\")\n",
    "            print(Y_ClassifiedResult_Reshaped[1,:])\n",
    "        \n",
    "        if i == 0:\n",
    "            PredictedEntireData = PredictedBatchData\n",
    "        else:\n",
    "            PredictedEntireData = np.vstack((PredictedEntireData,PredictedBatchData))\n",
    "        \n",
    "    \n",
    "    print(\"R_square of EntireData\")\n",
    "    print(r2_score(Y_ClassifiedResult, PredictedEntireData))\n",
    "    ############################################################################\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('3rd.xlsx') # LLMM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(Hypothesis, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(np.rint(Result_Test_Y))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('9th.xlsx') # MMLL\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(Hypothesis, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(np.rint(Result_Test_Y))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('13th.xlsx') # HHMM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(Hypothesis, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(np.rint(Result_Test_Y))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('18th.xlsx') # MHHM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(Hypothesis, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(np.rint(Result_Test_Y))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('19th.xlsx') # MHML\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(Hypothesis, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(np.rint(Result_Test_Y))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('27th.xlsx') # MHMH\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(Hypothesis, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(np.rint(Result_Test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 0 into shape (100,3648)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-b25be8997857>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mResult_Test_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTestOESdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_InputUnit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mResult_Test_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHypothesis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mResult_Test_X\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    230\u001b[0m            [5, 6]])\n\u001b[1;32m    231\u001b[0m     \"\"\"\n\u001b[0;32m--> 232\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# An AttributeError occurs if the object does not have\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 0 into shape (100,3648)"
     ]
    }
   ],
   "source": [
    "data2 = pd.read_excel('11th.xlsx') # MMHL\n",
    "data2 = data2.values\n",
    "TestOESdata = data2[151:251,1:]\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(Hypothesis, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(np.rint(Result_Test_Y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 589,
   "position": {
    "height": "845px",
    "left": "1528px",
    "right": "20px",
    "top": "117px",
    "width": "372px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
