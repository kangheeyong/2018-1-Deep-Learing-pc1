{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "import random\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Power Pressure Gas1 Gas2\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "data = pd.read_excel('12th.xlsx') # LMML\n",
    "data = data.values\n",
    "RealOESdata = data[151:251,1:]\n",
    "data = pd.read_excel('14th.xlsx') # MLHM\n",
    "data = data.values\n",
    "RealOESdata = np.vstack((RealOESdata, data[151:251,1:]))\n",
    "data = pd.read_excel('16th.xlsx') # HMML\n",
    "data = data.values\n",
    "RealOESdata = np.vstack((RealOESdata, data[151:251,1:]))\n",
    "data = pd.read_excel('17th.xlsx') # LMLM\n",
    "data = data.values\n",
    "RealOESdata = np.vstack((RealOESdata, data[151:251,1:]))\n",
    "data = pd.read_excel('21th.xlsx') # HMHM\n",
    "data = data.values\n",
    "RealOESdata = np.vstack((RealOESdata, data[151:251,1:]))\n",
    "data = pd.read_excel('23th.xlsx') # MLML\n",
    "data = data.values\n",
    "RealOESdata = np.vstack((RealOESdata, data[151:251,1:]))\n",
    "data = pd.read_excel('24th.xlsx') # HMLM\n",
    "data = data.values\n",
    "RealOESdata = np.vstack((RealOESdata, data[151:251,1:]))\n",
    "data = pd.read_excel('25th.xlsx') # LMMH\n",
    "data = data.values\n",
    "RealOESdata = np.vstack((RealOESdata, data[151:251,1:]))\n",
    "####\n",
    "data = pd.read_excel('1st.xlsx') # MMHH\n",
    "data = data.values\n",
    "RealOESdata = np.vstack((RealOESdata, data[151:251,1:]))\n",
    "data = pd.read_excel('7th.xlsx') # MMLH\n",
    "data = data.values\n",
    "RealOESdata = np.vstack((RealOESdata, data[151:251,1:]))\n",
    "data = pd.read_excel('15th.xlsx') # LHMM\n",
    "data = data.values\n",
    "RealOESdata = np.vstack((RealOESdata, data[151:251,1:]))\n",
    "data = pd.read_excel('22th.xlsx') # MHLM\n",
    "data = data.values\n",
    "RealOESdata = np.vstack((RealOESdata, data[151:251,1:]))\n",
    "data = pd.read_excel('26th.xlsx') # MMMM\n",
    "data = data.values\n",
    "RealOESdata = np.vstack((RealOESdata, data[151:251,1:]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RealOESdata_norm = (RealOESdata-np.min(RealOESdata))/(np.max(RealOESdata)-np.min(RealOESdata))\n",
    "\n",
    "# Low = 1 0 0\n",
    "# Medium = 0 1 0\n",
    "# High = 0 0 1\n",
    "\n",
    "####\n",
    "Y_ClassifiedResult_Power = np.array([1, 0, 0])\n",
    "for k in range(99):\n",
    "    Y_ClassifiedResult_Power = np.vstack((Y_ClassifiedResult_Power, np.array([1, 0, 0])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_Power = np.vstack((Y_ClassifiedResult_Power, np.array([0, 1, 0])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_Power = np.vstack((Y_ClassifiedResult_Power, np.array([0, 0, 1])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_Power = np.vstack((Y_ClassifiedResult_Power, np.array([1, 0, 0])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_Power = np.vstack((Y_ClassifiedResult_Power, np.array([0, 0, 1])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_Power = np.vstack((Y_ClassifiedResult_Power, np.array([0, 1, 0])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_Power = np.vstack((Y_ClassifiedResult_Power, np.array([0, 0, 1])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_Power = np.vstack((Y_ClassifiedResult_Power, np.array([1, 0, 0])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_Power = np.vstack((Y_ClassifiedResult_Power, np.array([0, 1, 0])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_Power = np.vstack((Y_ClassifiedResult_Power, np.array([0, 1, 0])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_Power = np.vstack((Y_ClassifiedResult_Power, np.array([1, 0, 0])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_Power = np.vstack((Y_ClassifiedResult_Power, np.array([0, 1, 0])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_Power = np.vstack((Y_ClassifiedResult_Power, np.array([0, 1, 0])))\n",
    "\n",
    "####\n",
    "Y_ClassifiedResult_Press = np.array([0, 1, 0])\n",
    "for k in range(99):\n",
    "    Y_ClassifiedResult_Press = np.vstack((Y_ClassifiedResult_Press, np.array([0, 1, 0])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_Press = np.vstack((Y_ClassifiedResult_Press, np.array([1, 0, 0])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_Press = np.vstack((Y_ClassifiedResult_Press, np.array([0, 1, 0])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_Press = np.vstack((Y_ClassifiedResult_Press, np.array([0, 1, 0])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_Press = np.vstack((Y_ClassifiedResult_Press, np.array([0, 1, 0])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_Press = np.vstack((Y_ClassifiedResult_Press, np.array([1, 0, 0])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_Press = np.vstack((Y_ClassifiedResult_Press, np.array([0, 1, 0])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_Press = np.vstack((Y_ClassifiedResult_Press, np.array([0, 1, 0])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_Press = np.vstack((Y_ClassifiedResult_Press, np.array([0, 1, 0])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_Press = np.vstack((Y_ClassifiedResult_Press, np.array([0, 1, 0])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_Press = np.vstack((Y_ClassifiedResult_Press, np.array([0, 0, 1])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_Press = np.vstack((Y_ClassifiedResult_Press, np.array([0, 0, 1])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_Press = np.vstack((Y_ClassifiedResult_Press, np.array([0, 1, 0])))\n",
    "    \n",
    "####\n",
    "Y_ClassifiedResult_C3H6 = np.array([0, 1, 0])\n",
    "for k in range(99):\n",
    "    Y_ClassifiedResult_C3H6 = np.vstack((Y_ClassifiedResult_C3H6, np.array([0, 1, 0])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_C3H6 = np.vstack((Y_ClassifiedResult_C3H6, np.array([0, 0, 1])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_C3H6 = np.vstack((Y_ClassifiedResult_C3H6, np.array([0, 1, 0])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_C3H6 = np.vstack((Y_ClassifiedResult_C3H6, np.array([1, 0, 0])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_C3H6 = np.vstack((Y_ClassifiedResult_C3H6, np.array([0, 0, 1])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_C3H6 = np.vstack((Y_ClassifiedResult_C3H6, np.array([0, 1, 0])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_C3H6 = np.vstack((Y_ClassifiedResult_C3H6, np.array([1, 0, 0])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_C3H6 = np.vstack((Y_ClassifiedResult_C3H6, np.array([0, 1, 0])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_C3H6 = np.vstack((Y_ClassifiedResult_C3H6, np.array([0, 0, 1])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_C3H6 = np.vstack((Y_ClassifiedResult_C3H6, np.array([1, 0, 0])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_C3H6 = np.vstack((Y_ClassifiedResult_C3H6, np.array([0, 1, 0])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_C3H6 = np.vstack((Y_ClassifiedResult_C3H6, np.array([1, 0, 0])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_C3H6 = np.vstack((Y_ClassifiedResult_C3H6, np.array([0, 1, 0])))\n",
    "    \n",
    "####\n",
    "Y_ClassifiedResult_N2 = np.array([1, 0, 0])\n",
    "for k in range(99):\n",
    "    Y_ClassifiedResult_N2 = np.vstack((Y_ClassifiedResult_N2, np.array([1, 0, 0])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_N2 = np.vstack((Y_ClassifiedResult_N2, np.array([0, 1, 0])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_N2 = np.vstack((Y_ClassifiedResult_N2, np.array([1, 0, 0])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_N2 = np.vstack((Y_ClassifiedResult_N2, np.array([0, 1, 0])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_N2 = np.vstack((Y_ClassifiedResult_N2, np.array([0, 1, 0])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_N2 = np.vstack((Y_ClassifiedResult_N2, np.array([1, 0, 0])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_N2 = np.vstack((Y_ClassifiedResult_N2, np.array([0, 1, 0])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_N2 = np.vstack((Y_ClassifiedResult_N2, np.array([0, 0, 1])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_N2 = np.vstack((Y_ClassifiedResult_N2, np.array([0, 0, 1])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_N2 = np.vstack((Y_ClassifiedResult_N2, np.array([0, 0, 1])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_N2 = np.vstack((Y_ClassifiedResult_N2, np.array([0, 1, 0])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_N2 = np.vstack((Y_ClassifiedResult_N2, np.array([0, 1, 0])))\n",
    "for k in range(100):\n",
    "    Y_ClassifiedResult_N2 = np.vstack((Y_ClassifiedResult_N2, np.array([0, 1, 0])))    \n",
    "\n",
    "    \n",
    "Sequence = np.array([0])\n",
    "for k in range(129):\n",
    "    Sequence = np.hstack((Sequence, np.array([k+1])))\n",
    "    \n",
    "Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.000001\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "batchsize = 10\n",
    "\n",
    "n_InputUnit = 3648\n",
    "n_1stHiddenUnit = 500\n",
    "n_2ndHiddenUnit = 250\n",
    "n_3rdHiddenUnit = 100\n",
    "n_OutputUnit = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm which decides standard for classifying data\n",
    "# Algorithm which can detect some kind of different phenomena\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([n_InputUnit, n_1stHiddenUnit],stddev=0.01))\n",
    "W2 = tf.Variable(tf.random_normal([n_1stHiddenUnit, n_2ndHiddenUnit],stddev=0.01))\n",
    "W3 = tf.Variable(tf.random_normal([n_2ndHiddenUnit, n_3rdHiddenUnit],stddev=0.01))\n",
    "W4 = tf.Variable(tf.random_normal([n_3rdHiddenUnit, n_OutputUnit],stddev=0.01))\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([n_1stHiddenUnit], stddev=0.01))\n",
    "b2 = tf.Variable(tf.random_normal([n_2ndHiddenUnit], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([n_3rdHiddenUnit], stddev=0.01))\n",
    "b4 = tf.Variable(tf.random_normal([n_OutputUnit], stddev=0.01))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_InputUnit]) # tensorflow의 placeholder라는 변수를 선언\n",
    "Y = tf.placeholder(tf.float32, [None, n_OutputUnit])\n",
    "\n",
    "L1 = tf.nn.elu(tf.matmul(X, W1) + b1)\n",
    "L2 = tf.nn.elu(tf.matmul(L1, W2) + b2)\n",
    "L3 = tf.nn.elu(tf.matmul(L2, W3) + b3)\n",
    "logits = tf.matmul(L3, W4) + b4\n",
    "Hypothesis = tf.nn.softmax(logits)\n",
    "\n",
    "\n",
    "#tf.stop_gradient(Y)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=logits))\n",
    "#cost = cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(, Y))\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=0.5).minimize(cost)\n",
    "prediction = tf.argmax(Hypothesis, 1)\n",
    "correct_prediction = tf.equal(tf.argmax(Hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Minibatch Loss: 9.921161, Accuracy: 0.000000\n",
      "Step 1000: Minibatch Loss: 0.927145, Accuracy: 1.000000\n",
      "Step 2000: Minibatch Loss: 1.093854, Accuracy: 1.000000\n",
      "Step 3000: Minibatch Loss: 0.131963, Accuracy: 1.000000\n",
      "Step 4000: Minibatch Loss: 0.762528, Accuracy: 1.000000\n",
      "Step 5000: Minibatch Loss: 1.351834, Accuracy: 0.000000\n",
      "Step 6000: Minibatch Loss: 1.913608, Accuracy: 0.000000\n",
      "Step 7000: Minibatch Loss: 1.206108, Accuracy: 1.000000\n",
      "Step 8000: Minibatch Loss: 0.970750, Accuracy: 1.000000\n",
      "Step 9000: Minibatch Loss: 0.326489, Accuracy: 1.000000\n",
      "Step 10000: Minibatch Loss: 0.492515, Accuracy: 1.000000\n",
      "Step 11000: Minibatch Loss: 0.584621, Accuracy: 1.000000\n",
      "Step 12000: Minibatch Loss: 0.487391, Accuracy: 1.000000\n",
      "Step 13000: Minibatch Loss: 0.118275, Accuracy: 1.000000\n",
      "Step 14000: Minibatch Loss: 1.197800, Accuracy: 0.100000\n",
      "Step 15000: Minibatch Loss: 0.298255, Accuracy: 1.000000\n",
      "Step 16000: Minibatch Loss: 0.491072, Accuracy: 1.000000\n",
      "Step 17000: Minibatch Loss: 0.720196, Accuracy: 1.000000\n",
      "Step 18000: Minibatch Loss: 0.261141, Accuracy: 1.000000\n",
      "Step 19000: Minibatch Loss: 0.134891, Accuracy: 1.000000\n",
      "Step 20000: Minibatch Loss: 1.073664, Accuracy: 0.900000\n",
      "Step 21000: Minibatch Loss: 0.136272, Accuracy: 1.000000\n",
      "Step 22000: Minibatch Loss: 0.126293, Accuracy: 1.000000\n",
      "Step 23000: Minibatch Loss: 0.055782, Accuracy: 1.000000\n",
      "Step 24000: Minibatch Loss: 0.058862, Accuracy: 1.000000\n",
      "Step 25000: Minibatch Loss: 0.101082, Accuracy: 1.000000\n",
      "Step 26000: Minibatch Loss: 0.107517, Accuracy: 1.000000\n",
      "Step 27000: Minibatch Loss: 0.041399, Accuracy: 1.000000\n",
      "Step 28000: Minibatch Loss: 0.207155, Accuracy: 1.000000\n",
      "Step 29000: Minibatch Loss: 0.346755, Accuracy: 1.000000\n",
      "Step 30000: Minibatch Loss: 0.058191, Accuracy: 1.000000\n",
      "0\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "Original Data\n",
      "[1 0 0]\n",
      "1\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "2\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "3\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "4\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "5\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "6\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "7\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "8\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "9\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "10\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "11\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "12\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "13\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "14\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "15\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "16\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "17\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "18\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "19\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "20\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "Original Data\n",
      "[0 0 1]\n",
      "21\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "22\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "23\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "24\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "25\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "26\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "27\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "28\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "29\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "30\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "Original Data\n",
      "[1 0 0]\n",
      "31\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "32\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "33\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "34\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "35\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "36\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "37\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "38\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "39\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "40\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "Original Data\n",
      "[0 0 1]\n",
      "41\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "42\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "43\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "44\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "45\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "46\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "47\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "48\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "49\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "50\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "51\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "52\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "53\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "54\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "55\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "56\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "57\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "58\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "59\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "60\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "Original Data\n",
      "[0 0 1]\n",
      "61\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "62\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "63\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "64\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "65\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "66\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "67\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "68\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "69\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "70\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "Original Data\n",
      "[1 0 0]\n",
      "71\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "72\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "73\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "74\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "75\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 1 1]\n",
      "76\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 0 0 0]\n",
      "77\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "78\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "79\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 0 1 0 1 1 0]\n",
      "80\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "81\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "82\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "83\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "84\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "85\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "86\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "87\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "88\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "89\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "90\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "91\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "92\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "93\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "94\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "95\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "96\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "97\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "98\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "99\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "100\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "Original Data\n",
      "[1 0 0]\n",
      "101\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "102\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "103\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "104\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "105\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "106\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "107\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "108\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "109\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "110\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "111\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "112\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "113\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "114\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "115\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "116\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "117\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "118\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "119\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "120\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "122\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "123\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "124\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "125\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "126\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "127\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "128\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "129\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Result of Test Data\n",
      "1 0 0\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "0 1 0\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 1.000000\n",
      "Result of Test Data\n",
      "0 0 1\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "0 1 0\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "0 1 0\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "0 1 0\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 1.000000\n",
      "Result of Test Data\n",
      "1 0 0\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Accuracy : 1.000000\n",
      "Result of Test Data\n",
      "0 1 0\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 1.000000\n",
      "Result of Test Data\n",
      "0 1 0\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 1.000000\n",
      "Result of Test Data\n",
      "0 0 1\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "0 0 1\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "Accuracy : 1.000000\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(30001):\n",
    "        Order = Sequence[step % 130]\n",
    "        \n",
    "        batch_X = np.reshape(RealOESdata[Order*batchsize: (Order+1)*batchsize,:],\n",
    "                             (batchsize, n_InputUnit))\n",
    "        \n",
    "        batch_Y = np.reshape(Y_ClassifiedResult_Power[Order*batchsize: (Order+1)*batchsize,:],\n",
    "                             (batchsize, n_OutputUnit))\n",
    "        \n",
    "        _, MinibatchLoss = session.run([train, cost], feed_dict ={X: batch_X, Y: batch_Y})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={X: batch_X, Y: batch_Y})\n",
    "            print ('Step %i: Minibatch Loss: %f, Accuracy: %f' % (step, MinibatchLoss, train_accuracy))\n",
    "            \n",
    "        if step % 130 == 0:\n",
    "            random.shuffle(Sequence)\n",
    "            \n",
    "    train_accuracy = accuracy.eval(feec_dict = {X: RealOESdata, Y: Y_ClassifiedResult_Power})        \n",
    "    print('Full batch Accuracy: %f' % (train_accuracy))        \n",
    "            \n",
    "    for i in range(130):\n",
    "        Result_batch_X = np.reshape(RealOESdata[i*batchsize: (i+1)*batchsize,:],\n",
    "                                    (batchsize, n_InputUnit))\n",
    "        PredictedBatchData = session.run(prediction, feed_dict = {X : Result_batch_X})\n",
    "        Y_ClassifiedResult_Reshaped = np.reshape(Y_ClassifiedResult_Power[i*batchsize: (i+1)*batchsize,:],\n",
    "                                                 (batchsize, n_OutputUnit))\n",
    "        \n",
    "        print(i)\n",
    "        print(\"Result of predicting EntireData\")\n",
    "        print(PredictedBatchData)\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(\"Original Data\")\n",
    "            print(Y_ClassifiedResult_Reshaped[1,:])\n",
    "    \n",
    "   # print(\"R_square of EntireData\")\n",
    "   # print(r2_score(Y_ClassifiedResult, PredictedEntireData))\n",
    "    ############################################################################\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('3rd.xlsx') # LLMM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"1 0 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([1, 0, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([1, 0, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('9th.xlsx') # MMLL\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 1 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('13th.xlsx') # HHMM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 0 1\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 0, 1])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 0, 1])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('18th.xlsx') # MHHM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 1 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('19th.xlsx') # MHML\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 1 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('27th.xlsx') # MHMH\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 1 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('4th.xlsx') # LMHM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"1 0 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([1, 0, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([1, 0, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('10th.xlsx') # MLLM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 1 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('2nd.xlsx') # MLMH\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 1 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('6th.xlsx') # HMMH\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 0 1\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 0, 1])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 0, 1])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('8th.xlsx') # HMMM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 0 1\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 0, 1])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 0, 1])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Minibatch Loss: 10.155670, Accuracy: 0.000000\n",
      "Step 1000: Minibatch Loss: 0.083707, Accuracy: 1.000000\n",
      "Step 2000: Minibatch Loss: 0.858612, Accuracy: 1.000000\n",
      "Step 3000: Minibatch Loss: 2.083933, Accuracy: 0.000000\n",
      "Step 4000: Minibatch Loss: 1.407754, Accuracy: 0.000000\n",
      "Step 5000: Minibatch Loss: 0.305353, Accuracy: 1.000000\n",
      "Step 6000: Minibatch Loss: 0.348498, Accuracy: 1.000000\n",
      "Step 7000: Minibatch Loss: 1.976183, Accuracy: 0.000000\n",
      "Step 8000: Minibatch Loss: 0.000091, Accuracy: 1.000000\n",
      "Step 9000: Minibatch Loss: 0.387186, Accuracy: 1.000000\n",
      "Step 10000: Minibatch Loss: 0.893321, Accuracy: 1.000000\n",
      "Step 11000: Minibatch Loss: 0.060318, Accuracy: 1.000000\n",
      "Step 12000: Minibatch Loss: 0.089939, Accuracy: 1.000000\n",
      "Step 13000: Minibatch Loss: 0.016754, Accuracy: 1.000000\n",
      "Step 14000: Minibatch Loss: 0.779571, Accuracy: 1.000000\n",
      "Step 15000: Minibatch Loss: 0.291644, Accuracy: 1.000000\n",
      "Step 16000: Minibatch Loss: 0.000001, Accuracy: 1.000000\n",
      "Step 17000: Minibatch Loss: 0.319642, Accuracy: 1.000000\n",
      "Step 18000: Minibatch Loss: 0.000000, Accuracy: 1.000000\n",
      "Step 19000: Minibatch Loss: 0.002481, Accuracy: 1.000000\n",
      "Step 20000: Minibatch Loss: 0.000000, Accuracy: 1.000000\n",
      "Step 21000: Minibatch Loss: 0.628171, Accuracy: 1.000000\n",
      "Step 22000: Minibatch Loss: 0.004370, Accuracy: 1.000000\n",
      "Step 23000: Minibatch Loss: 0.157033, Accuracy: 1.000000\n",
      "Step 24000: Minibatch Loss: 0.480645, Accuracy: 1.000000\n",
      "Step 25000: Minibatch Loss: 0.313769, Accuracy: 1.000000\n",
      "Step 26000: Minibatch Loss: 0.656255, Accuracy: 1.000000\n",
      "Step 27000: Minibatch Loss: 0.983204, Accuracy: 0.800000\n",
      "Step 28000: Minibatch Loss: 0.230814, Accuracy: 1.000000\n",
      "Step 29000: Minibatch Loss: 0.131477, Accuracy: 1.000000\n",
      "Step 30000: Minibatch Loss: 1.462272, Accuracy: 0.800000\n",
      "0\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "1\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "2\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "3\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "4\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "5\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "6\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "7\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "8\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "9\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "10\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "Original Data\n",
      "[1 0 0]\n",
      "11\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "12\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "13\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "14\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "15\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "16\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "17\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "18\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "19\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "20\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "21\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "22\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "23\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "24\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "25\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "26\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "27\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "28\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "29\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "30\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "31\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "32\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "33\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "34\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "35\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "36\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "37\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "38\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "39\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "40\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "41\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "42\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "43\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "44\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "45\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "46\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "47\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "48\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "49\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "50\n",
      "Result of predicting EntireData\n",
      "[0 0 0 1 0 1 1 1 0 1]\n",
      "Original Data\n",
      "[1 0 0]\n",
      "51\n",
      "Result of predicting EntireData\n",
      "[0 1 1 0 0 1 1 0 0 1]\n",
      "52\n",
      "Result of predicting EntireData\n",
      "[1 1 0 1 1 1 0 0 1 0]\n",
      "53\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 1 0 1 0 1]\n",
      "54\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 1 0 0 0 0 0]\n",
      "55\n",
      "Result of predicting EntireData\n",
      "[1 0 0 1 1 1 1 0 1 0]\n",
      "56\n",
      "Result of predicting EntireData\n",
      "[0 1 0 1 0 0 0 0 0 0]\n",
      "57\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 1 0]\n",
      "58\n",
      "Result of predicting EntireData\n",
      "[1 0 0 0 0 0 0 0 0 1]\n",
      "59\n",
      "Result of predicting EntireData\n",
      "[1 1 0 0 0 0 0 0 0 1]\n",
      "60\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "61\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "62\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "63\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "64\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "65\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "66\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "67\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "68\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "69\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "70\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "71\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "72\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "73\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "74\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "75\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "76\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "77\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "78\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "79\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "80\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "81\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "82\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "83\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "84\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "85\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "86\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "87\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "88\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "89\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "90\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "91\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "92\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "93\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "94\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "95\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "96\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "97\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "98\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "99\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "100\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 0 1]\n",
      "101\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "102\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "103\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "104\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "105\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "106\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "107\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "108\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "109\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "110\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 0 1]\n",
      "111\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "112\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "113\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "114\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "115\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "116\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "117\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "118\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "119\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "120\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "121\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "123\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "124\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "125\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "126\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "127\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "128\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "129\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Result of Test Data\n",
      "1 0 0\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "0 1 0\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "0 0 1\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "0 0 1\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "0 0 1\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "0 0 1\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "0 1 0\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 1.000000\n",
      "Result of Test Data\n",
      "1 0 0\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "1 0 0\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "0 1 0\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 1.000000\n",
      "Result of Test Data\n",
      "0, 1, 0\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 1.000000\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(30001):\n",
    "        Order = Sequence[step % 130]\n",
    "        \n",
    "        batch_X = np.reshape(RealOESdata[Order*batchsize: (Order+1)*batchsize,:],\n",
    "                             (batchsize, n_InputUnit))\n",
    "        \n",
    "        batch_Y = np.reshape(Y_ClassifiedResult_Press[Order*batchsize: (Order+1)*batchsize,:],\n",
    "                             (batchsize, n_OutputUnit))\n",
    "        \n",
    "        _, MinibatchLoss = session.run([train, cost], feed_dict ={X: batch_X, Y: batch_Y})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={X: batch_X, Y: batch_Y})\n",
    "            print ('Step %i: Minibatch Loss: %f, Minibatch Accuracy: %f' % (step, MinibatchLoss, train_accuracy))\n",
    "            \n",
    "        if step % 130 == 0:\n",
    "            random.shuffle(Sequence)\n",
    "            \n",
    "    train_accuracy = accuracy.eval(feec_dict = {X: RealOESdata, Y: Y_ClassifiedResult_Press})        \n",
    "    print('Full batch Accuracy: %f' % (train_accuracy))\n",
    "            \n",
    "    for i in range(130):\n",
    "        Result_batch_X = np.reshape(RealOESdata[i*batchsize: (i+1)*batchsize,:],\n",
    "                                    (batchsize, n_InputUnit))\n",
    "        PredictedBatchData = session.run(prediction, feed_dict = {X : Result_batch_X})\n",
    "        Y_ClassifiedResult_Reshaped = np.reshape(Y_ClassifiedResult_Press[i*batchsize: (i+1)*batchsize,:],\n",
    "                                                 (batchsize, n_OutputUnit))\n",
    "        \n",
    "        print(i)\n",
    "        print(\"Result of predicting EntireData\")\n",
    "        print(PredictedBatchData)\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(\"Original Data\")\n",
    "            print(Y_ClassifiedResult_Reshaped[1,:])\n",
    "    \n",
    "   # print(\"R_square of EntireData\")\n",
    "   # print(r2_score(Y_ClassifiedResult, PredictedEntireData))\n",
    "    ############################################################################\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('3rd.xlsx') # LLMM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"1 0 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([1, 0, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([1, 0, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('9th.xlsx') # MMLL\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 1 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('13th.xlsx') # HHMM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 0 1\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 0, 1])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 0, 1])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('18th.xlsx') # MHHM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 0 1\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 0, 1])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 0, 1])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('19th.xlsx') # MHML\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 0 1\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 0, 1])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 0, 1])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('27th.xlsx') # MHMH\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 0 1\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 0, 1])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 0, 1])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('4th.xlsx') # LMHM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 1 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('10th.xlsx') # MLLM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"1 0 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([1, 0, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([1, 0, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('2nd.xlsx') # MLMH\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"1 0 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([1, 0, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([1, 0, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('6th.xlsx') # HMMH\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 1 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('8th.xlsx') # HMMM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0, 1, 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## C3H6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Minibatch Loss: 15.673769, Accuracy: 0.000000\n",
      "Step 1000: Minibatch Loss: 0.802558, Accuracy: 1.000000\n",
      "Step 2000: Minibatch Loss: 0.094377, Accuracy: 1.000000\n",
      "Step 3000: Minibatch Loss: 0.470431, Accuracy: 1.000000\n",
      "Step 4000: Minibatch Loss: 1.843229, Accuracy: 0.000000\n",
      "Step 5000: Minibatch Loss: 0.510509, Accuracy: 1.000000\n",
      "Step 6000: Minibatch Loss: 2.042659, Accuracy: 0.000000\n",
      "Step 7000: Minibatch Loss: 0.534891, Accuracy: 1.000000\n",
      "Step 8000: Minibatch Loss: 0.231228, Accuracy: 1.000000\n",
      "Step 9000: Minibatch Loss: 1.270837, Accuracy: 0.200000\n",
      "Step 10000: Minibatch Loss: 0.047977, Accuracy: 1.000000\n",
      "Step 11000: Minibatch Loss: 0.059828, Accuracy: 1.000000\n",
      "Step 12000: Minibatch Loss: 2.582606, Accuracy: 0.000000\n",
      "Step 13000: Minibatch Loss: 0.184587, Accuracy: 1.000000\n",
      "Step 14000: Minibatch Loss: 0.041830, Accuracy: 1.000000\n",
      "Step 15000: Minibatch Loss: 0.000063, Accuracy: 1.000000\n",
      "Step 16000: Minibatch Loss: 0.280127, Accuracy: 1.000000\n",
      "Step 17000: Minibatch Loss: 0.060379, Accuracy: 1.000000\n",
      "Step 18000: Minibatch Loss: 0.000068, Accuracy: 1.000000\n",
      "Step 19000: Minibatch Loss: 0.060447, Accuracy: 1.000000\n",
      "Step 20000: Minibatch Loss: 1.765498, Accuracy: 0.000000\n",
      "Step 21000: Minibatch Loss: 0.209348, Accuracy: 1.000000\n",
      "Step 22000: Minibatch Loss: 1.942731, Accuracy: 0.000000\n",
      "Step 23000: Minibatch Loss: 0.202548, Accuracy: 1.000000\n",
      "Step 24000: Minibatch Loss: 0.080035, Accuracy: 1.000000\n",
      "Step 25000: Minibatch Loss: 0.089164, Accuracy: 1.000000\n",
      "Step 26000: Minibatch Loss: 0.002607, Accuracy: 1.000000\n",
      "Step 27000: Minibatch Loss: 0.091247, Accuracy: 1.000000\n",
      "Step 28000: Minibatch Loss: 0.241586, Accuracy: 1.000000\n",
      "Step 29000: Minibatch Loss: 0.365484, Accuracy: 1.000000\n",
      "Step 30000: Minibatch Loss: 0.685815, Accuracy: 1.000000\n",
      "0\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "1\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "2\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "3\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "4\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "5\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "6\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "7\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "8\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "9\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "10\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "Original Data\n",
      "[0 0 1]\n",
      "11\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "12\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "13\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "14\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "15\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "16\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "17\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "18\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "19\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "20\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "21\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "22\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "23\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "24\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "25\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "26\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "27\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "28\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "29\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "30\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "Original Data\n",
      "[1 0 0]\n",
      "31\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "32\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "33\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "34\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "35\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "36\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "37\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "38\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "39\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "40\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 0 1]\n",
      "41\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "42\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "43\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "44\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "45\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "46\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "47\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "48\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "49\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "50\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "51\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "52\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "53\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "54\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "55\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "56\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "57\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "58\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "59\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "60\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "Original Data\n",
      "[1 0 0]\n",
      "61\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "62\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "63\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "64\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "65\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "66\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "67\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "68\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "69\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "70\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "71\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "72\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "73\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "74\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "75\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "76\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "77\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "78\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "79\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "80\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "Original Data\n",
      "[0 0 1]\n",
      "81\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "82\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "83\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "84\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "85\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "86\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "87\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "88\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "89\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "90\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "Original Data\n",
      "[1 0 0]\n",
      "91\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "92\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "93\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "94\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "95\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "96\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "97\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "98\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "99\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "100\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "101\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "102\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "103\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "104\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "105\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "106\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "107\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "108\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "109\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "110\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[1 0 0]\n",
      "111\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "112\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "113\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "114\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "115\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "116\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "118\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "119\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "120\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "121\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "122\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "123\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "124\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "125\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "126\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "127\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "128\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "129\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Result of Test Data\n",
      "0 1 0\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "1 0 0\n",
      "[2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 1 2 2 2 1 2 2 2 0 2 2 2 2 2 2 2 2 2 0 2 2 2\n",
      " 2 2 2 2 2 2 2 1 2 1 2 1 2 1 1 1 1 2 1 0 1 1 0 2 0 0 0 0 0 1 2 0 2 0 2 2 1\n",
      " 2 2 2 1 2 2 2 2 2 1 2 2 2 2 2 2 1 2 1 2 0 0 0 2 0 2]\n",
      "Accuracy : 0.150000\n",
      "Result of Test Data\n",
      "0 1 0\n",
      "[2 2 2 2 2 2 2 2 2 2 1 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 2 2 2 1 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2]\n",
      "Accuracy : 0.080000\n",
      "Result of Test Data\n",
      "0 0 1\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "0 1 0\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 1.000000\n",
      "Result of Test Data\n",
      "0 1 0\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 1.000000\n",
      "Result of Test Data\n",
      "0 0 1\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "1 0 0\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Accuracy : 1.000000\n",
      "Result of Test Data\n",
      "0 1 0\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "0 1 0\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "0, 1, 0\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Accuracy : 0.000000\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(30001):\n",
    "        Order = Sequence[step % 130]\n",
    "        \n",
    "        batch_X = np.reshape(RealOESdata[Order*batchsize: (Order+1)*batchsize,:],\n",
    "                             (batchsize, n_InputUnit))\n",
    "        \n",
    "        batch_Y = np.reshape(Y_ClassifiedResult_C3H6[Order*batchsize: (Order+1)*batchsize,:],\n",
    "                             (batchsize, n_OutputUnit))\n",
    "        \n",
    "        _, MinibatchLoss = session.run([train, cost], feed_dict ={X: batch_X, Y: batch_Y})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={X: batch_X, Y: batch_Y})\n",
    "            print ('Step %i: Minibatch Loss: %f, Accuracy: %f' % (step, MinibatchLoss, train_accuracy))\n",
    "            \n",
    "        if step % 130 == 0:\n",
    "            random.shuffle(Sequence)\n",
    "            \n",
    "    train_accuracy = accuracy.eval(feec_dict = {X: RealOESdata, Y: Y_ClassifiedResult_C3H6})        \n",
    "    print('Full batch Accuracy: %f' % (train_accuracy))           \n",
    "            \n",
    "    for i in range(130):\n",
    "        Result_batch_X = np.reshape(RealOESdata[i*batchsize: (i+1)*batchsize,:],\n",
    "                                    (batchsize, n_InputUnit))\n",
    "        PredictedBatchData = session.run(prediction, feed_dict = {X : Result_batch_X})\n",
    "        Y_ClassifiedResult_Reshaped = np.reshape(Y_ClassifiedResult_C3H6[i*batchsize: (i+1)*batchsize,:],\n",
    "                                                 (batchsize, n_OutputUnit))\n",
    "        \n",
    "        print(i)\n",
    "        print(\"Result of predicting EntireData\")\n",
    "        print(PredictedBatchData)\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(\"Original Data\")\n",
    "            print(Y_ClassifiedResult_Reshaped[1,:])\n",
    "    \n",
    "   # print(\"R_square of EntireData\")\n",
    "   # print(r2_score(Y_ClassifiedResult, PredictedEntireData))\n",
    "    ############################################################################\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('3rd.xlsx') # LLMM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 1 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('9th.xlsx') # MMLL\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"1 0 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([1, 0, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([1, 0, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('13th.xlsx') # HHMM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 1 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('18th.xlsx') # MHHM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 0 1\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 0, 1])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 0, 1])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('19th.xlsx') # MHML\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 1 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('27th.xlsx') # MHMH\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 1 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('4th.xlsx') # LMHM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 0 1\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 0, 1])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 0, 1])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('10th.xlsx') # MLLM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"1 0 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([1, 0, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([1, 0, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('2nd.xlsx') # MLMH\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 1 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('6th.xlsx') # HMMH\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 1 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('8th.xlsx') # HMMM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0, 1, 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## N2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Minibatch Loss: 0.000147, Accuracy: 1.000000\n",
      "Step 1000: Minibatch Loss: 0.642141, Accuracy: 1.000000\n",
      "Step 2000: Minibatch Loss: 0.414539, Accuracy: 1.000000\n",
      "Step 3000: Minibatch Loss: 0.931533, Accuracy: 0.800000\n",
      "Step 4000: Minibatch Loss: 0.298773, Accuracy: 1.000000\n",
      "Step 5000: Minibatch Loss: 0.282244, Accuracy: 1.000000\n",
      "Step 6000: Minibatch Loss: 0.724031, Accuracy: 1.000000\n",
      "Step 7000: Minibatch Loss: 0.088688, Accuracy: 1.000000\n",
      "Step 8000: Minibatch Loss: 0.381017, Accuracy: 1.000000\n",
      "Step 9000: Minibatch Loss: 0.210079, Accuracy: 1.000000\n",
      "Step 10000: Minibatch Loss: 0.769329, Accuracy: 1.000000\n",
      "Step 11000: Minibatch Loss: 0.313769, Accuracy: 1.000000\n",
      "Step 12000: Minibatch Loss: 0.230183, Accuracy: 1.000000\n",
      "Step 13000: Minibatch Loss: 0.004515, Accuracy: 1.000000\n",
      "Step 14000: Minibatch Loss: 0.164434, Accuracy: 1.000000\n",
      "Step 15000: Minibatch Loss: 0.140269, Accuracy: 1.000000\n",
      "Step 16000: Minibatch Loss: 0.103085, Accuracy: 1.000000\n",
      "Step 17000: Minibatch Loss: 1.122354, Accuracy: 0.300000\n",
      "Step 18000: Minibatch Loss: 0.074926, Accuracy: 1.000000\n",
      "Step 19000: Minibatch Loss: 0.814988, Accuracy: 1.000000\n",
      "Step 20000: Minibatch Loss: 0.475379, Accuracy: 1.000000\n",
      "Step 21000: Minibatch Loss: 0.005908, Accuracy: 1.000000\n",
      "Step 22000: Minibatch Loss: 0.015471, Accuracy: 1.000000\n",
      "Step 23000: Minibatch Loss: 0.098690, Accuracy: 1.000000\n",
      "Step 24000: Minibatch Loss: 0.015123, Accuracy: 1.000000\n",
      "Step 25000: Minibatch Loss: 0.072998, Accuracy: 1.000000\n",
      "Step 26000: Minibatch Loss: 0.325475, Accuracy: 1.000000\n",
      "Step 27000: Minibatch Loss: 0.039707, Accuracy: 1.000000\n",
      "Step 28000: Minibatch Loss: 0.440189, Accuracy: 1.000000\n",
      "Step 29000: Minibatch Loss: 0.016082, Accuracy: 1.000000\n",
      "Step 30000: Minibatch Loss: 0.004814, Accuracy: 1.000000\n",
      "0\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "Original Data\n",
      "[1 0 0]\n",
      "1\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "2\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "3\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "4\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "5\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "6\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "7\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "8\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "9\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "10\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "11\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "12\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "13\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "14\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "15\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "16\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "17\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "18\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "19\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "20\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "Original Data\n",
      "[1 0 0]\n",
      "21\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "22\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "23\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "24\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "25\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "26\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "27\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "28\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "29\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "30\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "31\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "32\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "33\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "34\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "35\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "36\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "37\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "38\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "39\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "40\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "41\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "42\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "43\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "44\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "45\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "46\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "47\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "48\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "49\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "50\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "Original Data\n",
      "[1 0 0]\n",
      "51\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "52\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "53\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "54\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "55\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "56\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "57\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "58\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "59\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "60\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "61\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "62\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "63\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "64\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "65\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "66\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "67\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "68\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "69\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "70\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "Original Data\n",
      "[0 0 1]\n",
      "71\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "72\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "73\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "74\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "75\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 1 1]\n",
      "76\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 2 2 2]\n",
      "77\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "78\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "79\n",
      "Result of predicting EntireData\n",
      "[2 2 1 2 2 1 2 1 1 2]\n",
      "80\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "Original Data\n",
      "[0 0 1]\n",
      "81\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "82\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "83\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "84\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "85\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "86\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "87\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "88\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "89\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "90\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "Original Data\n",
      "[0 0 1]\n",
      "91\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "92\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "93\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "94\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "95\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "96\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "97\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "98\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "99\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "100\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "101\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "102\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "103\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "104\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "105\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "106\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "107\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "108\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "109\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "110\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "111\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "112\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "113\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "114\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "115\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "116\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "117\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "118\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "119\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "120\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "121\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "122\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "124\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "125\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "126\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "127\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "128\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "129\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Result of Test Data\n",
      "0 1 0\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "1 0 0\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "0 1 0\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 1.000000\n",
      "Result of Test Data\n",
      "0 1 0\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "1 0 0\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Accuracy : 1.000000\n",
      "Result of Test Data\n",
      "0 0 1\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "0 1 0\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 1.000000\n",
      "Result of Test Data\n",
      "0 1 0\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 1.000000\n",
      "Result of Test Data\n",
      "0 0 1\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "Accuracy : 1.000000\n",
      "Result of Test Data\n",
      "0 0 1\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "Accuracy : 1.000000\n",
      "Result of Test Data\n",
      "0, 1, 0\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 1.000000\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(30001):\n",
    "        Order = Sequence[step % 130]\n",
    "        \n",
    "        batch_X = np.reshape(RealOESdata[Order*batchsize: (Order+1)*batchsize,:],\n",
    "                             (batchsize, n_InputUnit))\n",
    "        \n",
    "        batch_Y = np.reshape(Y_ClassifiedResult_N2[Order*batchsize: (Order+1)*batchsize,:],\n",
    "                             (batchsize, n_OutputUnit))\n",
    "        \n",
    "        _, MinibatchLoss = session.run([train, cost], feed_dict ={X: batch_X, Y: batch_Y})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={X: batch_X, Y: batch_Y})\n",
    "            print ('Step %i: Minibatch Loss: %f, Accuracy: %f' % (step, MinibatchLoss, train_accuracy))\n",
    "            \n",
    "        if step % 130 == 0:\n",
    "            random.shuffle(Sequence)\n",
    "            \n",
    "    train_accuracy = accuracy.eval(feec_dict = {X: RealOESdata, Y: Y_ClassifiedResult_N2})        \n",
    "    print('Full batch Accuracy: %f' % (train_accuracy))             \n",
    "            \n",
    "    for i in range(130):\n",
    "        Result_batch_X = np.reshape(RealOESdata[i*batchsize: (i+1)*batchsize,:],\n",
    "                                    (batchsize, n_InputUnit))\n",
    "        PredictedBatchData = session.run(prediction, feed_dict = {X : Result_batch_X})\n",
    "        Y_ClassifiedResult_Reshaped = np.reshape(Y_ClassifiedResult_N2[i*batchsize: (i+1)*batchsize,:],\n",
    "                                                 (batchsize, n_OutputUnit))\n",
    "        \n",
    "        print(i)\n",
    "        print(\"Result of predicting EntireData\")\n",
    "        print(PredictedBatchData)\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(\"Original Data\")\n",
    "            print(Y_ClassifiedResult_Reshaped[1,:])\n",
    "    \n",
    "   # print(\"R_square of EntireData\")\n",
    "   # print(r2_score(Y_ClassifiedResult, PredictedEntireData))\n",
    "    ############################################################################\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('3rd.xlsx') # LLMM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 1 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('9th.xlsx') # MMLL\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"1 0 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([1, 0, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([1, 0, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('13th.xlsx') # HHMM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 1 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('18th.xlsx') # MHHM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 1 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('19th.xlsx') # MHML\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"1 0 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([1, 0, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([1, 0, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('27th.xlsx') # MHMH\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 0 1\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 0, 1])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 0, 1])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('4th.xlsx') # LMHM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 1 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('10th.xlsx') # MLLM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 1 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('2nd.xlsx') # MLMH\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 0 1\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 0, 1])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 0, 1])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('6th.xlsx') # HMMH\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 0 1\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 0, 1])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 0, 1])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('8th.xlsx') # HMMM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0, 1, 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.00001\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "batchsize = 10\n",
    "\n",
    "n_InputUnit = 3648\n",
    "n_1stHiddenUnit = 500\n",
    "n_2ndHiddenUnit = 250\n",
    "n_3rdHiddenUnit = 100\n",
    "n_OutputUnit = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm which decides standard for classifying data\n",
    "# Algorithm which can detect some kind of different phenomena\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([n_InputUnit, n_1stHiddenUnit],stddev=0.01))\n",
    "W2 = tf.Variable(tf.random_normal([n_1stHiddenUnit, n_2ndHiddenUnit],stddev=0.01))\n",
    "W3 = tf.Variable(tf.random_normal([n_2ndHiddenUnit, n_3rdHiddenUnit],stddev=0.01))\n",
    "W4 = tf.Variable(tf.random_normal([n_3rdHiddenUnit, n_OutputUnit],stddev=0.01))\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([n_1stHiddenUnit], stddev=0.01))\n",
    "b2 = tf.Variable(tf.random_normal([n_2ndHiddenUnit], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([n_3rdHiddenUnit], stddev=0.01))\n",
    "b4 = tf.Variable(tf.random_normal([n_OutputUnit], stddev=0.01))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_InputUnit]) # tensorflow의 placeholder라는 변수를 선언\n",
    "Y = tf.placeholder(tf.float32, [None, n_OutputUnit])\n",
    "\n",
    "L1 = tf.nn.elu(tf.matmul(X, W1) + b1)\n",
    "L2 = tf.nn.elu(tf.matmul(L1, W2) + b2)\n",
    "L3 = tf.nn.elu(tf.matmul(L2, W3) + b3)\n",
    "logits = tf.matmul(L3, W4) + b4\n",
    "Hypothesis = tf.nn.softmax(logits)\n",
    "\n",
    "\n",
    "#tf.stop_gradient(Y)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=logits))\n",
    "#cost = cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(, Y))\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=0.5).minimize(cost)\n",
    "prediction = tf.argmax(Hypothesis, 1)\n",
    "correct_prediction = tf.equal(tf.argmax(Hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Minibatch Loss: 3.661479, Accuracy: 1.000000\n",
      "Step 1000: Minibatch Loss: 1.907795, Accuracy: 0.000000\n",
      "Step 2000: Minibatch Loss: 0.821222, Accuracy: 1.000000\n",
      "Step 3000: Minibatch Loss: 0.650408, Accuracy: 1.000000\n",
      "Step 4000: Minibatch Loss: 0.788339, Accuracy: 1.000000\n",
      "Step 5000: Minibatch Loss: 0.788178, Accuracy: 1.000000\n",
      "Step 6000: Minibatch Loss: 1.013652, Accuracy: 1.000000\n",
      "Step 7000: Minibatch Loss: 0.445446, Accuracy: 1.000000\n",
      "Step 8000: Minibatch Loss: 0.290457, Accuracy: 1.000000\n",
      "Step 9000: Minibatch Loss: 0.863107, Accuracy: 1.000000\n",
      "Step 10000: Minibatch Loss: 0.256852, Accuracy: 1.000000\n",
      "Step 11000: Minibatch Loss: 0.029684, Accuracy: 1.000000\n",
      "Step 12000: Minibatch Loss: 0.825751, Accuracy: 1.000000\n",
      "Step 13000: Minibatch Loss: 0.028913, Accuracy: 1.000000\n",
      "Step 14000: Minibatch Loss: 0.039008, Accuracy: 1.000000\n",
      "Step 15000: Minibatch Loss: 0.422893, Accuracy: 1.000000\n",
      "Step 16000: Minibatch Loss: 0.034948, Accuracy: 1.000000\n",
      "Step 17000: Minibatch Loss: 0.217907, Accuracy: 1.000000\n",
      "Step 18000: Minibatch Loss: 0.034578, Accuracy: 1.000000\n",
      "Step 19000: Minibatch Loss: 0.061843, Accuracy: 1.000000\n",
      "Step 20000: Minibatch Loss: 0.749522, Accuracy: 1.000000\n",
      "Step 21000: Minibatch Loss: 0.551736, Accuracy: 1.000000\n",
      "Step 22000: Minibatch Loss: 0.000001, Accuracy: 1.000000\n",
      "Step 23000: Minibatch Loss: 0.024549, Accuracy: 1.000000\n",
      "Step 24000: Minibatch Loss: 0.029903, Accuracy: 1.000000\n",
      "Step 25000: Minibatch Loss: 0.003068, Accuracy: 1.000000\n",
      "Step 26000: Minibatch Loss: 0.023678, Accuracy: 1.000000\n",
      "Step 27000: Minibatch Loss: 0.000000, Accuracy: 1.000000\n",
      "Step 28000: Minibatch Loss: 0.003422, Accuracy: 1.000000\n",
      "Step 29000: Minibatch Loss: 0.100840, Accuracy: 1.000000\n",
      "Step 30000: Minibatch Loss: 1.358311, Accuracy: 1.000000\n",
      "Step 31000: Minibatch Loss: 0.001540, Accuracy: 1.000000\n",
      "Step 32000: Minibatch Loss: 0.000737, Accuracy: 1.000000\n",
      "Step 33000: Minibatch Loss: 0.034738, Accuracy: 1.000000\n",
      "Step 34000: Minibatch Loss: 0.155555, Accuracy: 1.000000\n",
      "Step 35000: Minibatch Loss: 0.000277, Accuracy: 1.000000\n",
      "Step 36000: Minibatch Loss: 1.049803, Accuracy: 1.000000\n",
      "Step 37000: Minibatch Loss: 0.002426, Accuracy: 1.000000\n",
      "Step 38000: Minibatch Loss: 0.000108, Accuracy: 1.000000\n",
      "Step 39000: Minibatch Loss: 0.017193, Accuracy: 1.000000\n",
      "Step 40000: Minibatch Loss: 0.007532, Accuracy: 1.000000\n",
      "Step 41000: Minibatch Loss: 0.044202, Accuracy: 1.000000\n",
      "Step 42000: Minibatch Loss: 0.006734, Accuracy: 1.000000\n",
      "Step 43000: Minibatch Loss: 0.020814, Accuracy: 1.000000\n",
      "Step 44000: Minibatch Loss: 0.007721, Accuracy: 1.000000\n",
      "Step 45000: Minibatch Loss: 0.000939, Accuracy: 1.000000\n",
      "Step 46000: Minibatch Loss: 0.033444, Accuracy: 1.000000\n",
      "Step 47000: Minibatch Loss: 0.048273, Accuracy: 1.000000\n",
      "Step 48000: Minibatch Loss: 0.117495, Accuracy: 1.000000\n",
      "Step 49000: Minibatch Loss: 0.007661, Accuracy: 1.000000\n",
      "Step 50000: Minibatch Loss: 0.057953, Accuracy: 1.000000\n",
      "Full batch Accuracy: 0.951538\n",
      "0\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "Original Data\n",
      "[1 0 0]\n",
      "1\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "2\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "3\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "4\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "5\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "6\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "7\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "8\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "9\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "10\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "11\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "12\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "13\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "14\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "15\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "16\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "17\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "18\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "19\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "20\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "Original Data\n",
      "[0 0 1]\n",
      "21\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "22\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "23\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "24\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "25\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "26\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "27\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "28\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "29\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "30\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "Original Data\n",
      "[1 0 0]\n",
      "31\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "32\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "33\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "34\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "35\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "36\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "37\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "38\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "39\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "40\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "Original Data\n",
      "[0 0 1]\n",
      "41\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "42\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "43\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "44\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "45\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "46\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "47\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "48\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "49\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "50\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "51\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "52\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "53\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "54\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "55\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "56\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "57\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "58\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "59\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "60\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "Original Data\n",
      "[0 0 1]\n",
      "61\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "62\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "63\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "64\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "65\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "66\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "67\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "68\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "69\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "70\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "Original Data\n",
      "[1 0 0]\n",
      "71\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "72\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "73\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "74\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "75\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "76\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "77\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "78\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "79\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "80\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "81\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "82\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "83\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "84\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "85\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "86\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "87\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "88\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "89\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "90\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "91\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "92\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "93\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "94\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "95\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "96\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "97\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "98\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "99\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "100\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "Original Data\n",
      "[1 0 0]\n",
      "101\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "102\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "103\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "104\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "105\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "106\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "107\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "109\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "110\n",
      "Result of predicting EntireData\n",
      "[1 0 1 0 0 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "111\n",
      "Result of predicting EntireData\n",
      "[0 0 1 1 0 1 0 1 0 1]\n",
      "112\n",
      "Result of predicting EntireData\n",
      "[0 0 1 1 0 0 1 0 1 0]\n",
      "113\n",
      "Result of predicting EntireData\n",
      "[1 0 1 0 1 0 1 0 0 0]\n",
      "114\n",
      "Result of predicting EntireData\n",
      "[0 0 1 0 0 1 0 1 0 0]\n",
      "115\n",
      "Result of predicting EntireData\n",
      "[0 1 0 0 0 0 0 1 0 0]\n",
      "116\n",
      "Result of predicting EntireData\n",
      "[0 0 1 0 0 0 1 0 1 0]\n",
      "117\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 1 1 0 0 0]\n",
      "118\n",
      "Result of predicting EntireData\n",
      "[0 1 0 0 0 0 0 1 0 0]\n",
      "119\n",
      "Result of predicting EntireData\n",
      "[1 0 0 0 1 1 1 0 1 0]\n",
      "120\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "121\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "122\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "123\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "124\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "125\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "126\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "127\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "128\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "129\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Result of Test Data\n",
      "1 0 0\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Accuracy : 1.000000\n",
      "Result of Test Data\n",
      "0 1 0\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 0.930000\n",
      "Result of Test Data\n",
      "0 0 1\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "0 1 0\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "0 1 0\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "0 1 0\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 1.000000\n",
      "Result of Test Data\n",
      "1 0 0\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "0 1 0\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "0 1 0\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 1.000000\n",
      "Result of Test Data\n",
      "0 0 1\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "Accuracy : 1.000000\n",
      "Result of Test Data\n",
      "0 0 1\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "Accuracy : 1.000000\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(50001):\n",
    "        Order = Sequence[step % 130]\n",
    "        \n",
    "        batch_X = np.reshape(RealOESdata[Order*batchsize: (Order+1)*batchsize,:],\n",
    "                             (batchsize, n_InputUnit))\n",
    "        \n",
    "        batch_Y = np.reshape(Y_ClassifiedResult_Power[Order*batchsize: (Order+1)*batchsize,:],\n",
    "                             (batchsize, n_OutputUnit))\n",
    "        \n",
    "        _, MinibatchLoss = session.run([train, cost], feed_dict ={X: batch_X, Y: batch_Y})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={X: batch_X, Y: batch_Y})\n",
    "            print ('Step %i: Minibatch Loss: %f, Accuracy: %f' % (step, MinibatchLoss, train_accuracy))\n",
    "            \n",
    "        if step % 130 == 0:\n",
    "            random.shuffle(Sequence)\n",
    "            \n",
    "    train_accuracy = accuracy.eval(feed_dict = {X: RealOESdata, Y: Y_ClassifiedResult_Power})        \n",
    "    print('Full batch Accuracy: %f' % (train_accuracy))        \n",
    "            \n",
    "    for i in range(130):\n",
    "        Result_batch_X = np.reshape(RealOESdata[i*batchsize: (i+1)*batchsize,:],\n",
    "                                    (batchsize, n_InputUnit))\n",
    "        PredictedBatchData = session.run(prediction, feed_dict = {X : Result_batch_X})\n",
    "        Y_ClassifiedResult_Reshaped = np.reshape(Y_ClassifiedResult_Power[i*batchsize: (i+1)*batchsize,:],\n",
    "                                                 (batchsize, n_OutputUnit))\n",
    "        \n",
    "        print(i)\n",
    "        print(\"Result of predicting EntireData\")\n",
    "        print(PredictedBatchData)\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(\"Original Data\")\n",
    "            print(Y_ClassifiedResult_Reshaped[1,:])\n",
    "    \n",
    "   # print(\"R_square of EntireData\")\n",
    "   # print(r2_score(Y_ClassifiedResult, PredictedEntireData))\n",
    "    ############################################################################\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('3rd.xlsx') # LLMM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"1 0 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([1, 0, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([1, 0, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('9th.xlsx') # MMLL\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 1 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('13th.xlsx') # HHMM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 0 1\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 0, 1])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 0, 1])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('18th.xlsx') # MHHM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 1 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('19th.xlsx') # MHML\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 1 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('27th.xlsx') # MHMH\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 1 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('4th.xlsx') # LMHM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"1 0 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([1, 0, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([1, 0, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('10th.xlsx') # MLLM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 1 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('2nd.xlsx') # MLMH\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 1 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('6th.xlsx') # HMMH\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 0 1\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 0, 1])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 0, 1])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('8th.xlsx') # HMMM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 0 1\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 0, 1])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 0, 1])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Minibatch Loss: 0.765151, Minibatch Accuracy: 1.000000\n",
      "Step 1000: Minibatch Loss: 0.187470, Minibatch Accuracy: 1.000000\n",
      "Step 2000: Minibatch Loss: 0.161063, Minibatch Accuracy: 1.000000\n",
      "Step 3000: Minibatch Loss: 0.530998, Minibatch Accuracy: 1.000000\n",
      "Step 4000: Minibatch Loss: 0.427762, Minibatch Accuracy: 1.000000\n",
      "Step 5000: Minibatch Loss: 0.656414, Minibatch Accuracy: 1.000000\n",
      "Step 6000: Minibatch Loss: 0.000577, Minibatch Accuracy: 1.000000\n",
      "Step 7000: Minibatch Loss: 1.531613, Minibatch Accuracy: 0.000000\n",
      "Step 8000: Minibatch Loss: 0.468201, Minibatch Accuracy: 1.000000\n",
      "Step 9000: Minibatch Loss: 0.003329, Minibatch Accuracy: 1.000000\n",
      "Step 10000: Minibatch Loss: 0.382784, Minibatch Accuracy: 1.000000\n",
      "Step 11000: Minibatch Loss: 0.003104, Minibatch Accuracy: 1.000000\n",
      "Step 12000: Minibatch Loss: 0.891543, Minibatch Accuracy: 1.000000\n",
      "Step 13000: Minibatch Loss: 1.228444, Minibatch Accuracy: 0.000000\n",
      "Step 14000: Minibatch Loss: 1.476048, Minibatch Accuracy: 0.000000\n",
      "Step 15000: Minibatch Loss: 0.389360, Minibatch Accuracy: 1.000000\n",
      "Step 16000: Minibatch Loss: 0.540931, Minibatch Accuracy: 1.000000\n",
      "Step 17000: Minibatch Loss: 0.000171, Minibatch Accuracy: 1.000000\n",
      "Step 18000: Minibatch Loss: 0.171985, Minibatch Accuracy: 1.000000\n",
      "Step 19000: Minibatch Loss: 0.412139, Minibatch Accuracy: 1.000000\n",
      "Step 20000: Minibatch Loss: 0.272727, Minibatch Accuracy: 1.000000\n",
      "Step 21000: Minibatch Loss: 0.461387, Minibatch Accuracy: 1.000000\n",
      "Step 22000: Minibatch Loss: 0.000002, Minibatch Accuracy: 1.000000\n",
      "Step 23000: Minibatch Loss: 0.000051, Minibatch Accuracy: 1.000000\n",
      "Step 24000: Minibatch Loss: 0.006772, Minibatch Accuracy: 1.000000\n",
      "Step 25000: Minibatch Loss: 0.000111, Minibatch Accuracy: 1.000000\n",
      "Step 26000: Minibatch Loss: 0.979595, Minibatch Accuracy: 1.000000\n",
      "Step 27000: Minibatch Loss: 0.221904, Minibatch Accuracy: 1.000000\n",
      "Step 28000: Minibatch Loss: 0.037848, Minibatch Accuracy: 1.000000\n",
      "Step 29000: Minibatch Loss: 0.572515, Minibatch Accuracy: 1.000000\n",
      "Step 30000: Minibatch Loss: 0.561064, Minibatch Accuracy: 1.000000\n",
      "Step 31000: Minibatch Loss: 0.000222, Minibatch Accuracy: 1.000000\n",
      "Step 32000: Minibatch Loss: 0.007058, Minibatch Accuracy: 1.000000\n",
      "Step 33000: Minibatch Loss: 0.198482, Minibatch Accuracy: 1.000000\n",
      "Step 34000: Minibatch Loss: 0.003560, Minibatch Accuracy: 1.000000\n",
      "Step 35000: Minibatch Loss: 0.403243, Minibatch Accuracy: 1.000000\n",
      "Step 36000: Minibatch Loss: 1.496702, Minibatch Accuracy: 1.000000\n",
      "Step 37000: Minibatch Loss: 0.000000, Minibatch Accuracy: 1.000000\n",
      "Step 38000: Minibatch Loss: 0.036105, Minibatch Accuracy: 1.000000\n",
      "Step 39000: Minibatch Loss: 0.014320, Minibatch Accuracy: 1.000000\n",
      "Step 40000: Minibatch Loss: 0.146640, Minibatch Accuracy: 1.000000\n",
      "Step 41000: Minibatch Loss: 0.000022, Minibatch Accuracy: 1.000000\n",
      "Step 42000: Minibatch Loss: 0.028137, Minibatch Accuracy: 1.000000\n",
      "Step 43000: Minibatch Loss: 0.000121, Minibatch Accuracy: 1.000000\n",
      "Step 44000: Minibatch Loss: 0.000000, Minibatch Accuracy: 1.000000\n",
      "Step 45000: Minibatch Loss: 0.072616, Minibatch Accuracy: 1.000000\n",
      "Step 46000: Minibatch Loss: 0.000002, Minibatch Accuracy: 1.000000\n",
      "Step 47000: Minibatch Loss: 0.027263, Minibatch Accuracy: 1.000000\n",
      "Step 48000: Minibatch Loss: 0.000000, Minibatch Accuracy: 1.000000\n",
      "Step 49000: Minibatch Loss: 0.027465, Minibatch Accuracy: 1.000000\n",
      "Step 50000: Minibatch Loss: 0.000358, Minibatch Accuracy: 1.000000\n",
      "Full batch Accuracy: 0.995385\n",
      "0\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "1\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "2\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "3\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "4\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "5\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "6\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "7\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "8\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "9\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "10\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "Original Data\n",
      "[1 0 0]\n",
      "11\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "12\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "13\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "14\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "15\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "16\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "17\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "18\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "19\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "20\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "21\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "22\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "23\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "24\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "25\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "26\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "27\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "28\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "29\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "30\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "31\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "32\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "33\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "34\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "35\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "36\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "37\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "38\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "39\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "40\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "41\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "42\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "43\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "44\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "45\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "46\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "47\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "48\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "49\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "50\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "Original Data\n",
      "[1 0 0]\n",
      "51\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "52\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "53\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "54\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "55\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "56\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "57\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "58\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "59\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "60\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "61\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "62\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "63\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "64\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "65\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "66\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "67\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "68\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "69\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "70\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "71\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "72\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "73\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "74\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "75\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "76\n",
      "Result of predicting EntireData\n",
      "[1 2 2 2 2 2 2 1 1 1]\n",
      "77\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "78\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "79\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "80\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "81\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "82\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "83\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "84\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "85\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "86\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "87\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "88\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "89\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "90\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "91\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "92\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "93\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "94\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "95\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "96\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "97\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "98\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "99\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "100\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "Original Data\n",
      "[0 0 1]\n",
      "101\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "102\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "103\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "104\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "105\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "106\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "107\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "108\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "109\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "110\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "Original Data\n",
      "[0 0 1]\n",
      "111\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "112\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "113\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "114\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "115\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "116\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "117\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "118\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "119\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "120\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "121\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "122\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "123\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "124\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "125\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "126\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "127\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "128\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "129\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of Test Data\n",
      "1 0 0\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "0 1 0\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "0 0 1\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "0 0 1\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "0 0 1\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "0 0 1\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "Accuracy : 1.000000\n",
      "Result of Test Data\n",
      "0 1 0\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "1 0 0\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "1 0 0\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "0 1 0\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 1.000000\n",
      "Result of Test Data\n",
      "0, 1, 0\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 1.000000\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(50001):\n",
    "        Order = Sequence[step % 130]\n",
    "        \n",
    "        batch_X = np.reshape(RealOESdata[Order*batchsize: (Order+1)*batchsize,:],\n",
    "                             (batchsize, n_InputUnit))\n",
    "        \n",
    "        batch_Y = np.reshape(Y_ClassifiedResult_Press[Order*batchsize: (Order+1)*batchsize,:],\n",
    "                             (batchsize, n_OutputUnit))\n",
    "        \n",
    "        _, MinibatchLoss = session.run([train, cost], feed_dict ={X: batch_X, Y: batch_Y})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={X: batch_X, Y: batch_Y})\n",
    "            print ('Step %i: Minibatch Loss: %f, Minibatch Accuracy: %f' % (step, MinibatchLoss, train_accuracy))\n",
    "            \n",
    "        if step % 130 == 0:\n",
    "            random.shuffle(Sequence)\n",
    "            \n",
    "    train_accuracy = accuracy.eval(feed_dict = {X: RealOESdata, Y: Y_ClassifiedResult_Press})        \n",
    "    print('Full batch Accuracy: %f' % (train_accuracy))\n",
    "            \n",
    "    for i in range(130):\n",
    "        Result_batch_X = np.reshape(RealOESdata[i*batchsize: (i+1)*batchsize,:],\n",
    "                                    (batchsize, n_InputUnit))\n",
    "        PredictedBatchData = session.run(prediction, feed_dict = {X : Result_batch_X})\n",
    "        Y_ClassifiedResult_Reshaped = np.reshape(Y_ClassifiedResult_Press[i*batchsize: (i+1)*batchsize,:],\n",
    "                                                 (batchsize, n_OutputUnit))\n",
    "        \n",
    "        print(i)\n",
    "        print(\"Result of predicting EntireData\")\n",
    "        print(PredictedBatchData)\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(\"Original Data\")\n",
    "            print(Y_ClassifiedResult_Reshaped[1,:])\n",
    "    \n",
    "   # print(\"R_square of EntireData\")\n",
    "   # print(r2_score(Y_ClassifiedResult, PredictedEntireData))\n",
    "    ############################################################################\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('3rd.xlsx') # LLMM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"1 0 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([1, 0, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([1, 0, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('9th.xlsx') # MMLL\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 1 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('13th.xlsx') # HHMM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 0 1\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 0, 1])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 0, 1])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('18th.xlsx') # MHHM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 0 1\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 0, 1])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 0, 1])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('19th.xlsx') # MHML\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 0 1\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 0, 1])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 0, 1])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('27th.xlsx') # MHMH\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 0 1\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 0, 1])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 0, 1])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('4th.xlsx') # LMHM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 1 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('10th.xlsx') # MLLM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"1 0 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([1, 0, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([1, 0, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('2nd.xlsx') # MLMH\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"1 0 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([1, 0, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([1, 0, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('6th.xlsx') # HMMH\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 1 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('8th.xlsx') # HMMM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0, 1, 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C3H6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Minibatch Loss: 3.864347, Accuracy: 0.900000\n",
      "Step 1000: Minibatch Loss: 0.113140, Accuracy: 1.000000\n",
      "Step 2000: Minibatch Loss: 0.279054, Accuracy: 1.000000\n",
      "Step 3000: Minibatch Loss: 0.826382, Accuracy: 1.000000\n",
      "Step 4000: Minibatch Loss: 0.011942, Accuracy: 1.000000\n",
      "Step 5000: Minibatch Loss: 0.231621, Accuracy: 1.000000\n",
      "Step 6000: Minibatch Loss: 0.005681, Accuracy: 1.000000\n",
      "Step 7000: Minibatch Loss: 0.501196, Accuracy: 1.000000\n",
      "Step 8000: Minibatch Loss: 0.242379, Accuracy: 1.000000\n",
      "Step 9000: Minibatch Loss: 0.125978, Accuracy: 1.000000\n",
      "Step 10000: Minibatch Loss: 1.951688, Accuracy: 0.000000\n",
      "Step 11000: Minibatch Loss: 0.355787, Accuracy: 1.000000\n",
      "Step 12000: Minibatch Loss: 0.204575, Accuracy: 1.000000\n",
      "Step 13000: Minibatch Loss: 0.214338, Accuracy: 1.000000\n",
      "Step 14000: Minibatch Loss: 0.930477, Accuracy: 1.000000\n",
      "Step 15000: Minibatch Loss: 0.047574, Accuracy: 1.000000\n",
      "Step 16000: Minibatch Loss: 0.128180, Accuracy: 1.000000\n",
      "Step 17000: Minibatch Loss: 0.966347, Accuracy: 1.000000\n",
      "Step 18000: Minibatch Loss: 0.981732, Accuracy: 1.000000\n",
      "Step 19000: Minibatch Loss: 1.467963, Accuracy: 0.000000\n",
      "Step 20000: Minibatch Loss: 0.000047, Accuracy: 1.000000\n",
      "Step 21000: Minibatch Loss: 0.077447, Accuracy: 1.000000\n",
      "Step 22000: Minibatch Loss: 0.038876, Accuracy: 1.000000\n",
      "Step 23000: Minibatch Loss: 0.356940, Accuracy: 1.000000\n",
      "Step 24000: Minibatch Loss: 0.275969, Accuracy: 1.000000\n",
      "Step 25000: Minibatch Loss: 1.598874, Accuracy: 0.000000\n",
      "Step 26000: Minibatch Loss: 0.028007, Accuracy: 1.000000\n",
      "Step 27000: Minibatch Loss: 0.015647, Accuracy: 1.000000\n",
      "Step 28000: Minibatch Loss: 0.000005, Accuracy: 1.000000\n",
      "Step 29000: Minibatch Loss: 0.072437, Accuracy: 1.000000\n",
      "Step 30000: Minibatch Loss: 0.148020, Accuracy: 1.000000\n",
      "Step 31000: Minibatch Loss: 0.002023, Accuracy: 1.000000\n",
      "Step 32000: Minibatch Loss: 0.390335, Accuracy: 1.000000\n",
      "Step 33000: Minibatch Loss: 0.649639, Accuracy: 1.000000\n",
      "Step 34000: Minibatch Loss: 0.000002, Accuracy: 1.000000\n",
      "Step 35000: Minibatch Loss: 0.000011, Accuracy: 1.000000\n",
      "Step 36000: Minibatch Loss: 0.094136, Accuracy: 1.000000\n",
      "Step 37000: Minibatch Loss: 0.961228, Accuracy: 1.000000\n",
      "Step 38000: Minibatch Loss: 0.113262, Accuracy: 1.000000\n",
      "Step 39000: Minibatch Loss: 0.504865, Accuracy: 1.000000\n",
      "Step 40000: Minibatch Loss: 0.111573, Accuracy: 1.000000\n",
      "Step 41000: Minibatch Loss: 0.000000, Accuracy: 1.000000\n",
      "Step 42000: Minibatch Loss: 0.053256, Accuracy: 1.000000\n",
      "Step 43000: Minibatch Loss: 0.005105, Accuracy: 1.000000\n",
      "Step 44000: Minibatch Loss: 0.023957, Accuracy: 1.000000\n",
      "Step 45000: Minibatch Loss: 0.038068, Accuracy: 1.000000\n",
      "Step 46000: Minibatch Loss: 0.000607, Accuracy: 1.000000\n",
      "Step 47000: Minibatch Loss: 0.131557, Accuracy: 1.000000\n",
      "Step 48000: Minibatch Loss: 0.594379, Accuracy: 1.000000\n",
      "Step 49000: Minibatch Loss: 0.000048, Accuracy: 1.000000\n",
      "Step 50000: Minibatch Loss: 0.008392, Accuracy: 1.000000\n",
      "Full batch Accuracy: 0.920000\n",
      "0\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "1\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "2\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "3\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "4\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "5\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "6\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "7\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "8\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "9\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "10\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "Original Data\n",
      "[0 0 1]\n",
      "11\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "12\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "13\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "14\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "15\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "16\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "17\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "18\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "19\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "20\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "21\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 2 1 1 1]\n",
      "22\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "23\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "24\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "25\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "26\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "27\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "28\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "29\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "30\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "Original Data\n",
      "[1 0 0]\n",
      "31\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "32\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "33\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "34\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "35\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "36\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "37\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "38\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "39\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "40\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "Original Data\n",
      "[0 0 1]\n",
      "41\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "42\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "43\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "44\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "45\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "46\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "47\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "48\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "49\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "50\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "51\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "52\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "53\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "54\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "55\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "56\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "57\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "58\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "59\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "60\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "Original Data\n",
      "[1 0 0]\n",
      "61\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "62\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "63\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "64\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "65\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "66\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "67\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "68\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "69\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "70\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "71\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "72\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "73\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "74\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "75\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "76\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "77\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "78\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "79\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "80\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "Original Data\n",
      "[0 0 1]\n",
      "81\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "82\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "83\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "84\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "85\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "86\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "87\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "88\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "89\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "90\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "Original Data\n",
      "[1 0 0]\n",
      "91\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "92\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "93\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "94\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "95\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "96\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "97\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "98\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "99\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "100\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "101\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "102\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "103\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "104\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "105\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "106\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "107\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "108\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "109\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "110\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 0 1 1 1]\n",
      "Original Data\n",
      "[1 0 0]\n",
      "111\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "112\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 0 1]\n",
      "113\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 0 1 0 1 1 1]\n",
      "114\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "115\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "116\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "117\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 0 0 1 1 1]\n",
      "118\n",
      "Result of predicting EntireData\n",
      "[1 0 1 1 1 1 1 0 1 1]\n",
      "119\n",
      "Result of predicting EntireData\n",
      "[1 1 1 0 1 0 1 1 0 1]\n",
      "120\n",
      "Result of predicting EntireData\n",
      "[1 1 2 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "121\n",
      "Result of predicting EntireData\n",
      "[1 2 2 1 1 1 1 1 2 1]\n",
      "122\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 2 2 1 1 1 1]\n",
      "123\n",
      "Result of predicting EntireData\n",
      "[1 2 2 1 1 1 1 2 1 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 2 1 1 1 1 1]\n",
      "125\n",
      "Result of predicting EntireData\n",
      "[1 1 2 1 1 1 2 1 1 1]\n",
      "126\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 2 1 1 1 1 1]\n",
      "127\n",
      "Result of predicting EntireData\n",
      "[1 1 2 1 1 1 1 1 1 1]\n",
      "128\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "129\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Result of Test Data\n",
      "0 1 0\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "1 0 0\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Accuracy : 1.000000\n",
      "Result of Test Data\n",
      "0 1 0\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "0 0 1\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "0 1 0\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 1.000000\n",
      "Result of Test Data\n",
      "0 1 0\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "0 0 1\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "Accuracy : 1.000000\n",
      "Result of Test Data\n",
      "1 0 0\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Accuracy : 1.000000\n",
      "Result of Test Data\n",
      "0 1 0\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "0 1 0\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "0, 1, 0\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Accuracy : 0.000000\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(50001):\n",
    "        Order = Sequence[step % 130]\n",
    "        \n",
    "        batch_X = np.reshape(RealOESdata[Order*batchsize: (Order+1)*batchsize,:],\n",
    "                             (batchsize, n_InputUnit))\n",
    "        \n",
    "        batch_Y = np.reshape(Y_ClassifiedResult_C3H6[Order*batchsize: (Order+1)*batchsize,:],\n",
    "                             (batchsize, n_OutputUnit))\n",
    "        \n",
    "        _, MinibatchLoss = session.run([train, cost], feed_dict ={X: batch_X, Y: batch_Y})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={X: batch_X, Y: batch_Y})\n",
    "            print ('Step %i: Minibatch Loss: %f, Accuracy: %f' % (step, MinibatchLoss, train_accuracy))\n",
    "            \n",
    "        if step % 130 == 0:\n",
    "            random.shuffle(Sequence)\n",
    "            \n",
    "    train_accuracy = accuracy.eval(feed_dict = {X: RealOESdata, Y: Y_ClassifiedResult_C3H6})        \n",
    "    print('Full batch Accuracy: %f' % (train_accuracy))           \n",
    "            \n",
    "    for i in range(130):\n",
    "        Result_batch_X = np.reshape(RealOESdata[i*batchsize: (i+1)*batchsize,:],\n",
    "                                    (batchsize, n_InputUnit))\n",
    "        PredictedBatchData = session.run(prediction, feed_dict = {X : Result_batch_X})\n",
    "        Y_ClassifiedResult_Reshaped = np.reshape(Y_ClassifiedResult_C3H6[i*batchsize: (i+1)*batchsize,:],\n",
    "                                                 (batchsize, n_OutputUnit))\n",
    "        \n",
    "        print(i)\n",
    "        print(\"Result of predicting EntireData\")\n",
    "        print(PredictedBatchData)\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(\"Original Data\")\n",
    "            print(Y_ClassifiedResult_Reshaped[1,:])\n",
    "    \n",
    "   # print(\"R_square of EntireData\")\n",
    "   # print(r2_score(Y_ClassifiedResult, PredictedEntireData))\n",
    "    ############################################################################\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('3rd.xlsx') # LLMM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 1 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('9th.xlsx') # MMLL\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"1 0 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([1, 0, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([1, 0, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('13th.xlsx') # HHMM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 1 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('18th.xlsx') # MHHM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 0 1\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 0, 1])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 0, 1])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('19th.xlsx') # MHML\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 1 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('27th.xlsx') # MHMH\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 1 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('4th.xlsx') # LMHM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 0 1\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 0, 1])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 0, 1])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('10th.xlsx') # MLLM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"1 0 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([1, 0, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([1, 0, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('2nd.xlsx') # MLMH\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 1 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('6th.xlsx') # HMMH\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 1 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('8th.xlsx') # HMMM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0, 1, 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Minibatch Loss: 0.510511, Accuracy: 1.000000\n",
      "Step 1000: Minibatch Loss: 0.356271, Accuracy: 1.000000\n",
      "Step 2000: Minibatch Loss: 0.228132, Accuracy: 1.000000\n",
      "Step 3000: Minibatch Loss: 1.017759, Accuracy: 1.000000\n",
      "Step 4000: Minibatch Loss: 0.496951, Accuracy: 1.000000\n",
      "Step 5000: Minibatch Loss: 1.565549, Accuracy: 1.000000\n",
      "Step 6000: Minibatch Loss: 0.161134, Accuracy: 1.000000\n",
      "Step 7000: Minibatch Loss: 0.002776, Accuracy: 1.000000\n",
      "Step 8000: Minibatch Loss: 0.052605, Accuracy: 1.000000\n",
      "Step 9000: Minibatch Loss: 0.588712, Accuracy: 1.000000\n",
      "Step 10000: Minibatch Loss: 0.100051, Accuracy: 1.000000\n",
      "Step 11000: Minibatch Loss: 0.026210, Accuracy: 1.000000\n",
      "Step 12000: Minibatch Loss: 1.047532, Accuracy: 1.000000\n",
      "Step 13000: Minibatch Loss: 1.402959, Accuracy: 1.000000\n",
      "Step 14000: Minibatch Loss: 0.006599, Accuracy: 1.000000\n",
      "Step 15000: Minibatch Loss: 0.543661, Accuracy: 1.000000\n",
      "Step 16000: Minibatch Loss: 0.023506, Accuracy: 1.000000\n",
      "Step 17000: Minibatch Loss: 0.060631, Accuracy: 1.000000\n",
      "Step 18000: Minibatch Loss: 0.001503, Accuracy: 1.000000\n",
      "Step 19000: Minibatch Loss: 0.009976, Accuracy: 1.000000\n",
      "Step 20000: Minibatch Loss: 0.004258, Accuracy: 1.000000\n",
      "Step 21000: Minibatch Loss: 0.001585, Accuracy: 1.000000\n",
      "Step 22000: Minibatch Loss: 0.000019, Accuracy: 1.000000\n",
      "Step 23000: Minibatch Loss: 0.003890, Accuracy: 1.000000\n",
      "Step 24000: Minibatch Loss: 0.768025, Accuracy: 1.000000\n",
      "Step 25000: Minibatch Loss: 0.001251, Accuracy: 1.000000\n",
      "Step 26000: Minibatch Loss: 0.001827, Accuracy: 1.000000\n",
      "Step 27000: Minibatch Loss: 0.002379, Accuracy: 1.000000\n",
      "Step 28000: Minibatch Loss: 1.107141, Accuracy: 1.000000\n",
      "Step 29000: Minibatch Loss: 0.867293, Accuracy: 1.000000\n",
      "Step 30000: Minibatch Loss: 0.004768, Accuracy: 1.000000\n",
      "Step 31000: Minibatch Loss: 1.759141, Accuracy: 1.000000\n",
      "Step 32000: Minibatch Loss: 0.007178, Accuracy: 1.000000\n",
      "Step 33000: Minibatch Loss: 0.001294, Accuracy: 1.000000\n",
      "Step 34000: Minibatch Loss: 0.578105, Accuracy: 1.000000\n",
      "Step 35000: Minibatch Loss: 0.006081, Accuracy: 1.000000\n",
      "Step 36000: Minibatch Loss: 0.000111, Accuracy: 1.000000\n",
      "Step 37000: Minibatch Loss: 0.057490, Accuracy: 1.000000\n",
      "Step 38000: Minibatch Loss: 0.006757, Accuracy: 1.000000\n",
      "Step 39000: Minibatch Loss: 0.000227, Accuracy: 1.000000\n",
      "Step 40000: Minibatch Loss: 0.539136, Accuracy: 1.000000\n",
      "Step 41000: Minibatch Loss: 0.025623, Accuracy: 1.000000\n",
      "Step 42000: Minibatch Loss: 0.000271, Accuracy: 1.000000\n",
      "Step 43000: Minibatch Loss: 0.000963, Accuracy: 1.000000\n",
      "Step 44000: Minibatch Loss: 0.007982, Accuracy: 1.000000\n",
      "Step 45000: Minibatch Loss: 0.000112, Accuracy: 1.000000\n",
      "Step 46000: Minibatch Loss: 0.008693, Accuracy: 1.000000\n",
      "Step 47000: Minibatch Loss: 0.000300, Accuracy: 1.000000\n",
      "Step 48000: Minibatch Loss: 0.000465, Accuracy: 1.000000\n",
      "Step 49000: Minibatch Loss: 0.037149, Accuracy: 1.000000\n",
      "Step 50000: Minibatch Loss: 0.001388, Accuracy: 1.000000\n",
      "Full batch Accuracy: 0.923077\n",
      "0\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "Original Data\n",
      "[1 0 0]\n",
      "1\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "2\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "3\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "4\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "5\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "6\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "7\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "8\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "9\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "10\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "11\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "12\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "13\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "14\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "15\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "16\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "17\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "18\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "19\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "20\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "Original Data\n",
      "[1 0 0]\n",
      "21\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "22\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "23\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "24\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "25\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "26\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "27\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "28\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "29\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "30\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "31\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "32\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "33\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "34\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "35\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "36\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "37\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "38\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "39\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "40\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "41\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "42\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "43\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "44\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "45\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "46\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "47\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "48\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "49\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "50\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "Original Data\n",
      "[1 0 0]\n",
      "51\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "52\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "53\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "54\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "55\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "56\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "57\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "58\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "59\n",
      "Result of predicting EntireData\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "60\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "61\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "62\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "63\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "64\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "65\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "66\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "67\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "68\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "69\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "70\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "Original Data\n",
      "[0 0 1]\n",
      "71\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "72\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "73\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "74\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "75\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "76\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "77\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "78\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "79\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "80\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "Original Data\n",
      "[0 0 1]\n",
      "81\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "82\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "83\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "84\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "85\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "86\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "87\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "88\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "89\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "90\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "Original Data\n",
      "[0 0 1]\n",
      "91\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "92\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "93\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "94\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "95\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "96\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "97\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "98\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "99\n",
      "Result of predicting EntireData\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "100\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "101\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "102\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "103\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "104\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "106\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "107\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "108\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "109\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "110\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "111\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "112\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "113\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "114\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "115\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "116\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "117\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "118\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "119\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "120\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Original Data\n",
      "[0 1 0]\n",
      "121\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "122\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "123\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "124\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "125\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "126\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "127\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "128\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "129\n",
      "Result of predicting EntireData\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Result of Test Data\n",
      "0 1 0\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "1 0 0\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "0 1 0\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 1.000000\n",
      "Result of Test Data\n",
      "0 1 0\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Accuracy : 0.000000\n",
      "Result of Test Data\n",
      "1 0 0\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Accuracy : 1.000000\n",
      "Result of Test Data\n",
      "0 0 1\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "Accuracy : 1.000000\n",
      "Result of Test Data\n",
      "0 1 0\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 1.000000\n",
      "Result of Test Data\n",
      "0 1 0\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 1.000000\n",
      "Result of Test Data\n",
      "0 0 1\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "Accuracy : 1.000000\n",
      "Result of Test Data\n",
      "0 0 1\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "Accuracy : 1.000000\n",
      "Result of Test Data\n",
      "0, 1, 0\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy : 1.000000\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(50001):\n",
    "        Order = Sequence[step % 130]\n",
    "        \n",
    "        batch_X = np.reshape(RealOESdata[Order*batchsize: (Order+1)*batchsize,:],\n",
    "                             (batchsize, n_InputUnit))\n",
    "        \n",
    "        batch_Y = np.reshape(Y_ClassifiedResult_N2[Order*batchsize: (Order+1)*batchsize,:],\n",
    "                             (batchsize, n_OutputUnit))\n",
    "        \n",
    "        _, MinibatchLoss = session.run([train, cost], feed_dict ={X: batch_X, Y: batch_Y})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={X: batch_X, Y: batch_Y})\n",
    "            print ('Step %i: Minibatch Loss: %f, Accuracy: %f' % (step, MinibatchLoss, train_accuracy))\n",
    "            \n",
    "        if step % 130 == 0:\n",
    "            random.shuffle(Sequence)\n",
    "            \n",
    "    train_accuracy = accuracy.eval(feed_dict = {X: RealOESdata, Y: Y_ClassifiedResult_N2})        \n",
    "    print('Full batch Accuracy: %f' % (train_accuracy))             \n",
    "            \n",
    "    for i in range(130):\n",
    "        Result_batch_X = np.reshape(RealOESdata[i*batchsize: (i+1)*batchsize,:],\n",
    "                                    (batchsize, n_InputUnit))\n",
    "        PredictedBatchData = session.run(prediction, feed_dict = {X : Result_batch_X})\n",
    "        Y_ClassifiedResult_Reshaped = np.reshape(Y_ClassifiedResult_N2[i*batchsize: (i+1)*batchsize,:],\n",
    "                                                 (batchsize, n_OutputUnit))\n",
    "        \n",
    "        print(i)\n",
    "        print(\"Result of predicting EntireData\")\n",
    "        print(PredictedBatchData)\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(\"Original Data\")\n",
    "            print(Y_ClassifiedResult_Reshaped[1,:])\n",
    "    \n",
    "   # print(\"R_square of EntireData\")\n",
    "   # print(r2_score(Y_ClassifiedResult, PredictedEntireData))\n",
    "    ############################################################################\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('3rd.xlsx') # LLMM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 1 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('9th.xlsx') # MMLL\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"1 0 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([1, 0, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([1, 0, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('13th.xlsx') # HHMM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 1 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('18th.xlsx') # MHHM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 1 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('19th.xlsx') # MHML\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"1 0 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([1, 0, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([1, 0, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('27th.xlsx') # MHMH\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 0 1\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 0, 1])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 0, 1])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('4th.xlsx') # LMHM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 1 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('10th.xlsx') # MLLM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 1 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('2nd.xlsx') # MLMH\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 0 1\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 0, 1])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 0, 1])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('6th.xlsx') # HMMH\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0 0 1\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 0, 1])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 0, 1])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))\n",
    "    \n",
    "    #-------------------------------------------#\n",
    "    data2 = pd.read_excel('8th.xlsx') # HMMM\n",
    "    data2 = data2.values\n",
    "    TestOESdata = data2[151:251,1:]\n",
    "    \n",
    "    Result_Test_X = np.reshape(TestOESdata, (100, n_InputUnit))\n",
    "    Result_Test_Y = session.run(prediction, feed_dict = {X : Result_Test_X})\n",
    "    \n",
    "    print(\"Result of Test Data\")\n",
    "    print(\"0, 1, 0\")\n",
    "    print(Result_Test_Y)\n",
    "    \n",
    "    Y_Test = np.array([0, 1, 0])\n",
    "    for i in range(99):\n",
    "        Y_Test = np.vstack((Y_Test, np.array([0, 1, 0])))    \n",
    "        \n",
    "    train_accuracy = accuracy.eval(feed_dict={X: TestOESdata, Y: Y_Test})\n",
    "    \n",
    "    print('Accuracy : %f' % (train_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Algorithm which decides standard for classifying data\n",
    "# Algorithm which can detect some kind of different phenomena\n",
    "\n",
    "W11 = tf.Variable(tf.random_normal([n_InputUnit, n_1stHiddenUnit],stddev=0.01))\n",
    "W12 = tf.Variable(tf.random_normal([n_1stHiddenUnit, n_2ndHiddenUnit],stddev=0.01))\n",
    "W13 = tf.Variable(tf.random_normal([n_2ndHiddenUnit, n_OutputUnit],stddev=0.01))\n",
    "\n",
    "b11 = tf.Variable(tf.random_normal([n_1stHiddenUnit], stddev=0.01))\n",
    "b12 = tf.Variable(tf.random_normal([n_2ndHiddenUnit], stddev=0.01))\n",
    "b13 = tf.Variable(tf.random_normal([n_OutputUnit], stddev=0.01))\n",
    "\n",
    "X1 = tf.placeholder(tf.float32, [None, n_InputUnit]) # tensorflow의 placeholder라는 변수를 선언\n",
    "Y1 = tf.placeholder(tf.float32, [None, n_OutputUnit])\n",
    "\n",
    "L11 = tf.nn.relu(tf.matmul(X1, W11) + b11)\n",
    "L12 = tf.nn.relu(tf.matmul(L11, W12) + b12)\n",
    "Hypothesis1 = tf.nn.relu(tf.matmul(L12, W13) + b13)\n",
    "\n",
    "cost1 = tf.reduce_mean(tf.pow(Y1 - Hypothesis1, 2))\n",
    "train1 = tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=0.5).minimize(cost1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm which decides standard for classifying data\n",
    "# Algorithm which can detect some kind of different phenomena\n",
    "\n",
    "W21 = tf.Variable(tf.random_normal([n_InputUnit, n_1stHiddenUnit],stddev=0.01))\n",
    "W22 = tf.Variable(tf.random_normal([n_1stHiddenUnit, n_2ndHiddenUnit],stddev=0.01))\n",
    "W23 = tf.Variable(tf.random_normal([n_2ndHiddenUnit, n_OutputUnit],stddev=0.01))\n",
    "\n",
    "b21 = tf.Variable(tf.random_normal([n_1stHiddenUnit], stddev=0.01))\n",
    "b22 = tf.Variable(tf.random_normal([n_2ndHiddenUnit], stddev=0.01))\n",
    "b23 = tf.Variable(tf.random_normal([n_OutputUnit], stddev=0.01))\n",
    "\n",
    "X2 = tf.placeholder(tf.float32, [None, n_InputUnit]) # tensorflow의 placeholder라는 변수를 선언\n",
    "Y2 = tf.placeholder(tf.float32, [None, n_OutputUnit])\n",
    "\n",
    "L21 = tf.nn.relu(tf.matmul(X2, W21) + b21)\n",
    "L22 = tf.nn.relu(tf.matmul(L21, W22) + b22)\n",
    "Hypothesis2 = tf.nn.relu(tf.matmul(L22, W23) + b23)\n",
    "\n",
    "cost2 = tf.reduce_mean(tf.pow(Y2 - Hypothesis2, 2))\n",
    "train2 = tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=0.5).minimize(cost2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C3H6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm which decides standard for classifying data\n",
    "# Algorithm which can detect some kind of different phenomena\n",
    "\n",
    "W31 = tf.Variable(tf.random_normal([n_InputUnit, n_1stHiddenUnit],stddev=0.01))\n",
    "W32 = tf.Variable(tf.random_normal([n_1stHiddenUnit, n_2ndHiddenUnit],stddev=0.01))\n",
    "W33 = tf.Variable(tf.random_normal([n_2ndHiddenUnit, n_OutputUnit],stddev=0.01))\n",
    "\n",
    "b31 = tf.Variable(tf.random_normal([n_1stHiddenUnit], stddev=0.01))\n",
    "b32 = tf.Variable(tf.random_normal([n_2ndHiddenUnit], stddev=0.01))\n",
    "b33 = tf.Variable(tf.random_normal([n_OutputUnit], stddev=0.01))\n",
    "\n",
    "X3 = tf.placeholder(tf.float32, [None, n_InputUnit]) # tensorflow의 placeholder라는 변수를 선언\n",
    "Y3 = tf.placeholder(tf.float32, [None, n_OutputUnit])\n",
    "\n",
    "L31 = tf.nn.relu(tf.matmul(X3, W31) + b31)\n",
    "L32 = tf.nn.relu(tf.matmul(L31, W32) + b32)\n",
    "Hypothesis3 = tf.nn.relu(tf.matmul(L32, W33) + b33)\n",
    "\n",
    "cost3 = tf.reduce_mean(tf.pow(Y3 - Hypothesis3, 2))\n",
    "train3 = tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=0.5).minimize(cost3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm which decides standard for classifying data\n",
    "# Algorithm which can detect some kind of different phenomena\n",
    "\n",
    "W41 = tf.Variable(tf.random_normal([n_InputUnit, n_1stHiddenUnit],stddev=0.01))\n",
    "W42 = tf.Variable(tf.random_normal([n_1stHiddenUnit, n_2ndHiddenUnit],stddev=0.01))\n",
    "W43 = tf.Variable(tf.random_normal([n_2ndHiddenUnit, n_OutputUnit],stddev=0.01))\n",
    "\n",
    "b41 = tf.Variable(tf.random_normal([n_1stHiddenUnit], stddev=0.01))\n",
    "b42 = tf.Variable(tf.random_normal([n_2ndHiddenUnit], stddev=0.01))\n",
    "b43 = tf.Variable(tf.random_normal([n_OutputUnit], stddev=0.01))\n",
    "\n",
    "X4 = tf.placeholder(tf.float32, [None, n_InputUnit]) # tensorflow의 placeholder라는 변수를 선언\n",
    "Y4 = tf.placeholder(tf.float32, [None, n_OutputUnit])\n",
    "\n",
    "L41 = tf.nn.relu(tf.matmul(X4, W41) + b41)\n",
    "L42 = tf.nn.relu(tf.matmul(L41, W42) + b42)\n",
    "Hypothesis4 = tf.nn.relu(tf.matmul(L42, W43) + b43)\n",
    "\n",
    "cost4 = tf.reduce_mean(tf.pow(Y4 - Hypothesis4, 2))\n",
    "train4 = tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=0.5).minimize(cost4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "828.391px",
    "left": "1521px",
    "right": "20px",
    "top": "113px",
    "width": "379px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
