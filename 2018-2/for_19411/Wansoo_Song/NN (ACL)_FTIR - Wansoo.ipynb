{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n",
    "\n",
    "# 2nd eLU, tanh, 4, 50, 50, 50, 1\n",
    "## Model\n",
    "## Train NN & Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data (normalized) & Separate to Training and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5  0.5  1.   1. ]\n",
      " [ 0.5  0.   0.5  1. ]\n",
      " [ 0.   0.   0.5  0.5]\n",
      " [ 0.   0.5  1.   0.5]\n",
      " [ 1.   0.5  0.5  1. ]\n",
      " [ 0.5  0.5  0.   1. ]\n",
      " [ 1.   0.   0.5  0.5]\n",
      " [ 0.5  0.5  0.   0. ]\n",
      " [ 0.5  0.   0.   0.5]\n",
      " [ 0.5  0.5  1.   0. ]\n",
      " [ 0.   0.5  0.5  0. ]\n",
      " [ 1.   1.   0.5  0.5]\n",
      " [ 0.5  0.   1.   0.5]\n",
      " [ 0.   1.   0.5  0.5]\n",
      " [ 1.   0.5  0.5  0. ]\n",
      " [ 0.   0.5  0.   0.5]\n",
      " [ 0.5  1.   1.   0.5]\n",
      " [ 0.5  1.   0.5  0. ]\n",
      " [ 1.   0.5  1.   0.5]\n",
      " [ 0.5  1.   0.   0.5]]\n",
      "------------------------\n",
      "[[ 0.5  0.   0.5  0. ]\n",
      " [ 1.   0.5  0.   0.5]\n",
      " [ 0.   0.5  0.5  1. ]\n",
      " [ 0.5  0.5  0.5  0.5]\n",
      " [ 0.5  1.   0.5  1. ]]\n",
      "------------------------\n",
      "[-0.21844449 -0.47152439 -0.45735005 -0.1123416  -0.11245536 -0.18036006\n",
      " -0.19692817  0.00145492 -0.14520267  0.01178692  0.04523337  0.52847561\n",
      " -0.13421128  0.19149351 -0.00787756  0.09143864 -0.16016158  0.30505231\n",
      "  0.04222738  0.33060721]\n",
      "------------------------\n",
      "[-0.08104142  0.20294599  0.18485121  0.07951933  0.2628122 ]\n"
     ]
    }
   ],
   "source": [
    "#data = np.loadtxt(\"ACL nomalization data.txt\")\n",
    "#data2 = np.loadtxt(\"acl data.txt\")\n",
    "data = np.loadtxt(\"ACL FTIR data_mean.txt\")\n",
    "\n",
    "X_NormalizedData = data[:,0:4]\n",
    "Y_NormalizedData = data[:,4]\n",
    "\n",
    "X_TrainingData = data[0:20,0:4]\n",
    "Y_TrainingData = data[0:20,4]\n",
    "\n",
    "X_TestData = data[20:,0:4]\n",
    "Y_TestData = data[20:,4]\n",
    "\n",
    "Sequence = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19]\n",
    "\n",
    "#XY_TrainingData = data[0:21,:]\n",
    "#X_TrainingData = XY_TrainingData[0:21,0:4]\n",
    "#Y_TrainingData = XY_TrainingData[0:21,4]\n",
    "#\n",
    "#XY_TestData = data[21:,:]\n",
    "#X_TestData = XY_TestData[:,0:4]\n",
    "#Y_TestData = XY_TestData[:,4]\n",
    "\n",
    "print(X_TrainingData)\n",
    "print(\"------------------------\")\n",
    "print(X_TestData)\n",
    "print(\"------------------------\")\n",
    "print(Y_TrainingData)\n",
    "print(\"------------------------\")\n",
    "print(Y_TestData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 1st eLU, tanh, 4, 18, 18, 9, 9, 1\n",
    "   R2 = 0.650794040271"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "n_InputUnit = 4\n",
    "n_1stHiddenUnit=18\n",
    "n_2ndHiddenUnit=18\n",
    "n_3rdHiddenUnit=9\n",
    "n_4thHiddenUnit=9\n",
    "n_OutputUnit = 1\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([n_InputUnit, n_1stHiddenUnit],stddev=0.01))\n",
    "W2 = tf.Variable(tf.random_normal([n_1stHiddenUnit, n_2ndHiddenUnit],stddev=0.01))\n",
    "W3 = tf.Variable(tf.random_normal([n_2ndHiddenUnit, n_3rdHiddenUnit],stddev=0.01))\n",
    "W4 = tf.Variable(tf.random_normal([n_3rdHiddenUnit, n_4thHiddenUnit],stddev=0.01))\n",
    "W5 = tf.Variable(tf.random_normal([n_4thHiddenUnit, n_OutputUnit],stddev=0.01))\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([n_1stHiddenUnit], stddev=0.01))\n",
    "b2 = tf.Variable(tf.random_normal([n_2ndHiddenUnit], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([n_3rdHiddenUnit], stddev=0.01))\n",
    "b4 = tf.Variable(tf.random_normal([n_4thHiddenUnit], stddev=0.01))\n",
    "b5 = tf.Variable(tf.random_normal([n_OutputUnit], stddev=0.01))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 4]) # tensorflow의 placeholder라는 변수를 선언\n",
    "Y = tf.placeholder(tf.float32, [None,])\n",
    "\n",
    "L1 = tf.nn.elu(tf.matmul(X, W1) + b1)\n",
    "L2 = tf.nn.elu(tf.matmul(L1, W2) + b2)\n",
    "L3 = tf.nn.elu(tf.matmul(L2, W3) + b3)\n",
    "L4 = tf.nn.elu(tf.matmul(L3, W4) + b4)\n",
    "Hypothesis = tf.nn.tanh(tf.matmul(L4, W5) + b5)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(Y-Hypothesis))\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=0.5).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Train NN & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0.0591896\n",
      "11 1000 0.0932284\n",
      "5 2000 0.0952678\n",
      "8 3000 0.0939003\n",
      "14 4000 0.095178\n",
      "10 5000 0.0968684\n",
      "14 6000 0.0933779\n",
      "12 7000 0.0960672\n",
      "0 8000 0.0976867\n",
      "11 9000 0.0920585\n",
      "9 10000 0.0954067\n",
      "16 11000 0.103425\n",
      "17 12000 0.100246\n",
      "9 13000 0.108791\n",
      "18 14000 0.0992377\n",
      "6 15000 0.109174\n",
      "4 16000 0.102449\n",
      "4 17000 0.108634\n",
      "5 18000 0.104711\n",
      "14 19000 0.106914\n",
      "4 20000 0.100476\n",
      "14 21000 0.111104\n",
      "1 22000 0.114193\n",
      "3 23000 0.11476\n",
      "8 24000 0.116818\n",
      "2 25000 0.105358\n",
      "10 26000 0.107656\n",
      "3 27000 0.118919\n",
      "12 28000 0.110507\n",
      "0 29000 0.111077\n",
      "11 30000 0.115278\n",
      "13 31000 0.113085\n",
      "15 32000 0.110596\n",
      "16 33000 0.114103\n",
      "12 34000 0.10827\n",
      "13 35000 0.105011\n",
      "5 36000 0.107045\n",
      "10 37000 0.106673\n",
      "13 38000 0.120903\n",
      "2 39000 0.11023\n",
      "12 40000 0.109934\n",
      "5 41000 0.106067\n",
      "8 42000 0.110262\n",
      "13 43000 0.118721\n",
      "2 44000 0.110114\n",
      "3 45000 0.113067\n",
      "4 46000 0.114026\n",
      "18 47000 0.106068\n",
      "4 48000 0.113776\n",
      "6 49000 0.11248\n",
      "9 50000 0.115551\n",
      "12 51000 0.112386\n",
      "17 52000 0.114736\n",
      "18 53000 0.112121\n",
      "12 54000 0.115675\n",
      "19 55000 0.117282\n",
      "19 56000 0.117015\n",
      "0 57000 0.111144\n",
      "2 58000 0.112381\n",
      "4 59000 0.120801\n",
      "17 60000 0.113274\n",
      "1 61000 0.109804\n",
      "4 62000 0.123213\n",
      "13 63000 0.113967\n",
      "12 64000 0.114569\n",
      "11 65000 0.115911\n",
      "12 66000 0.113805\n",
      "0 67000 0.117086\n",
      "16 68000 0.115386\n",
      "19 69000 0.113325\n",
      "0 70000 0.119789\n",
      "14 71000 0.116436\n",
      "19 72000 0.111872\n",
      "18 73000 0.120074\n",
      "13 74000 0.111147\n",
      "4 75000 0.113434\n",
      "8 76000 0.107439\n",
      "17 77000 0.116397\n",
      "8 78000 0.110764\n",
      "10 79000 0.116974\n",
      "14 80000 0.11112\n",
      "0 81000 0.114728\n",
      "17 82000 0.109813\n",
      "7 83000 0.113791\n",
      "10 84000 0.114436\n",
      "15 85000 0.117938\n",
      "15 86000 0.114691\n",
      "6 87000 0.115113\n",
      "9 88000 0.115958\n",
      "16 89000 0.108072\n",
      "19 90000 0.113351\n",
      "13 91000 0.116466\n",
      "6 92000 0.11717\n",
      "18 93000 0.109356\n",
      "9 94000 0.111248\n",
      "15 95000 0.120688\n",
      "5 96000 0.11337\n",
      "1 97000 0.115089\n",
      "0 98000 0.117213\n",
      "18 99000 0.116589\n",
      "R_square\n",
      "0.650794040271\n",
      "Result of predicting TrainingData\n",
      "[[ -2.21868858e-01]\n",
      " [ -4.79906708e-01]\n",
      " [ -4.85656112e-01]\n",
      " [ -1.16037555e-01]\n",
      " [ -1.24498338e-01]\n",
      " [ -1.64491773e-01]\n",
      " [ -1.97971418e-01]\n",
      " [ -7.31251761e-03]\n",
      " [ -1.55632108e-01]\n",
      " [ -4.82290896e-04]\n",
      " [  4.28913161e-02]\n",
      " [  5.37065506e-01]\n",
      " [ -1.45066082e-01]\n",
      " [  2.03783691e-01]\n",
      " [ -1.50591871e-02]\n",
      " [  8.62428844e-02]\n",
      " [ -1.68003276e-01]\n",
      " [  2.94223487e-01]\n",
      " [  2.97964681e-02]\n",
      " [  4.49590892e-01]]\n",
      "Result of predicting TestData\n",
      "[[ 0.02685649]\n",
      " [ 0.28625515]\n",
      " [-0.45935735]\n",
      " [ 0.01014276]\n",
      " [ 0.35766801]]\n",
      "Y_NormalizedData\n",
      "[-0.21844449 -0.47152439 -0.45735005 -0.1123416  -0.11245536 -0.18036006\n",
      " -0.19692817  0.00145492 -0.14520267  0.01178692  0.04523337  0.52847561\n",
      " -0.13421128  0.19149351 -0.00787756  0.09143864 -0.16016158  0.30505231\n",
      "  0.04222738  0.33060721 -0.08104142  0.20294599  0.18485121  0.07951933\n",
      "  0.2628122 ]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(100000):\n",
    "        SGDorder = Sequence[step % 20] # training을 0번부터 20번까지 순차적으로 돌린다.\n",
    "        session.run(train, feed_dict ={X: X_TrainingData[SGDorder: SGDorder + 1,:], Y: Y_TrainingData[SGDorder: SGDorder + 1]})\n",
    "        #session.run(train, feed_dict ={X: X_TrainingData, Y: Y_TrainingData})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print (SGDorder,step, session.run(cost, feed_dict = {X: X_TrainingData, Y: Y_TrainingData}))\n",
    "            #print (W1)\n",
    "            #print (b1)\n",
    "        if step % 20 == 0:\n",
    "            random.shuffle(Sequence)\n",
    "            \n",
    "    Predict_to_TestData = session.run(Hypothesis, feed_dict={X : X_TestData})\n",
    "    Predict_to_TrainingData = session.run(Hypothesis, feed_dict={X : X_TrainingData})\n",
    "    Predict_to_EntireData = session.run(Hypothesis, feed_dict = {X : X_NormalizedData})\n",
    "    \n",
    "    print(\"R_square\")\n",
    "    print(r2_score(Y_NormalizedData, Predict_to_EntireData))\n",
    "    print(\"Result of predicting TrainingData\")\n",
    "    print(Predict_to_TrainingData)\n",
    "    print(\"Result of predicting TestData\")\n",
    "    print(Predict_to_TestData)\n",
    "    print(\"Y_NormalizedData\")\n",
    "    print(Y_NormalizedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 2nd eLU, tanh, 4, 50, 50, 50, 50, 1\n",
    "R2 = 0.739438404489"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "n_InputUnit = 4\n",
    "n_1stHiddenUnit=50\n",
    "n_2ndHiddenUnit=50\n",
    "n_3rdHiddenUnit=50\n",
    "n_4thHiddenUnit=50\n",
    "n_OutputUnit = 1\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([n_InputUnit, n_1stHiddenUnit],stddev=0.01))\n",
    "W2 = tf.Variable(tf.random_normal([n_1stHiddenUnit, n_2ndHiddenUnit],stddev=0.01))\n",
    "W3 = tf.Variable(tf.random_normal([n_2ndHiddenUnit, n_3rdHiddenUnit],stddev=0.01))\n",
    "W4 = tf.Variable(tf.random_normal([n_3rdHiddenUnit, n_4thHiddenUnit],stddev=0.01))\n",
    "W5 = tf.Variable(tf.random_normal([n_4thHiddenUnit, n_OutputUnit],stddev=0.01))\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([n_1stHiddenUnit], stddev=0.01))\n",
    "b2 = tf.Variable(tf.random_normal([n_2ndHiddenUnit], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([n_3rdHiddenUnit], stddev=0.01))\n",
    "b4 = tf.Variable(tf.random_normal([n_4thHiddenUnit], stddev=0.01))\n",
    "b5 = tf.Variable(tf.random_normal([n_OutputUnit], stddev=0.01))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 4]) # tensorflow의 placeholder라는 변수를 선언\n",
    "Y = tf.placeholder(tf.float32, [None,])\n",
    "\n",
    "L1 = tf.nn.elu(tf.matmul(X, W1) + b1)\n",
    "L2 = tf.nn.elu(tf.matmul(L1, W2) + b2)\n",
    "L3 = tf.nn.elu(tf.matmul(L2, W3) + b3)\n",
    "L4 = tf.nn.elu(tf.matmul(L3, W4) + b4)\n",
    "Hypothesis = tf.nn.tanh(tf.matmul(L4, W5) + b5)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(Y-Hypothesis))\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=0.5).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Train NN & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 0 0.0595104\n",
      "19 1000 0.0794318\n",
      "1 2000 0.0947253\n",
      "3 3000 0.0882092\n",
      "8 4000 0.0973845\n",
      "3 5000 0.0912867\n",
      "13 6000 0.109581\n",
      "14 7000 0.0984348\n",
      "16 8000 0.106975\n",
      "6 9000 0.104623\n",
      "14 10000 0.112115\n",
      "6 11000 0.117953\n",
      "1 12000 0.112353\n",
      "1 13000 0.110814\n",
      "8 14000 0.114513\n",
      "13 15000 0.122464\n",
      "17 16000 0.11721\n",
      "19 17000 0.111499\n",
      "14 18000 0.111959\n",
      "17 19000 0.120489\n",
      "19 20000 0.111344\n",
      "0 21000 0.113771\n",
      "15 22000 0.117568\n",
      "6 23000 0.110788\n",
      "11 24000 0.114281\n",
      "10 25000 0.107376\n",
      "4 26000 0.116347\n",
      "3 27000 0.120781\n",
      "18 28000 0.112704\n",
      "9 29000 0.112731\n",
      "11 30000 0.120121\n",
      "12 31000 0.116988\n",
      "6 32000 0.115963\n",
      "0 33000 0.116304\n",
      "0 34000 0.114918\n",
      "19 35000 0.116479\n",
      "4 36000 0.122564\n",
      "19 37000 0.114276\n",
      "3 38000 0.117473\n",
      "0 39000 0.115592\n",
      "2 40000 0.119671\n",
      "10 41000 0.115765\n",
      "16 42000 0.114277\n",
      "7 43000 0.115904\n",
      "13 44000 0.113214\n",
      "1 45000 0.115032\n",
      "9 46000 0.112982\n",
      "13 47000 0.114722\n",
      "17 48000 0.11347\n",
      "3 49000 0.116227\n",
      "9 50000 0.114015\n",
      "18 51000 0.117751\n",
      "12 52000 0.112584\n",
      "17 53000 0.115038\n",
      "14 54000 0.11479\n",
      "13 55000 0.108616\n",
      "14 56000 0.113845\n",
      "19 57000 0.114314\n",
      "4 58000 0.117318\n",
      "8 59000 0.119734\n",
      "10 60000 0.113853\n",
      "5 61000 0.114623\n",
      "0 62000 0.113162\n",
      "16 63000 0.11673\n",
      "3 64000 0.116224\n",
      "5 65000 0.115077\n",
      "4 66000 0.114124\n",
      "15 67000 0.11516\n",
      "5 68000 0.114507\n",
      "11 69000 0.116044\n",
      "17 70000 0.115211\n",
      "7 71000 0.118448\n",
      "6 72000 0.114868\n",
      "14 73000 0.114309\n",
      "15 74000 0.117367\n",
      "15 75000 0.115922\n",
      "9 76000 0.114339\n",
      "12 77000 0.115228\n",
      "0 78000 0.115967\n",
      "17 79000 0.115061\n",
      "9 80000 0.108605\n",
      "17 81000 0.115385\n",
      "12 82000 0.115219\n",
      "15 83000 0.115708\n",
      "4 84000 0.12182\n",
      "5 85000 0.11109\n",
      "9 86000 0.115299\n",
      "12 87000 0.115619\n",
      "18 88000 0.115644\n",
      "9 89000 0.114461\n",
      "0 90000 0.112977\n",
      "2 91000 0.114871\n",
      "10 92000 0.112237\n",
      "19 93000 0.115074\n",
      "16 94000 0.117188\n",
      "8 95000 0.114565\n",
      "4 96000 0.110981\n",
      "4 97000 0.11511\n",
      "10 98000 0.122822\n",
      "1 99000 0.112311\n",
      "R_square\n",
      "0.739438404489\n",
      "Result of predicting TrainingData\n",
      "[[-0.2298978 ]\n",
      " [-0.4755336 ]\n",
      " [-0.46726772]\n",
      " [-0.10793684]\n",
      " [-0.10758535]\n",
      " [-0.17802277]\n",
      " [-0.18241481]\n",
      " [ 0.0031644 ]\n",
      " [-0.13028099]\n",
      " [ 0.01293737]\n",
      " [ 0.03998682]\n",
      " [ 0.55006588]\n",
      " [-0.11513842]\n",
      " [ 0.19132304]\n",
      " [-0.00609799]\n",
      " [ 0.10049019]\n",
      " [-0.16169359]\n",
      " [ 0.2772328 ]\n",
      " [ 0.04191996]\n",
      " [ 0.32439512]]\n",
      "Result of predicting TestData\n",
      "[[ 0.00207727]\n",
      " [ 0.48642907]\n",
      " [-0.2910623 ]\n",
      " [ 0.03873577]\n",
      " [ 0.0947119 ]]\n",
      "Y_NormalizedData\n",
      "[-0.21844449 -0.47152439 -0.45735005 -0.1123416  -0.11245536 -0.18036006\n",
      " -0.19692817  0.00145492 -0.14520267  0.01178692  0.04523337  0.52847561\n",
      " -0.13421128  0.19149351 -0.00787756  0.09143864 -0.16016158  0.30505231\n",
      "  0.04222738  0.33060721 -0.08104142  0.20294599  0.18485121  0.07951933\n",
      "  0.2628122 ]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(100000):\n",
    "        SGDorder = Sequence[step % 20] # training을 0번부터 20번까지 순차적으로 돌린다.\n",
    "        session.run(train, feed_dict ={X: X_TrainingData[SGDorder: SGDorder + 1,:], Y: Y_TrainingData[SGDorder: SGDorder + 1]})\n",
    "        #session.run(train, feed_dict ={X: X_TrainingData, Y: Y_TrainingData})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print (SGDorder,step, session.run(cost, feed_dict = {X: X_TrainingData, Y: Y_TrainingData}))\n",
    "            #print (W1)\n",
    "            #print (b1)\n",
    "        if step % 20 == 0:\n",
    "            random.shuffle(Sequence)\n",
    "            \n",
    "    Predict_to_TestData = session.run(Hypothesis, feed_dict={X : X_TestData})\n",
    "    Predict_to_TrainingData = session.run(Hypothesis, feed_dict={X : X_TrainingData})\n",
    "    Predict_to_EntireData = session.run(Hypothesis, feed_dict = {X : X_NormalizedData})\n",
    "    \n",
    "    print(\"R_square\")\n",
    "    print(r2_score(Y_NormalizedData, Predict_to_EntireData))\n",
    "    print(\"Result of predicting TrainingData\")\n",
    "    print(Predict_to_TrainingData)\n",
    "    print(\"Result of predicting TestData\")\n",
    "    print(Predict_to_TestData)\n",
    "    print(\"Y_NormalizedData\")\n",
    "    print(Y_NormalizedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 3rd eLU, tanh, 4, 10, 10, 10, 1\n",
    "R2 = 0.175927828405"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "n_InputUnit = 4\n",
    "n_1stHiddenUnit=10\n",
    "n_2ndHiddenUnit=10\n",
    "n_3rdHiddenUnit=10\n",
    "n_OutputUnit = 1\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([n_InputUnit, n_1stHiddenUnit],stddev=0.01))\n",
    "W2 = tf.Variable(tf.random_normal([n_1stHiddenUnit, n_2ndHiddenUnit],stddev=0.01))\n",
    "W3 = tf.Variable(tf.random_normal([n_2ndHiddenUnit, n_3rdHiddenUnit],stddev=0.01))\n",
    "W4 = tf.Variable(tf.random_normal([n_3rdHiddenUnit, n_OutputUnit],stddev=0.01))\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([n_1stHiddenUnit], stddev=0.01))\n",
    "b2 = tf.Variable(tf.random_normal([n_2ndHiddenUnit], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([n_3rdHiddenUnit], stddev=0.01))\n",
    "b4 = tf.Variable(tf.random_normal([n_OutputUnit], stddev=0.01))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 4]) # tensorflow의 placeholder라는 변수를 선언\n",
    "Y = tf.placeholder(tf.float32, [None,])\n",
    "\n",
    "L1 = tf.nn.elu(tf.matmul(X, W1) + b1)\n",
    "L2 = tf.nn.elu(tf.matmul(L1, W2) + b2)\n",
    "L3 = tf.nn.elu(tf.matmul(L2, W3) + b3)\n",
    "Hypothesis = tf.nn.tanh(tf.matmul(L3, W4) + b4)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(Y-Hypothesis))\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=0.5).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Train NN & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0 0.0585732\n",
      "18 1000 0.0956587\n",
      "13 2000 0.0985326\n",
      "9 3000 0.0949933\n",
      "10 4000 0.095396\n",
      "16 5000 0.0974526\n",
      "10 6000 0.0956013\n",
      "1 7000 0.0963442\n",
      "14 8000 0.100505\n",
      "18 9000 0.0994718\n",
      "15 10000 0.096631\n",
      "3 11000 0.0963814\n",
      "5 12000 0.099483\n",
      "14 13000 0.0987677\n",
      "15 14000 0.0976411\n",
      "3 15000 0.100531\n",
      "13 16000 0.101459\n",
      "14 17000 0.0999619\n",
      "3 18000 0.103314\n",
      "0 19000 0.103218\n",
      "13 20000 0.100759\n",
      "3 21000 0.102449\n",
      "1 22000 0.103823\n",
      "4 23000 0.102486\n",
      "5 24000 0.105033\n",
      "11 25000 0.104035\n",
      "8 26000 0.10446\n",
      "11 27000 0.104431\n",
      "4 28000 0.104472\n",
      "0 29000 0.10785\n",
      "10 30000 0.106745\n",
      "11 31000 0.104375\n",
      "0 32000 0.102216\n",
      "16 33000 0.108761\n",
      "1 34000 0.107189\n",
      "5 35000 0.101689\n",
      "8 36000 0.108072\n",
      "7 37000 0.106626\n",
      "0 38000 0.10947\n",
      "4 39000 0.110847\n",
      "18 40000 0.110233\n",
      "10 41000 0.10897\n",
      "18 42000 0.109099\n",
      "19 43000 0.115332\n",
      "2 44000 0.103648\n",
      "18 45000 0.106616\n",
      "11 46000 0.110686\n",
      "17 47000 0.103853\n",
      "17 48000 0.111057\n",
      "12 49000 0.107612\n",
      "10 50000 0.115527\n",
      "4 51000 0.113622\n",
      "17 52000 0.114835\n",
      "4 53000 0.112899\n",
      "10 54000 0.117094\n",
      "17 55000 0.106935\n",
      "19 56000 0.116198\n",
      "14 57000 0.107495\n",
      "18 58000 0.113897\n",
      "17 59000 0.119313\n",
      "19 60000 0.112194\n",
      "16 61000 0.11228\n",
      "14 62000 0.112021\n",
      "19 63000 0.114787\n",
      "1 64000 0.111604\n",
      "4 65000 0.11855\n",
      "16 66000 0.113326\n",
      "15 67000 0.114763\n",
      "7 68000 0.111278\n",
      "13 69000 0.123209\n",
      "8 70000 0.127414\n",
      "18 71000 0.110083\n",
      "19 72000 0.113298\n",
      "8 73000 0.116882\n",
      "7 74000 0.11387\n",
      "16 75000 0.111761\n",
      "17 76000 0.114011\n",
      "5 77000 0.115203\n",
      "18 78000 0.115225\n",
      "8 79000 0.114139\n",
      "13 80000 0.110515\n",
      "4 81000 0.110366\n",
      "13 82000 0.116446\n",
      "14 83000 0.116075\n",
      "6 84000 0.114861\n",
      "3 85000 0.115025\n",
      "4 86000 0.1164\n",
      "16 87000 0.12169\n",
      "19 88000 0.113548\n",
      "14 89000 0.122591\n",
      "7 90000 0.107796\n",
      "13 91000 0.117619\n",
      "17 92000 0.115468\n",
      "4 93000 0.114877\n",
      "6 94000 0.11321\n",
      "17 95000 0.11384\n",
      "17 96000 0.11089\n",
      "18 97000 0.113657\n",
      "1 98000 0.115246\n",
      "7 99000 0.116411\n",
      "R_square\n",
      "0.175927828405\n",
      "Result of predicting TrainingData\n",
      "[[-0.22900331]\n",
      " [-0.48789892]\n",
      " [-0.46437266]\n",
      " [-0.11018249]\n",
      " [-0.12036154]\n",
      " [-0.20333906]\n",
      " [-0.18935929]\n",
      " [ 0.00403018]\n",
      " [-0.15747587]\n",
      " [ 0.02602797]\n",
      " [ 0.0498494 ]\n",
      " [ 0.52917457]\n",
      " [-0.14579839]\n",
      " [ 0.19282202]\n",
      " [-0.01600436]\n",
      " [ 0.08804649]\n",
      " [-0.15751632]\n",
      " [ 0.30678895]\n",
      " [ 0.03283839]\n",
      " [ 0.33928314]]\n",
      "Result of predicting TestData\n",
      "[[-0.12712105]\n",
      " [ 0.22802933]\n",
      " [-0.79215717]\n",
      " [ 0.02509907]\n",
      " [-0.10151034]]\n",
      "Y_NormalizedData\n",
      "[-0.21844449 -0.47152439 -0.45735005 -0.1123416  -0.11245536 -0.18036006\n",
      " -0.19692817  0.00145492 -0.14520267  0.01178692  0.04523337  0.52847561\n",
      " -0.13421128  0.19149351 -0.00787756  0.09143864 -0.16016158  0.30505231\n",
      "  0.04222738  0.33060721 -0.08104142  0.20294599  0.18485121  0.07951933\n",
      "  0.2628122 ]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(100000):\n",
    "        SGDorder = Sequence[step % 20] # training을 0번부터 20번까지 순차적으로 돌린다.\n",
    "        session.run(train, feed_dict ={X: X_TrainingData[SGDorder: SGDorder + 1,:], Y: Y_TrainingData[SGDorder: SGDorder + 1]})\n",
    "        #session.run(train, feed_dict ={X: X_TrainingData, Y: Y_TrainingData})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print (SGDorder,step, session.run(cost, feed_dict = {X: X_TrainingData, Y: Y_TrainingData}))\n",
    "            #print (W1)\n",
    "            #print (b1)\n",
    "        if step % 20 == 0:\n",
    "            random.shuffle(Sequence)\n",
    "            \n",
    "    Predict_to_TestData = session.run(Hypothesis, feed_dict={X : X_TestData})\n",
    "    Predict_to_TrainingData = session.run(Hypothesis, feed_dict={X : X_TrainingData})\n",
    "    Predict_to_EntireData = session.run(Hypothesis, feed_dict = {X : X_NormalizedData})\n",
    "    \n",
    "    print(\"R_square\")\n",
    "    print(r2_score(Y_NormalizedData, Predict_to_EntireData))\n",
    "    print(\"Result of predicting TrainingData\")\n",
    "    print(Predict_to_TrainingData)\n",
    "    print(\"Result of predicting TestData\")\n",
    "    print(Predict_to_TestData)\n",
    "    print(\"Y_NormalizedData\")\n",
    "    print(Y_NormalizedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 4th eLU, tanh, 4, 50, 30, 10, 1\n",
    "R2 = 0.719074577467"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "n_InputUnit = 4\n",
    "n_1stHiddenUnit=50\n",
    "n_2ndHiddenUnit=30\n",
    "n_3rdHiddenUnit=10\n",
    "n_OutputUnit = 1\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([n_InputUnit, n_1stHiddenUnit],stddev=0.01))\n",
    "W2 = tf.Variable(tf.random_normal([n_1stHiddenUnit, n_2ndHiddenUnit],stddev=0.01))\n",
    "W3 = tf.Variable(tf.random_normal([n_2ndHiddenUnit, n_3rdHiddenUnit],stddev=0.01))\n",
    "W4 = tf.Variable(tf.random_normal([n_3rdHiddenUnit, n_OutputUnit],stddev=0.01))\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([n_1stHiddenUnit], stddev=0.01))\n",
    "b2 = tf.Variable(tf.random_normal([n_2ndHiddenUnit], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([n_3rdHiddenUnit], stddev=0.01))\n",
    "b4 = tf.Variable(tf.random_normal([n_OutputUnit], stddev=0.01))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 4]) # tensorflow의 placeholder라는 변수를 선언\n",
    "Y = tf.placeholder(tf.float32, [None,])\n",
    "\n",
    "L1 = tf.nn.elu(tf.matmul(X, W1) + b1)\n",
    "L2 = tf.nn.elu(tf.matmul(L1, W2) + b2)\n",
    "L3 = tf.nn.elu(tf.matmul(L2, W3) + b3)\n",
    "Hypothesis = tf.nn.tanh(tf.matmul(L3, W4) + b4)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(Y-Hypothesis))\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=0.5).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Train NN & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0 0.0594844\n",
      "8 1000 0.0934577\n",
      "8 2000 0.0981473\n",
      "6 3000 0.0996605\n",
      "7 4000 0.0987898\n",
      "7 5000 0.0974686\n",
      "15 6000 0.0997668\n",
      "2 7000 0.0975844\n",
      "10 8000 0.103077\n",
      "15 9000 0.10619\n",
      "11 10000 0.104992\n",
      "8 11000 0.103286\n",
      "8 12000 0.103685\n",
      "0 13000 0.111437\n",
      "11 14000 0.102675\n",
      "18 15000 0.106349\n",
      "17 16000 0.102384\n",
      "2 17000 0.120925\n",
      "7 18000 0.111471\n",
      "3 19000 0.118386\n",
      "15 20000 0.100725\n",
      "0 21000 0.11871\n",
      "8 22000 0.116021\n",
      "7 23000 0.122172\n",
      "13 24000 0.126074\n",
      "9 25000 0.114277\n",
      "8 26000 0.111456\n",
      "7 27000 0.120353\n",
      "14 28000 0.10986\n",
      "8 29000 0.115471\n",
      "6 30000 0.11848\n",
      "18 31000 0.119425\n",
      "11 32000 0.117928\n",
      "12 33000 0.112237\n",
      "2 34000 0.113067\n",
      "6 35000 0.113546\n",
      "3 36000 0.111758\n",
      "7 37000 0.109041\n",
      "16 38000 0.115154\n",
      "4 39000 0.122314\n",
      "14 40000 0.118878\n",
      "3 41000 0.113248\n",
      "16 42000 0.115505\n",
      "17 43000 0.11083\n",
      "0 44000 0.110674\n",
      "10 45000 0.11487\n",
      "14 46000 0.115533\n",
      "15 47000 0.11516\n",
      "19 48000 0.111967\n",
      "18 49000 0.115233\n",
      "8 50000 0.116072\n",
      "10 51000 0.114825\n",
      "18 52000 0.112569\n",
      "8 53000 0.11706\n",
      "7 54000 0.116262\n",
      "9 55000 0.116531\n",
      "13 56000 0.118971\n",
      "14 57000 0.113998\n",
      "17 58000 0.114565\n",
      "4 59000 0.11435\n",
      "3 60000 0.115737\n",
      "13 61000 0.114593\n",
      "12 62000 0.1159\n",
      "13 63000 0.115682\n",
      "2 64000 0.114875\n",
      "9 65000 0.114524\n",
      "15 66000 0.118579\n",
      "12 67000 0.115675\n",
      "15 68000 0.116533\n",
      "11 69000 0.114909\n",
      "6 70000 0.116157\n",
      "6 71000 0.114493\n",
      "3 72000 0.111445\n",
      "0 73000 0.115093\n",
      "10 74000 0.113649\n",
      "5 75000 0.114995\n",
      "12 76000 0.115021\n",
      "15 77000 0.115199\n",
      "4 78000 0.116232\n",
      "8 79000 0.113806\n",
      "18 80000 0.115172\n",
      "13 81000 0.112696\n",
      "4 82000 0.114935\n",
      "1 83000 0.114737\n",
      "12 84000 0.116038\n",
      "15 85000 0.114429\n",
      "2 86000 0.115314\n",
      "0 87000 0.116371\n",
      "16 88000 0.110586\n",
      "14 89000 0.114011\n",
      "10 90000 0.115815\n",
      "1 91000 0.116528\n",
      "5 92000 0.112924\n",
      "6 93000 0.114891\n",
      "8 94000 0.11489\n",
      "0 95000 0.117711\n",
      "12 96000 0.11314\n",
      "1 97000 0.114972\n",
      "6 98000 0.114322\n",
      "8 99000 0.112602\n",
      "R_square\n",
      "0.719074577467\n",
      "Result of predicting TrainingData\n",
      "[[ -2.14697897e-01]\n",
      " [ -4.63033944e-01]\n",
      " [ -4.47905332e-01]\n",
      " [ -1.09662540e-01]\n",
      " [ -1.10438652e-01]\n",
      " [ -1.80275425e-01]\n",
      " [ -1.93990543e-01]\n",
      " [  4.34216025e-04]\n",
      " [ -1.39089644e-01]\n",
      " [  1.20973848e-02]\n",
      " [  4.52563651e-02]\n",
      " [  5.24351001e-01]\n",
      " [ -1.27447337e-01]\n",
      " [  1.89465880e-01]\n",
      " [ -7.81890750e-03]\n",
      " [  9.17430818e-02]\n",
      " [ -1.57310590e-01]\n",
      " [  2.98849642e-01]\n",
      " [  4.26339358e-02]\n",
      " [  3.22009504e-01]]\n",
      "Result of predicting TestData\n",
      "[[-0.00983813]\n",
      " [ 0.04991201]\n",
      " [-0.25568742]\n",
      " [-0.11569195]\n",
      " [-0.07205753]]\n",
      "Y_NormalizedData\n",
      "[-0.21844449 -0.47152439 -0.45735005 -0.1123416  -0.11245536 -0.18036006\n",
      " -0.19692817  0.00145492 -0.14520267  0.01178692  0.04523337  0.52847561\n",
      " -0.13421128  0.19149351 -0.00787756  0.09143864 -0.16016158  0.30505231\n",
      "  0.04222738  0.33060721 -0.08104142  0.20294599  0.18485121  0.07951933\n",
      "  0.2628122 ]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(100000):\n",
    "        SGDorder = Sequence[step % 20] # training을 0번부터 20번까지 순차적으로 돌린다.\n",
    "        session.run(train, feed_dict ={X: X_TrainingData[SGDorder: SGDorder + 1,:], Y: Y_TrainingData[SGDorder: SGDorder + 1]})\n",
    "        #session.run(train, feed_dict ={X: X_TrainingData, Y: Y_TrainingData})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print (SGDorder,step, session.run(cost, feed_dict = {X: X_TrainingData, Y: Y_TrainingData}))\n",
    "            #print (W1)\n",
    "            #print (b1)\n",
    "        if step % 20 == 0:\n",
    "            random.shuffle(Sequence)\n",
    "            \n",
    "    Predict_to_TestData = session.run(Hypothesis, feed_dict={X : X_TestData})\n",
    "    Predict_to_TrainingData = session.run(Hypothesis, feed_dict={X : X_TrainingData})\n",
    "    Predict_to_EntireData = session.run(Hypothesis, feed_dict = {X : X_NormalizedData})\n",
    "    \n",
    "    print(\"R_square\")\n",
    "    print(r2_score(Y_NormalizedData, Predict_to_EntireData))\n",
    "    print(\"Result of predicting TrainingData\")\n",
    "    print(Predict_to_TrainingData)\n",
    "    print(\"Result of predicting TestData\")\n",
    "    print(Predict_to_TestData)\n",
    "    print(\"Y_NormalizedData\")\n",
    "    print(Y_NormalizedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 5th ReLU, tanh, 4, 50, 50, 50, 1\n",
    "R2 = 0.587211552943"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "n_InputUnit = 4\n",
    "n_1stHiddenUnit=50\n",
    "n_2ndHiddenUnit=50\n",
    "n_3rdHiddenUnit=50\n",
    "n_OutputUnit = 1\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([n_InputUnit, n_1stHiddenUnit],stddev=0.01))\n",
    "W2 = tf.Variable(tf.random_normal([n_1stHiddenUnit, n_2ndHiddenUnit],stddev=0.01))\n",
    "W3 = tf.Variable(tf.random_normal([n_2ndHiddenUnit, n_3rdHiddenUnit],stddev=0.01))\n",
    "W4 = tf.Variable(tf.random_normal([n_3rdHiddenUnit, n_OutputUnit],stddev=0.01))\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([n_1stHiddenUnit], stddev=0.01))\n",
    "b2 = tf.Variable(tf.random_normal([n_2ndHiddenUnit], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([n_3rdHiddenUnit], stddev=0.01))\n",
    "b4 = tf.Variable(tf.random_normal([n_OutputUnit], stddev=0.01))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 4]) # tensorflow의 placeholder라는 변수를 선언\n",
    "Y = tf.placeholder(tf.float32, [None,])\n",
    "\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "L3 = tf.nn.relu(tf.matmul(L2, W3) + b3)\n",
    "Hypothesis = tf.nn.tanh(tf.matmul(L3, W4) + b4)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(Y-Hypothesis))\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=0.5).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Train NN & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 0 0.0593963\n",
      "6 1000 0.0988289\n",
      "18 2000 0.0957394\n",
      "7 3000 0.0982848\n",
      "12 4000 0.10646\n",
      "18 5000 0.106831\n",
      "12 6000 0.110742\n",
      "14 7000 0.110526\n",
      "0 8000 0.111224\n",
      "15 9000 0.111403\n",
      "13 10000 0.0876452\n",
      "0 11000 0.113256\n",
      "14 12000 0.115606\n",
      "10 13000 0.11472\n",
      "19 14000 0.114371\n",
      "4 15000 0.109506\n",
      "3 16000 0.111037\n",
      "1 17000 0.115207\n",
      "9 18000 0.116183\n",
      "16 19000 0.11143\n",
      "10 20000 0.11894\n",
      "19 21000 0.116465\n",
      "14 22000 0.116571\n",
      "15 23000 0.114528\n",
      "19 24000 0.113283\n",
      "0 25000 0.114385\n",
      "9 26000 0.113969\n",
      "2 27000 0.114596\n",
      "19 28000 0.114905\n",
      "11 29000 0.114939\n",
      "7 30000 0.115006\n",
      "5 31000 0.114689\n",
      "7 32000 0.114953\n",
      "18 33000 0.115066\n",
      "16 34000 0.114993\n",
      "9 35000 0.11563\n",
      "12 36000 0.113433\n",
      "0 37000 0.121245\n",
      "15 38000 0.114956\n",
      "17 39000 0.114997\n",
      "2 40000 0.113638\n",
      "5 41000 0.116218\n",
      "7 42000 0.118442\n",
      "12 43000 0.119567\n",
      "17 44000 0.115007\n",
      "1 45000 0.115016\n",
      "7 46000 0.115434\n",
      "12 47000 0.116504\n",
      "1 48000 0.114807\n",
      "5 49000 0.115065\n",
      "7 50000 0.115042\n",
      "7 51000 0.114945\n",
      "0 52000 0.115066\n",
      "5 53000 0.115858\n",
      "12 54000 0.115899\n",
      "12 55000 0.114973\n",
      "17 56000 0.115473\n",
      "15 57000 0.114995\n",
      "3 58000 0.114836\n",
      "18 59000 0.11355\n",
      "1 60000 0.11537\n",
      "16 61000 0.114935\n",
      "5 62000 0.115052\n",
      "7 63000 0.117892\n",
      "2 64000 0.114688\n",
      "14 65000 0.114919\n",
      "18 66000 0.114107\n",
      "16 67000 0.114618\n",
      "16 68000 0.114957\n",
      "3 69000 0.112804\n",
      "7 70000 0.114413\n",
      "10 71000 0.115179\n",
      "1 72000 0.115048\n",
      "16 73000 0.1149\n",
      "10 74000 0.11507\n",
      "0 75000 0.115058\n",
      "18 76000 0.116113\n",
      "19 77000 0.116032\n",
      "6 78000 0.101562\n",
      "15 79000 0.115016\n",
      "16 80000 0.115314\n",
      "7 81000 0.11618\n",
      "18 82000 0.117198\n",
      "3 83000 0.112511\n",
      "12 84000 0.115708\n",
      "12 85000 0.112084\n",
      "18 86000 0.118169\n",
      "3 87000 0.114094\n",
      "11 88000 0.115028\n",
      "13 89000 0.114855\n",
      "4 90000 0.114816\n",
      "16 91000 0.114957\n",
      "6 92000 0.11506\n",
      "17 93000 0.115114\n",
      "3 94000 0.117352\n",
      "12 95000 0.11501\n",
      "3 96000 0.102521\n",
      "19 97000 0.115043\n",
      "9 98000 0.114992\n",
      "0 99000 0.119557\n",
      "R_square\n",
      "0.587211552943\n",
      "Result of predicting TrainingData\n",
      "[[ -2.01041281e-01]\n",
      " [ -5.17706811e-01]\n",
      " [ -4.92285341e-01]\n",
      " [ -1.13067135e-01]\n",
      " [ -1.13067135e-01]\n",
      " [ -1.80245712e-01]\n",
      " [ -2.03361899e-01]\n",
      " [  4.23937978e-04]\n",
      " [ -1.50997058e-01]\n",
      " [  9.70216841e-03]\n",
      " [  4.44599614e-02]\n",
      " [  5.22687614e-01]\n",
      " [ -1.36664525e-01]\n",
      " [  1.92800269e-01]\n",
      " [ -1.50693720e-02]\n",
      " [  8.91390517e-02]\n",
      " [ -1.51562467e-01]\n",
      " [  3.04239511e-01]\n",
      " [  3.85272987e-02]\n",
      " [  3.19983304e-01]]\n",
      "Result of predicting TestData\n",
      "[[-0.12689641]\n",
      " [ 0.30392048]\n",
      " [-0.38066065]\n",
      " [ 0.06281701]\n",
      " [-0.19762377]]\n",
      "Y_NormalizedData\n",
      "[-0.21844449 -0.47152439 -0.45735005 -0.1123416  -0.11245536 -0.18036006\n",
      " -0.19692817  0.00145492 -0.14520267  0.01178692  0.04523337  0.52847561\n",
      " -0.13421128  0.19149351 -0.00787756  0.09143864 -0.16016158  0.30505231\n",
      "  0.04222738  0.33060721 -0.08104142  0.20294599  0.18485121  0.07951933\n",
      "  0.2628122 ]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(100000):\n",
    "        SGDorder = Sequence[step % 20] # training을 0번부터 20번까지 순차적으로 돌린다.\n",
    "        session.run(train, feed_dict ={X: X_TrainingData[SGDorder: SGDorder + 1,:], Y: Y_TrainingData[SGDorder: SGDorder + 1]})\n",
    "        #session.run(train, feed_dict ={X: X_TrainingData, Y: Y_TrainingData})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print (SGDorder,step, session.run(cost, feed_dict = {X: X_TrainingData, Y: Y_TrainingData}))\n",
    "            #print (W1)\n",
    "            #print (b1)\n",
    "        if step % 20 == 0:\n",
    "            random.shuffle(Sequence)\n",
    "            \n",
    "    Predict_to_TestData = session.run(Hypothesis, feed_dict={X : X_TestData})\n",
    "    Predict_to_TrainingData = session.run(Hypothesis, feed_dict={X : X_TrainingData})\n",
    "    Predict_to_EntireData = session.run(Hypothesis, feed_dict = {X : X_NormalizedData})\n",
    "    \n",
    "    print(\"R_square\")\n",
    "    print(r2_score(Y_NormalizedData, Predict_to_EntireData))\n",
    "    print(\"Result of predicting TrainingData\")\n",
    "    print(Predict_to_TrainingData)\n",
    "    print(\"Result of predicting TestData\")\n",
    "    print(Predict_to_TestData)\n",
    "    print(\"Y_NormalizedData\")\n",
    "    print(Y_NormalizedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 6th eLU, tanh, 4, 50, 40, 30, 20, 1\n",
    "R2 = 0.728673962973"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "n_InputUnit = 4\n",
    "n_1stHiddenUnit=50\n",
    "n_2ndHiddenUnit=40\n",
    "n_3rdHiddenUnit=30\n",
    "n_4thHiddenUnit=20\n",
    "n_OutputUnit = 1\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([n_InputUnit, n_1stHiddenUnit],stddev=0.01))\n",
    "W2 = tf.Variable(tf.random_normal([n_1stHiddenUnit, n_2ndHiddenUnit],stddev=0.01))\n",
    "W3 = tf.Variable(tf.random_normal([n_2ndHiddenUnit, n_3rdHiddenUnit],stddev=0.01))\n",
    "W4 = tf.Variable(tf.random_normal([n_3rdHiddenUnit, n_4thHiddenUnit],stddev=0.01))\n",
    "W5 = tf.Variable(tf.random_normal([n_4thHiddenUnit, n_OutputUnit],stddev=0.01))\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([n_1stHiddenUnit], stddev=0.01))\n",
    "b2 = tf.Variable(tf.random_normal([n_2ndHiddenUnit], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([n_3rdHiddenUnit], stddev=0.01))\n",
    "b4 = tf.Variable(tf.random_normal([n_4thHiddenUnit], stddev=0.01))\n",
    "b5 = tf.Variable(tf.random_normal([n_OutputUnit], stddev=0.01))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 4]) # tensorflow의 placeholder라는 변수를 선언\n",
    "Y = tf.placeholder(tf.float32, [None,])\n",
    "\n",
    "L1 = tf.nn.elu(tf.matmul(X, W1) + b1)\n",
    "L2 = tf.nn.elu(tf.matmul(L1, W2) + b2)\n",
    "L3 = tf.nn.elu(tf.matmul(L2, W3) + b3)\n",
    "L4 = tf.nn.elu(tf.matmul(L3, W4) + b4)\n",
    "Hypothesis = tf.nn.tanh(tf.matmul(L4, W5) + b5)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(Y-Hypothesis))\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=0.5).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Train NN & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 0 0.0584089\n",
      "5 1000 0.0889852\n",
      "3 2000 0.096943\n",
      "19 3000 0.0955534\n",
      "0 4000 0.0826085\n",
      "14 5000 0.103788\n",
      "4 6000 0.094176\n",
      "1 7000 0.0958272\n",
      "14 8000 0.105854\n",
      "8 9000 0.110534\n",
      "7 10000 0.100915\n",
      "16 11000 0.118889\n",
      "1 12000 0.09571\n",
      "14 13000 0.112289\n",
      "6 14000 0.121041\n",
      "11 15000 0.110803\n",
      "4 16000 0.1061\n",
      "1 17000 0.108667\n",
      "0 18000 0.104039\n",
      "8 19000 0.112856\n",
      "10 20000 0.147471\n",
      "15 21000 0.105981\n",
      "11 22000 0.124301\n",
      "8 23000 0.114043\n",
      "5 24000 0.115559\n",
      "6 25000 0.11247\n",
      "8 26000 0.105947\n",
      "7 27000 0.111409\n",
      "5 28000 0.118417\n",
      "9 29000 0.122557\n",
      "10 30000 0.107671\n",
      "6 31000 0.113358\n",
      "17 32000 0.121184\n",
      "16 33000 0.109899\n",
      "6 34000 0.105591\n",
      "8 35000 0.114376\n",
      "6 36000 0.115434\n",
      "15 37000 0.115779\n",
      "10 38000 0.118606\n",
      "19 39000 0.126987\n",
      "4 40000 0.111636\n",
      "11 41000 0.115003\n",
      "15 42000 0.0954767\n",
      "0 43000 0.114065\n",
      "6 44000 0.113682\n",
      "6 45000 0.10701\n",
      "0 46000 0.115171\n",
      "1 47000 0.119999\n",
      "1 48000 0.0927157\n",
      "3 49000 0.113133\n",
      "0 50000 0.110648\n",
      "4 51000 0.120122\n",
      "9 52000 0.11475\n",
      "13 53000 0.112333\n",
      "18 54000 0.124206\n",
      "2 55000 0.114164\n",
      "2 56000 0.11451\n",
      "14 57000 0.114476\n",
      "11 58000 0.117963\n",
      "4 59000 0.115568\n",
      "2 60000 0.110492\n",
      "9 61000 0.116251\n",
      "4 62000 0.121134\n",
      "13 63000 0.105471\n",
      "19 64000 0.113777\n",
      "19 65000 0.11278\n",
      "18 66000 0.118396\n",
      "14 67000 0.119508\n",
      "13 68000 0.1167\n",
      "10 69000 0.116284\n",
      "1 70000 0.115271\n",
      "4 71000 0.113506\n",
      "17 72000 0.11762\n",
      "15 73000 0.113584\n",
      "10 74000 0.111099\n",
      "13 75000 0.115035\n",
      "0 76000 0.114316\n",
      "9 77000 0.114165\n",
      "19 78000 0.116734\n",
      "5 79000 0.114337\n",
      "0 80000 0.113938\n",
      "7 81000 0.115015\n",
      "13 82000 0.114852\n",
      "0 83000 0.113187\n",
      "4 84000 0.107094\n",
      "10 85000 0.115168\n",
      "18 86000 0.118149\n",
      "10 87000 0.111631\n",
      "3 88000 0.106889\n",
      "1 89000 0.0991202\n",
      "15 90000 0.113699\n",
      "17 91000 0.113706\n",
      "5 92000 0.113047\n",
      "5 93000 0.114609\n",
      "3 94000 0.114395\n",
      "8 95000 0.115713\n",
      "3 96000 0.111767\n",
      "19 97000 0.11312\n",
      "15 98000 0.11268\n",
      "0 99000 0.114619\n",
      "R_square\n",
      "0.728673962973\n",
      "Result of predicting TrainingData\n",
      "[[ -2.19678700e-01]\n",
      " [ -4.71858442e-01]\n",
      " [ -4.57779080e-01]\n",
      " [ -1.13577954e-01]\n",
      " [ -1.12822391e-01]\n",
      " [ -1.79411143e-01]\n",
      " [ -1.98558062e-01]\n",
      " [ -4.49873449e-04]\n",
      " [ -1.44282237e-01]\n",
      " [  1.14065288e-02]\n",
      " [  4.65921201e-02]\n",
      " [  5.29757500e-01]\n",
      " [ -1.34717524e-01]\n",
      " [  1.91002324e-01]\n",
      " [ -6.16817502e-03]\n",
      " [  9.07833874e-02]\n",
      " [ -1.60211965e-01]\n",
      " [  3.04636866e-01]\n",
      " [  4.12484668e-02]\n",
      " [  3.32541615e-01]]\n",
      "Result of predicting TestData\n",
      "[[-0.17071693]\n",
      " [ 0.07352177]\n",
      " [-0.29986262]\n",
      " [-0.01310892]\n",
      " [-0.04072192]]\n",
      "Y_NormalizedData\n",
      "[-0.21844449 -0.47152439 -0.45735005 -0.1123416  -0.11245536 -0.18036006\n",
      " -0.19692817  0.00145492 -0.14520267  0.01178692  0.04523337  0.52847561\n",
      " -0.13421128  0.19149351 -0.00787756  0.09143864 -0.16016158  0.30505231\n",
      "  0.04222738  0.33060721 -0.08104142  0.20294599  0.18485121  0.07951933\n",
      "  0.2628122 ]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(100000):\n",
    "        SGDorder = Sequence[step % 20] # training을 0번부터 20번까지 순차적으로 돌린다.\n",
    "        session.run(train, feed_dict ={X: X_TrainingData[SGDorder: SGDorder + 1,:], Y: Y_TrainingData[SGDorder: SGDorder + 1]})\n",
    "        #session.run(train, feed_dict ={X: X_TrainingData, Y: Y_TrainingData})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print (SGDorder,step, session.run(cost, feed_dict = {X: X_TrainingData, Y: Y_TrainingData}))\n",
    "            #print (W1)\n",
    "            #print (b1)\n",
    "        if step % 20 == 0:\n",
    "            random.shuffle(Sequence)\n",
    "            \n",
    "    Predict_to_TestData = session.run(Hypothesis, feed_dict={X : X_TestData})\n",
    "    Predict_to_TrainingData = session.run(Hypothesis, feed_dict={X : X_TrainingData})\n",
    "    Predict_to_EntireData = session.run(Hypothesis, feed_dict = {X : X_NormalizedData})\n",
    "    \n",
    "    print(\"R_square\")\n",
    "    print(r2_score(Y_NormalizedData, Predict_to_EntireData))\n",
    "    print(\"Result of predicting TrainingData\")\n",
    "    print(Predict_to_TrainingData)\n",
    "    print(\"Result of predicting TestData\")\n",
    "    print(Predict_to_TestData)\n",
    "    print(\"Y_NormalizedData\")\n",
    "    print(Y_NormalizedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 7th eLU, tanh, 4, 100, 100, 50, 1\n",
    "R2 = 0.801217519573"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "n_InputUnit = 4\n",
    "n_1stHiddenUnit=100\n",
    "n_2ndHiddenUnit=100\n",
    "n_3rdHiddenUnit=50\n",
    "n_OutputUnit = 1\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([n_InputUnit, n_1stHiddenUnit],stddev=0.01))\n",
    "W2 = tf.Variable(tf.random_normal([n_1stHiddenUnit, n_2ndHiddenUnit],stddev=0.01))\n",
    "W3 = tf.Variable(tf.random_normal([n_2ndHiddenUnit, n_3rdHiddenUnit],stddev=0.01))\n",
    "W4 = tf.Variable(tf.random_normal([n_3rdHiddenUnit, n_OutputUnit],stddev=0.01))\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([n_1stHiddenUnit], stddev=0.01))\n",
    "b2 = tf.Variable(tf.random_normal([n_2ndHiddenUnit], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([n_3rdHiddenUnit], stddev=0.01))\n",
    "b4 = tf.Variable(tf.random_normal([n_OutputUnit], stddev=0.01))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 4]) # tensorflow의 placeholder라는 변수를 선언\n",
    "Y = tf.placeholder(tf.float32, [None,])\n",
    "\n",
    "L1 = tf.nn.elu(tf.matmul(X, W1) + b1)\n",
    "L2 = tf.nn.elu(tf.matmul(L1, W2) + b2)\n",
    "L3 = tf.nn.elu(tf.matmul(L2, W3) + b3)\n",
    "Hypothesis = tf.nn.tanh(tf.matmul(L3, W4) + b4)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(Y-Hypothesis))\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=0.5).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Train NN & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0.058191\n",
      "1 1000 0.101107\n",
      "12 2000 0.0960644\n",
      "9 3000 0.0938841\n",
      "7 4000 0.114192\n",
      "11 5000 0.0969135\n",
      "3 6000 0.0922015\n",
      "9 7000 0.104336\n",
      "10 8000 0.102777\n",
      "12 9000 0.105459\n",
      "6 10000 0.109769\n",
      "5 11000 0.107603\n",
      "17 12000 0.116835\n",
      "6 13000 0.114466\n",
      "15 14000 0.100625\n",
      "5 15000 0.10978\n",
      "15 16000 0.11109\n",
      "8 17000 0.116498\n",
      "6 18000 0.115498\n",
      "1 19000 0.118965\n",
      "16 20000 0.128822\n",
      "12 21000 0.123297\n",
      "0 22000 0.114232\n",
      "11 23000 0.11745\n",
      "19 24000 0.113926\n",
      "19 25000 0.111348\n",
      "6 26000 0.117462\n",
      "3 27000 0.116889\n",
      "18 28000 0.121879\n",
      "10 29000 0.121835\n",
      "12 30000 0.122406\n",
      "2 31000 0.11689\n",
      "17 32000 0.118096\n",
      "12 33000 0.117157\n",
      "18 34000 0.113255\n",
      "18 35000 0.118077\n",
      "10 36000 0.111037\n",
      "7 37000 0.114608\n",
      "6 38000 0.113373\n",
      "17 39000 0.110088\n",
      "17 40000 0.115716\n",
      "1 41000 0.115978\n",
      "13 42000 0.116177\n",
      "13 43000 0.111218\n",
      "7 44000 0.11466\n",
      "1 45000 0.111398\n",
      "4 46000 0.121792\n",
      "5 47000 0.112257\n",
      "10 48000 0.114788\n",
      "13 49000 0.118285\n",
      "10 50000 0.113396\n",
      "15 51000 0.115431\n",
      "19 52000 0.11741\n",
      "9 53000 0.115719\n",
      "17 54000 0.117874\n",
      "3 55000 0.114671\n",
      "13 56000 0.115848\n",
      "6 57000 0.115692\n",
      "19 58000 0.113692\n",
      "15 59000 0.114874\n",
      "19 60000 0.116272\n",
      "17 61000 0.114847\n",
      "17 62000 0.111686\n",
      "13 63000 0.113059\n",
      "8 64000 0.113302\n",
      "18 65000 0.114451\n",
      "5 66000 0.117157\n",
      "8 67000 0.11602\n",
      "13 68000 0.120187\n",
      "17 69000 0.114912\n",
      "11 70000 0.114386\n",
      "13 71000 0.113907\n",
      "18 72000 0.119443\n",
      "10 73000 0.114939\n",
      "0 74000 0.113874\n",
      "4 75000 0.114823\n",
      "9 76000 0.114977\n",
      "2 77000 0.115378\n",
      "5 78000 0.118994\n",
      "2 79000 0.115007\n",
      "6 80000 0.104364\n",
      "15 81000 0.108914\n",
      "16 82000 0.115022\n",
      "7 83000 0.115606\n",
      "1 84000 0.114882\n",
      "7 85000 0.11483\n",
      "19 86000 0.113868\n",
      "6 87000 0.116933\n",
      "9 88000 0.112411\n",
      "3 89000 0.115277\n",
      "3 90000 0.114229\n",
      "2 91000 0.116206\n",
      "2 92000 0.115032\n",
      "18 93000 0.114325\n",
      "9 94000 0.116427\n",
      "9 95000 0.118274\n",
      "11 96000 0.116074\n",
      "7 97000 0.123573\n",
      "7 98000 0.114924\n",
      "4 99000 0.111653\n",
      "R_square\n",
      "0.801217519573\n",
      "Result of predicting TrainingData\n",
      "[[-0.197071  ]\n",
      " [-0.44771084]\n",
      " [-0.44095361]\n",
      " [-0.10359816]\n",
      " [-0.09243078]\n",
      " [-0.15445872]\n",
      " [-0.17846753]\n",
      " [-0.02352535]\n",
      " [-0.12809289]\n",
      " [ 0.01972234]\n",
      " [ 0.02907962]\n",
      " [ 0.51202983]\n",
      " [-0.11719534]\n",
      " [ 0.17425452]\n",
      " [-0.00711534]\n",
      " [ 0.09386291]\n",
      " [-0.16994509]\n",
      " [ 0.26495749]\n",
      " [ 0.05945806]\n",
      " [ 0.31810269]]\n",
      "Result of predicting TestData\n",
      "[[-0.04531691]\n",
      " [ 0.24917626]\n",
      " [-0.26274458]\n",
      " [ 0.071194  ]\n",
      " [ 0.03209667]]\n",
      "Y_NormalizedData\n",
      "[-0.21844449 -0.47152439 -0.45735005 -0.1123416  -0.11245536 -0.18036006\n",
      " -0.19692817  0.00145492 -0.14520267  0.01178692  0.04523337  0.52847561\n",
      " -0.13421128  0.19149351 -0.00787756  0.09143864 -0.16016158  0.30505231\n",
      "  0.04222738  0.33060721 -0.08104142  0.20294599  0.18485121  0.07951933\n",
      "  0.2628122 ]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(100000):\n",
    "        SGDorder = Sequence[step % 20] # training을 0번부터 20번까지 순차적으로 돌린다.\n",
    "        session.run(train, feed_dict ={X: X_TrainingData[SGDorder: SGDorder + 1,:], Y: Y_TrainingData[SGDorder: SGDorder + 1]})\n",
    "        #session.run(train, feed_dict ={X: X_TrainingData, Y: Y_TrainingData})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print (SGDorder,step, session.run(cost, feed_dict = {X: X_TrainingData, Y: Y_TrainingData}))\n",
    "            #print (W1)\n",
    "            #print (b1)\n",
    "        if step % 20 == 0:\n",
    "            random.shuffle(Sequence)\n",
    "            \n",
    "    Predict_to_TestData = session.run(Hypothesis, feed_dict={X : X_TestData})\n",
    "    Predict_to_TrainingData = session.run(Hypothesis, feed_dict={X : X_TrainingData})\n",
    "    Predict_to_EntireData = session.run(Hypothesis, feed_dict = {X : X_NormalizedData})\n",
    "    \n",
    "    print(\"R_square\")\n",
    "    print(r2_score(Y_NormalizedData, Predict_to_EntireData))\n",
    "    print(\"Result of predicting TrainingData\")\n",
    "    print(Predict_to_TrainingData)\n",
    "    print(\"Result of predicting TestData\")\n",
    "    print(Predict_to_TestData)\n",
    "    print(\"Y_NormalizedData\")\n",
    "    print(Y_NormalizedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 8th eLU, tanh, 4, 10, 10, 10, 10, 10, 10, 1\n",
    "R2 = 0.616077753531"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "n_InputUnit = 4\n",
    "n_1stHiddenUnit=10\n",
    "n_2ndHiddenUnit=10\n",
    "n_3rdHiddenUnit=10\n",
    "n_4thHiddenUnit=10\n",
    "n_5thHiddenUnit=10\n",
    "n_6thHiddenUnit=10\n",
    "n_OutputUnit = 1\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([n_InputUnit, n_1stHiddenUnit],stddev=0.01))\n",
    "W2 = tf.Variable(tf.random_normal([n_1stHiddenUnit, n_2ndHiddenUnit],stddev=0.01))\n",
    "W3 = tf.Variable(tf.random_normal([n_2ndHiddenUnit, n_3rdHiddenUnit],stddev=0.01))\n",
    "W4 = tf.Variable(tf.random_normal([n_3rdHiddenUnit, n_4thHiddenUnit],stddev=0.01))\n",
    "W5 = tf.Variable(tf.random_normal([n_4thHiddenUnit, n_5thHiddenUnit],stddev=0.01))\n",
    "W6 = tf.Variable(tf.random_normal([n_5thHiddenUnit, n_6thHiddenUnit],stddev=0.01))\n",
    "W7 = tf.Variable(tf.random_normal([n_6thHiddenUnit, n_OutputUnit],stddev=0.01))\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([n_1stHiddenUnit], stddev=0.01))\n",
    "b2 = tf.Variable(tf.random_normal([n_2ndHiddenUnit], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([n_3rdHiddenUnit], stddev=0.01))\n",
    "b4 = tf.Variable(tf.random_normal([n_4thHiddenUnit], stddev=0.01))\n",
    "b5 = tf.Variable(tf.random_normal([n_5thHiddenUnit], stddev=0.01))\n",
    "b6 = tf.Variable(tf.random_normal([n_6thHiddenUnit], stddev=0.01))\n",
    "b7 = tf.Variable(tf.random_normal([n_OutputUnit], stddev=0.01))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 4]) # tensorflow의 placeholder라는 변수를 선언\n",
    "Y = tf.placeholder(tf.float32, [None,])\n",
    "\n",
    "L1 = tf.nn.elu(tf.matmul(X, W1) + b1)\n",
    "L2 = tf.nn.elu(tf.matmul(L1, W2) + b2)\n",
    "L3 = tf.nn.elu(tf.matmul(L2, W3) + b3)\n",
    "L4 = tf.nn.elu(tf.matmul(L3, W4) + b4)\n",
    "L5 = tf.nn.elu(tf.matmul(L4, W5) + b5)\n",
    "L6 = tf.nn.elu(tf.matmul(L5, W6) + b6)\n",
    "Hypothesis = tf.nn.tanh(tf.matmul(L6, W7) + b7)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(Y-Hypothesis))\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=0.5).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Train NN & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 0 0.0584986\n",
      "4 1000 0.05751\n",
      "0 2000 0.0575096\n",
      "9 3000 0.0575098\n",
      "2 4000 0.0575105\n",
      "19 5000 0.0575096\n",
      "1 6000 0.0575096\n",
      "6 7000 0.0575095\n",
      "10 8000 0.0910533\n",
      "6 9000 0.0927686\n",
      "14 10000 0.094628\n",
      "19 11000 0.0938583\n",
      "8 12000 0.0980775\n",
      "19 13000 0.0966723\n",
      "2 14000 0.0971877\n",
      "7 15000 0.0984727\n",
      "9 16000 0.104427\n",
      "19 17000 0.0991159\n",
      "12 18000 0.10123\n",
      "19 19000 0.106698\n",
      "6 20000 0.101266\n",
      "2 21000 0.105709\n",
      "18 22000 0.108244\n",
      "1 23000 0.103687\n",
      "18 24000 0.10294\n",
      "11 25000 0.106746\n",
      "0 26000 0.101528\n",
      "6 27000 0.109472\n",
      "16 28000 0.111191\n",
      "16 29000 0.108533\n",
      "6 30000 0.115233\n",
      "10 31000 0.1034\n",
      "14 32000 0.114603\n",
      "11 33000 0.103743\n",
      "7 34000 0.109129\n",
      "19 35000 0.119815\n",
      "6 36000 0.110349\n",
      "7 37000 0.10667\n",
      "9 38000 0.113066\n",
      "12 39000 0.110166\n",
      "2 40000 0.105086\n",
      "9 41000 0.1098\n",
      "15 42000 0.110773\n",
      "0 43000 0.10842\n",
      "9 44000 0.115677\n",
      "7 45000 0.116446\n",
      "7 46000 0.111838\n",
      "5 47000 0.105516\n",
      "15 48000 0.108791\n",
      "17 49000 0.111241\n",
      "12 50000 0.10988\n",
      "10 51000 0.109114\n",
      "12 52000 0.113994\n",
      "14 53000 0.10778\n",
      "7 54000 0.115579\n",
      "0 55000 0.114109\n",
      "10 56000 0.108697\n",
      "18 57000 0.112169\n",
      "16 58000 0.111795\n",
      "4 59000 0.114286\n",
      "1 60000 0.112661\n",
      "8 61000 0.114285\n",
      "2 62000 0.112709\n",
      "14 63000 0.11488\n",
      "4 64000 0.112579\n",
      "1 65000 0.124009\n",
      "14 66000 0.114275\n",
      "8 67000 0.113272\n",
      "10 68000 0.11966\n",
      "4 69000 0.118877\n",
      "15 70000 0.112887\n",
      "0 71000 0.126015\n",
      "6 72000 0.1132\n",
      "2 73000 0.11642\n",
      "10 74000 0.115169\n",
      "4 75000 0.111301\n",
      "4 76000 0.115532\n",
      "18 77000 0.113409\n",
      "2 78000 0.116047\n",
      "9 79000 0.115088\n",
      "4 80000 0.110795\n",
      "2 81000 0.115015\n",
      "18 82000 0.11435\n",
      "2 83000 0.112299\n",
      "11 84000 0.110009\n",
      "16 85000 0.112591\n",
      "3 86000 0.117763\n",
      "10 87000 0.123315\n",
      "2 88000 0.114587\n",
      "11 89000 0.114723\n",
      "18 90000 0.116465\n",
      "10 91000 0.114177\n",
      "11 92000 0.116005\n",
      "14 93000 0.124741\n",
      "14 94000 0.110358\n",
      "9 95000 0.117011\n",
      "8 96000 0.118681\n",
      "5 97000 0.112259\n",
      "16 98000 0.11805\n",
      "4 99000 0.113475\n",
      "R_square\n",
      "0.616077753531\n",
      "Result of predicting TrainingData\n",
      "[[-0.21397132]\n",
      " [-0.47306699]\n",
      " [-0.4574824 ]\n",
      " [-0.10765294]\n",
      " [-0.11102898]\n",
      " [-0.18158379]\n",
      " [-0.19013895]\n",
      " [-0.00272008]\n",
      " [-0.14264292]\n",
      " [ 0.01280492]\n",
      " [ 0.04653285]\n",
      " [ 0.52982956]\n",
      " [-0.13183691]\n",
      " [ 0.19346395]\n",
      " [-0.00791548]\n",
      " [ 0.09286185]\n",
      " [-0.16145721]\n",
      " [ 0.30705816]\n",
      " [ 0.04793849]\n",
      " [ 0.32511383]]\n",
      "Result of predicting TestData\n",
      "[[ 0.046147  ]\n",
      " [ 0.34756127]\n",
      " [-0.50241733]\n",
      " [ 0.06829826]\n",
      " [ 0.24514864]]\n",
      "Y_NormalizedData\n",
      "[-0.21844449 -0.47152439 -0.45735005 -0.1123416  -0.11245536 -0.18036006\n",
      " -0.19692817  0.00145492 -0.14520267  0.01178692  0.04523337  0.52847561\n",
      " -0.13421128  0.19149351 -0.00787756  0.09143864 -0.16016158  0.30505231\n",
      "  0.04222738  0.33060721 -0.08104142  0.20294599  0.18485121  0.07951933\n",
      "  0.2628122 ]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(100000):\n",
    "        SGDorder = Sequence[step % 20] # training을 0번부터 20번까지 순차적으로 돌린다.\n",
    "        session.run(train, feed_dict ={X: X_TrainingData[SGDorder: SGDorder + 1,:], Y: Y_TrainingData[SGDorder: SGDorder + 1]})\n",
    "        #session.run(train, feed_dict ={X: X_TrainingData, Y: Y_TrainingData})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print (SGDorder,step, session.run(cost, feed_dict = {X: X_TrainingData, Y: Y_TrainingData}))\n",
    "            #print (W1)\n",
    "            #print (b1)\n",
    "        if step % 20 == 0:\n",
    "            random.shuffle(Sequence)\n",
    "            \n",
    "    Predict_to_TestData = session.run(Hypothesis, feed_dict={X : X_TestData})\n",
    "    Predict_to_TrainingData = session.run(Hypothesis, feed_dict={X : X_TrainingData})\n",
    "    Predict_to_EntireData = session.run(Hypothesis, feed_dict = {X : X_NormalizedData})\n",
    "    \n",
    "    print(\"R_square\")\n",
    "    print(r2_score(Y_NormalizedData, Predict_to_EntireData))\n",
    "    print(\"Result of predicting TrainingData\")\n",
    "    print(Predict_to_TrainingData)\n",
    "    print(\"Result of predicting TestData\")\n",
    "    print(Predict_to_TestData)\n",
    "    print(\"Y_NormalizedData\")\n",
    "    print(Y_NormalizedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 9th eLU, tanh, 4, 500, 500, 100, 1\n",
    "R2 = 0.76630321537"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "n_InputUnit = 4\n",
    "n_1stHiddenUnit=500\n",
    "n_2ndHiddenUnit=500\n",
    "n_3rdHiddenUnit=100\n",
    "n_OutputUnit = 1\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([n_InputUnit, n_1stHiddenUnit],stddev=0.01))\n",
    "W2 = tf.Variable(tf.random_normal([n_1stHiddenUnit, n_2ndHiddenUnit],stddev=0.01))\n",
    "W3 = tf.Variable(tf.random_normal([n_2ndHiddenUnit, n_3rdHiddenUnit],stddev=0.01))\n",
    "W4 = tf.Variable(tf.random_normal([n_3rdHiddenUnit, n_OutputUnit],stddev=0.01))\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([n_1stHiddenUnit], stddev=0.01))\n",
    "b2 = tf.Variable(tf.random_normal([n_2ndHiddenUnit], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([n_3rdHiddenUnit], stddev=0.01))\n",
    "b4 = tf.Variable(tf.random_normal([n_OutputUnit], stddev=0.01))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 4]) # tensorflow의 placeholder라는 변수를 선언\n",
    "Y = tf.placeholder(tf.float32, [None,])\n",
    "\n",
    "L1 = tf.nn.elu(tf.matmul(X, W1) + b1)\n",
    "L2 = tf.nn.elu(tf.matmul(L1, W2) + b2)\n",
    "L3 = tf.nn.elu(tf.matmul(L2, W3) + b3)\n",
    "Hypothesis = tf.nn.tanh(tf.matmul(L3, W4) + b4)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(Y-Hypothesis))\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=0.5).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Train NN & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0 0.0591716\n",
      "9 1000 0.0892799\n",
      "16 2000 0.10809\n",
      "3 3000 0.103186\n",
      "7 4000 0.103598\n",
      "14 5000 0.117744\n",
      "16 6000 0.127433\n",
      "1 7000 0.114091\n",
      "19 8000 0.104694\n",
      "1 9000 0.116884\n",
      "14 10000 0.141292\n",
      "8 11000 0.120442\n",
      "10 12000 0.127927\n",
      "2 13000 0.116145\n",
      "18 14000 0.130627\n",
      "8 15000 0.110261\n",
      "12 16000 0.111499\n",
      "1 17000 0.112028\n",
      "13 18000 0.116446\n",
      "10 19000 0.108579\n",
      "0 20000 0.112549\n",
      "9 21000 0.121002\n",
      "7 22000 0.117856\n",
      "11 23000 0.11388\n",
      "1 24000 0.114377\n",
      "14 25000 0.11183\n",
      "6 26000 0.128711\n",
      "10 27000 0.124649\n",
      "0 28000 0.112747\n",
      "2 29000 0.126037\n",
      "5 30000 0.116953\n",
      "8 31000 0.10597\n",
      "14 32000 0.119594\n",
      "16 33000 0.108452\n",
      "10 34000 0.100466\n",
      "13 35000 0.108436\n",
      "9 36000 0.122141\n",
      "2 37000 0.115701\n",
      "7 38000 0.11209\n",
      "6 39000 0.0956433\n",
      "10 40000 0.1147\n",
      "13 41000 0.114312\n",
      "15 42000 0.118883\n",
      "12 43000 0.115445\n",
      "2 44000 0.116235\n",
      "14 45000 0.112408\n",
      "3 46000 0.113826\n",
      "18 47000 0.115152\n",
      "5 48000 0.113972\n",
      "10 49000 0.18944\n",
      "7 50000 0.114084\n",
      "19 51000 0.10623\n",
      "2 52000 0.116874\n",
      "12 53000 0.108805\n",
      "16 54000 0.122585\n",
      "7 55000 0.116312\n",
      "4 56000 0.107072\n",
      "4 57000 0.116556\n",
      "1 58000 0.120994\n",
      "6 59000 0.120673\n",
      "3 60000 0.11565\n",
      "18 61000 0.113339\n",
      "12 62000 0.111645\n",
      "16 63000 0.114224\n",
      "12 64000 0.119451\n",
      "19 65000 0.122786\n",
      "7 66000 0.115837\n",
      "5 67000 0.115428\n",
      "14 68000 0.122125\n",
      "3 69000 0.115142\n",
      "19 70000 0.114674\n",
      "1 71000 0.134605\n",
      "5 72000 0.125623\n",
      "6 73000 0.11789\n",
      "8 74000 0.115415\n",
      "17 75000 0.110184\n",
      "11 76000 0.109592\n",
      "14 77000 0.114217\n",
      "16 78000 0.111609\n",
      "18 79000 0.118173\n",
      "8 80000 0.11619\n",
      "11 81000 0.112834\n",
      "2 82000 0.117221\n",
      "11 83000 0.117548\n",
      "2 84000 0.114181\n",
      "18 85000 0.116904\n",
      "7 86000 0.117119\n",
      "6 87000 0.112489\n",
      "10 88000 0.115546\n",
      "0 89000 0.113714\n",
      "10 90000 0.124561\n",
      "3 91000 0.118179\n",
      "5 92000 0.137609\n",
      "4 93000 0.11858\n",
      "13 94000 0.115083\n",
      "2 95000 0.116031\n",
      "2 96000 0.11574\n",
      "8 97000 0.115118\n",
      "12 98000 0.11518\n",
      "16 99000 0.115031\n",
      "R_square\n",
      "0.76630321537\n",
      "Result of predicting TrainingData\n",
      "[[-0.19098325]\n",
      " [-0.42580888]\n",
      " [-0.44795826]\n",
      " [-0.11214798]\n",
      " [-0.05445065]\n",
      " [-0.15306319]\n",
      " [-0.17880888]\n",
      " [-0.00382708]\n",
      " [-0.14859299]\n",
      " [ 0.02697191]\n",
      " [ 0.04566457]\n",
      " [ 0.55551291]\n",
      " [-0.10497236]\n",
      " [ 0.15589622]\n",
      " [ 0.01213767]\n",
      " [ 0.08947811]\n",
      " [-0.18193437]\n",
      " [ 0.30805594]\n",
      " [ 0.04367873]\n",
      " [ 0.35430574]]\n",
      "Result of predicting TestData\n",
      "[[-0.10468662]\n",
      " [ 0.0092185 ]\n",
      " [-0.25743201]\n",
      " [-0.03067329]\n",
      " [ 0.03326405]]\n",
      "Y_NormalizedData\n",
      "[-0.21844449 -0.47152439 -0.45735005 -0.1123416  -0.11245536 -0.18036006\n",
      " -0.19692817  0.00145492 -0.14520267  0.01178692  0.04523337  0.52847561\n",
      " -0.13421128  0.19149351 -0.00787756  0.09143864 -0.16016158  0.30505231\n",
      "  0.04222738  0.33060721 -0.08104142  0.20294599  0.18485121  0.07951933\n",
      "  0.2628122 ]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(100000):\n",
    "        SGDorder = Sequence[step % 20] # training을 0번부터 20번까지 순차적으로 돌린다.\n",
    "        session.run(train, feed_dict ={X: X_TrainingData[SGDorder: SGDorder + 1,:], Y: Y_TrainingData[SGDorder: SGDorder + 1]})\n",
    "        #session.run(train, feed_dict ={X: X_TrainingData, Y: Y_TrainingData})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print (SGDorder,step, session.run(cost, feed_dict = {X: X_TrainingData, Y: Y_TrainingData}))\n",
    "            #print (W1)\n",
    "            #print (b1)\n",
    "        if step % 20 == 0:\n",
    "            random.shuffle(Sequence)\n",
    "            \n",
    "    Predict_to_TestData = session.run(Hypothesis, feed_dict={X : X_TestData})\n",
    "    Predict_to_TrainingData = session.run(Hypothesis, feed_dict={X : X_TrainingData})\n",
    "    Predict_to_EntireData = session.run(Hypothesis, feed_dict = {X : X_NormalizedData})\n",
    "    \n",
    "    print(\"R_square\")\n",
    "    print(r2_score(Y_NormalizedData, Predict_to_EntireData))\n",
    "    print(\"Result of predicting TrainingData\")\n",
    "    print(Predict_to_TrainingData)\n",
    "    print(\"Result of predicting TestData\")\n",
    "    print(Predict_to_TestData)\n",
    "    print(\"Y_NormalizedData\")\n",
    "    print(Y_NormalizedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 10th eLU, tanh, 4, 100, 100, 100, 50, 1\n",
    "R2 = 0.834434007079"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "n_InputUnit = 4\n",
    "n_1stHiddenUnit=100\n",
    "n_2ndHiddenUnit=100\n",
    "n_3rdHiddenUnit=100\n",
    "n_4thHiddenUnit=50\n",
    "n_OutputUnit = 1\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([n_InputUnit, n_1stHiddenUnit],stddev=0.01))\n",
    "W2 = tf.Variable(tf.random_normal([n_1stHiddenUnit, n_2ndHiddenUnit],stddev=0.01))\n",
    "W3 = tf.Variable(tf.random_normal([n_2ndHiddenUnit, n_3rdHiddenUnit],stddev=0.01))\n",
    "W4 = tf.Variable(tf.random_normal([n_3rdHiddenUnit, n_4thHiddenUnit],stddev=0.01))\n",
    "W5 = tf.Variable(tf.random_normal([n_4thHiddenUnit, n_OutputUnit],stddev=0.01))\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([n_1stHiddenUnit], stddev=0.01))\n",
    "b2 = tf.Variable(tf.random_normal([n_2ndHiddenUnit], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([n_3rdHiddenUnit], stddev=0.01))\n",
    "b4 = tf.Variable(tf.random_normal([n_4thHiddenUnit], stddev=0.01))\n",
    "b5 = tf.Variable(tf.random_normal([n_OutputUnit], stddev=0.01))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 4]) # tensorflow의 placeholder라는 변수를 선언\n",
    "Y = tf.placeholder(tf.float32, [None,])\n",
    "\n",
    "L1 = tf.nn.elu(tf.matmul(X, W1) + b1)\n",
    "L2 = tf.nn.elu(tf.matmul(L1, W2) + b2)\n",
    "L3 = tf.nn.elu(tf.matmul(L2, W3) + b3)\n",
    "L4 = tf.nn.elu(tf.matmul(L3, W4) + b4)\n",
    "Hypothesis = tf.nn.tanh(tf.matmul(L4, W5) + b5)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(Y-Hypothesis))\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=0.5).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Train NN & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0.0591532\n",
      "9 1000 0.0819874\n",
      "3 2000 0.111594\n",
      "18 3000 0.0960085\n",
      "0 4000 0.101961\n",
      "15 5000 0.0962025\n",
      "15 6000 0.102826\n",
      "18 7000 0.109316\n",
      "4 8000 0.101001\n",
      "5 9000 0.1166\n",
      "9 10000 0.0995242\n",
      "3 11000 0.11739\n",
      "15 12000 0.116031\n",
      "11 13000 0.119342\n",
      "15 14000 0.102046\n",
      "9 15000 0.128017\n",
      "14 16000 0.114145\n",
      "10 17000 0.10797\n",
      "11 18000 0.118899\n",
      "10 19000 0.112987\n",
      "5 20000 0.113118\n",
      "2 21000 0.118085\n",
      "9 22000 0.119887\n",
      "4 23000 0.117802\n",
      "15 24000 0.111444\n",
      "0 25000 0.110789\n",
      "1 26000 0.114857\n",
      "0 27000 0.114896\n",
      "7 28000 0.118763\n",
      "3 29000 0.112085\n",
      "19 30000 0.107129\n",
      "3 31000 0.114253\n",
      "1 32000 0.114603\n",
      "12 33000 0.114935\n",
      "6 34000 0.124381\n",
      "1 35000 0.113026\n",
      "11 36000 0.114894\n",
      "0 37000 0.115068\n",
      "14 38000 0.115593\n",
      "0 39000 0.115816\n",
      "11 40000 0.108769\n",
      "18 41000 0.114977\n",
      "3 42000 0.116739\n",
      "17 43000 0.11549\n",
      "4 44000 0.112316\n",
      "4 45000 0.11509\n",
      "19 46000 0.148605\n",
      "17 47000 0.115076\n",
      "9 48000 0.115063\n",
      "15 49000 0.113165\n",
      "15 50000 0.11599\n",
      "3 51000 0.101449\n",
      "15 52000 0.115462\n",
      "3 53000 0.112869\n",
      "19 54000 0.115575\n",
      "14 55000 0.11646\n",
      "17 56000 0.115033\n",
      "2 57000 0.114915\n",
      "6 58000 0.114728\n",
      "11 59000 0.114823\n",
      "4 60000 0.115959\n",
      "12 61000 0.116477\n",
      "12 62000 0.115852\n",
      "12 63000 0.114948\n",
      "4 64000 0.118177\n",
      "5 65000 0.114804\n",
      "9 66000 0.115601\n",
      "11 67000 0.114915\n",
      "5 68000 0.114917\n",
      "15 69000 0.115348\n",
      "15 70000 0.115523\n",
      "13 71000 0.114196\n",
      "3 72000 0.114819\n",
      "5 73000 0.115597\n",
      "0 74000 0.11391\n",
      "0 75000 0.115513\n",
      "17 76000 0.125552\n",
      "11 77000 0.11494\n",
      "13 78000 0.114922\n",
      "4 79000 0.11535\n",
      "6 80000 0.115807\n",
      "3 81000 0.116848\n",
      "16 82000 0.115343\n",
      "4 83000 0.119187\n",
      "16 84000 0.115031\n",
      "5 85000 0.115502\n",
      "11 86000 0.120433\n",
      "16 87000 0.114975\n",
      "10 88000 0.117912\n",
      "17 89000 0.114597\n",
      "13 90000 0.112128\n",
      "6 91000 0.120953\n",
      "2 92000 0.114623\n",
      "18 93000 0.113754\n",
      "19 94000 0.116932\n",
      "15 95000 0.116596\n",
      "5 96000 0.118289\n",
      "13 97000 0.113642\n",
      "6 98000 0.114567\n",
      "13 99000 0.119024\n",
      "R_square\n",
      "0.834434007079\n",
      "Result of predicting TrainingData\n",
      "[[-0.2168038 ]\n",
      " [-0.47999686]\n",
      " [-0.46920249]\n",
      " [-0.1069559 ]\n",
      " [-0.1116661 ]\n",
      " [-0.18702251]\n",
      " [-0.19961496]\n",
      " [-0.0016965 ]\n",
      " [-0.15646128]\n",
      " [ 0.01666788]\n",
      " [ 0.04721088]\n",
      " [ 0.52247089]\n",
      " [-0.13335589]\n",
      " [ 0.19138078]\n",
      " [-0.01083938]\n",
      " [ 0.08862348]\n",
      " [-0.16051023]\n",
      " [ 0.30288148]\n",
      " [ 0.04358968]\n",
      " [ 0.32692093]]\n",
      "Result of predicting TestData\n",
      "[[-0.24661477]\n",
      " [ 0.26052132]\n",
      " [-0.19027884]\n",
      " [-0.11316925]\n",
      " [ 0.15864241]]\n",
      "Y_NormalizedData\n",
      "[-0.21844449 -0.47152439 -0.45735005 -0.1123416  -0.11245536 -0.18036006\n",
      " -0.19692817  0.00145492 -0.14520267  0.01178692  0.04523337  0.52847561\n",
      " -0.13421128  0.19149351 -0.00787756  0.09143864 -0.16016158  0.30505231\n",
      "  0.04222738  0.33060721 -0.08104142  0.20294599  0.18485121  0.07951933\n",
      "  0.2628122 ]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(100000):\n",
    "        SGDorder = Sequence[step % 20] # training을 0번부터 20번까지 순차적으로 돌린다.\n",
    "        session.run(train, feed_dict ={X: X_TrainingData[SGDorder: SGDorder + 1,:], Y: Y_TrainingData[SGDorder: SGDorder + 1]})\n",
    "        #session.run(train, feed_dict ={X: X_TrainingData, Y: Y_TrainingData})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print (SGDorder,step, session.run(cost, feed_dict = {X: X_TrainingData, Y: Y_TrainingData}))\n",
    "            #print (W1)\n",
    "            #print (b1)\n",
    "        if step % 20 == 0:\n",
    "            random.shuffle(Sequence)\n",
    "            \n",
    "    Predict_to_TestData = session.run(Hypothesis, feed_dict={X : X_TestData})\n",
    "    Predict_to_TrainingData = session.run(Hypothesis, feed_dict={X : X_TrainingData})\n",
    "    Predict_to_EntireData = session.run(Hypothesis, feed_dict = {X : X_NormalizedData})\n",
    "    \n",
    "    print(\"R_square\")\n",
    "    print(r2_score(Y_NormalizedData, Predict_to_EntireData))\n",
    "    print(\"Result of predicting TrainingData\")\n",
    "    print(Predict_to_TrainingData)\n",
    "    print(\"Result of predicting TestData\")\n",
    "    print(Predict_to_TestData)\n",
    "    print(\"Y_NormalizedData\")\n",
    "    print(Y_NormalizedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "426px",
    "left": "1770.98px",
    "right": "20px",
    "top": "120.984px",
    "width": "354px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
