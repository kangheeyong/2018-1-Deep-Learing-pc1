{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n",
    "\n",
    "# 2nd eLU, tanh, 4, 50, 50, 50, 1\n",
    "## Model\n",
    "## Train NN & Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data (normalized) & Separate to Training and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.   0.   0.5  0.5]\n",
      " [ 0.  -0.5  0.   0.5]\n",
      " [-0.5 -0.5  0.   0. ]\n",
      " [-0.5  0.   0.5  0. ]\n",
      " [ 0.5  0.   0.   0.5]\n",
      " [ 0.   0.  -0.5  0.5]\n",
      " [ 0.5 -0.5  0.   0. ]\n",
      " [ 0.   0.  -0.5 -0.5]\n",
      " [ 0.  -0.5 -0.5  0. ]\n",
      " [ 0.   0.   0.5 -0.5]\n",
      " [-0.5  0.   0.  -0.5]\n",
      " [ 0.5  0.5  0.   0. ]\n",
      " [ 0.  -0.5  0.5  0. ]\n",
      " [-0.5  0.5  0.   0. ]\n",
      " [ 0.5  0.   0.  -0.5]\n",
      " [-0.5  0.  -0.5  0. ]\n",
      " [ 0.   0.5  0.5  0. ]\n",
      " [ 0.   0.5  0.  -0.5]\n",
      " [ 0.5  0.   0.5  0. ]\n",
      " [ 0.   0.5 -0.5  0. ]]\n",
      "------------------------\n",
      "[[ 0.  -0.5  0.  -0.5]\n",
      " [ 0.5  0.  -0.5  0. ]\n",
      " [-0.5  0.   0.   0.5]\n",
      " [ 0.   0.   0.   0. ]\n",
      " [ 0.   0.5  0.   0.5]]\n",
      "------------------------\n",
      "[-0.21844449 -0.47152439 -0.45735005 -0.1123416  -0.11245536 -0.18036006\n",
      " -0.19692817  0.00145492 -0.14520267  0.01178692  0.04523337  0.52847561\n",
      " -0.13421128  0.19149351 -0.00787756  0.09143864 -0.16016158  0.30505231\n",
      "  0.04222738  0.33060721]\n",
      "------------------------\n",
      "[-0.08104142  0.20294599  0.18485121  0.07951933  0.2628122 ]\n"
     ]
    }
   ],
   "source": [
    "#data = np.loadtxt(\"ACL nomalization data.txt\")\n",
    "#data2 = np.loadtxt(\"acl data.txt\")\n",
    "data = np.loadtxt(\"ACL FTIR data_mean.txt\")\n",
    "\n",
    "X_NormalizedData = data[:,0:4]\n",
    "X_NormalizedData = X_NormalizedData - 0.5\n",
    "Y_NormalizedData = data[:,4]\n",
    "\n",
    "X_TrainingData = data[0:20,0:4]\n",
    "X_TrainingData = X_TrainingData - 0.5\n",
    "Y_TrainingData = data[0:20,4]\n",
    "\n",
    "X_TestData = data[20:,0:4]\n",
    "X_TestData = X_TestData - 0.5\n",
    "Y_TestData = data[20:,4]\n",
    "\n",
    "Sequence = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19]\n",
    "\n",
    "#XY_TrainingData = data[0:21,:]\n",
    "#X_TrainingData = XY_TrainingData[0:21,0:4]\n",
    "#Y_TrainingData = XY_TrainingData[0:21,4]\n",
    "#\n",
    "#XY_TestData = data[21:,:]\n",
    "#X_TestData = XY_TestData[:,0:4]\n",
    "#Y_TestData = XY_TestData[:,4]\n",
    "\n",
    "print(X_TrainingData)\n",
    "print(\"------------------------\")\n",
    "print(X_TestData)\n",
    "print(\"------------------------\")\n",
    "print(Y_TrainingData)\n",
    "print(\"------------------------\")\n",
    "print(Y_TestData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st eLU, tanh, 4, 18, 18, 9, 9, 1\n",
    "R_square of EntireData\n",
    "0.457788879515\n",
    "R_square of TestData\n",
    "-8.85773593135"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "n_InputUnit = 4\n",
    "n_1stHiddenUnit=18\n",
    "n_2ndHiddenUnit=18\n",
    "n_3rdHiddenUnit=9\n",
    "n_4thHiddenUnit=9\n",
    "n_OutputUnit = 1\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([n_InputUnit, n_1stHiddenUnit],stddev=0.01))\n",
    "W2 = tf.Variable(tf.random_normal([n_1stHiddenUnit, n_2ndHiddenUnit],stddev=0.01))\n",
    "W3 = tf.Variable(tf.random_normal([n_2ndHiddenUnit, n_3rdHiddenUnit],stddev=0.01))\n",
    "W4 = tf.Variable(tf.random_normal([n_3rdHiddenUnit, n_4thHiddenUnit],stddev=0.01))\n",
    "W5 = tf.Variable(tf.random_normal([n_4thHiddenUnit, n_OutputUnit],stddev=0.01))\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([n_1stHiddenUnit], stddev=0.01))\n",
    "b2 = tf.Variable(tf.random_normal([n_2ndHiddenUnit], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([n_3rdHiddenUnit], stddev=0.01))\n",
    "b4 = tf.Variable(tf.random_normal([n_4thHiddenUnit], stddev=0.01))\n",
    "b5 = tf.Variable(tf.random_normal([n_OutputUnit], stddev=0.01))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 4]) # tensorflow의 placeholder라는 변수를 선언\n",
    "Y = tf.placeholder(tf.float32, [None,])\n",
    "\n",
    "L1 = tf.nn.elu(tf.matmul(X, W1) + b1)\n",
    "L2 = tf.nn.elu(tf.matmul(L1, W2) + b2)\n",
    "L3 = tf.nn.elu(tf.matmul(L2, W3) + b3)\n",
    "L4 = tf.nn.elu(tf.matmul(L3, W4) + b4)\n",
    "Hypothesis = tf.nn.tanh(tf.matmul(L4, W5) + b5)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(Y-Hypothesis))\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=0.5).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train NN & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0.0591896\n",
      "10 1000 0.0980585\n",
      "11 2000 0.0964576\n",
      "5 3000 0.0933272\n",
      "4 4000 0.0976842\n",
      "3 5000 0.101685\n",
      "17 6000 0.100689\n",
      "9 7000 0.093919\n",
      "3 8000 0.104772\n",
      "19 9000 0.105406\n",
      "7 10000 0.104006\n",
      "8 11000 0.107245\n",
      "19 12000 0.105855\n",
      "3 13000 0.107375\n",
      "0 14000 0.108926\n",
      "15 15000 0.102045\n",
      "12 16000 0.11168\n",
      "15 17000 0.102177\n",
      "1 18000 0.108222\n",
      "0 19000 0.105598\n",
      "0 20000 0.108124\n",
      "3 21000 0.111011\n",
      "14 22000 0.111952\n",
      "2 23000 0.108096\n",
      "2 24000 0.106436\n",
      "14 25000 0.107102\n",
      "16 26000 0.110736\n",
      "10 27000 0.106293\n",
      "3 28000 0.106177\n",
      "1 29000 0.113394\n",
      "7 30000 0.109856\n",
      "0 31000 0.108528\n",
      "11 32000 0.112121\n",
      "0 33000 0.10653\n",
      "15 34000 0.111205\n",
      "0 35000 0.11291\n",
      "8 36000 0.104547\n",
      "3 37000 0.107129\n",
      "17 38000 0.114612\n",
      "2 39000 0.112383\n",
      "11 40000 0.104235\n",
      "3 41000 0.114119\n",
      "8 42000 0.115389\n",
      "14 43000 0.112666\n",
      "13 44000 0.112508\n",
      "13 45000 0.115128\n",
      "19 46000 0.115\n",
      "18 47000 0.114319\n",
      "1 48000 0.114413\n",
      "13 49000 0.110813\n",
      "19 50000 0.110752\n",
      "3 51000 0.113449\n",
      "14 52000 0.115576\n",
      "1 53000 0.113428\n",
      "9 54000 0.11659\n",
      "18 55000 0.117161\n",
      "11 56000 0.115485\n",
      "7 57000 0.110828\n",
      "11 58000 0.114437\n",
      "6 59000 0.113681\n",
      "5 60000 0.110285\n",
      "17 61000 0.117757\n",
      "17 62000 0.114442\n",
      "15 63000 0.113498\n",
      "7 64000 0.114419\n",
      "17 65000 0.110463\n",
      "1 66000 0.114496\n",
      "15 67000 0.115819\n",
      "12 68000 0.120405\n",
      "3 69000 0.107334\n",
      "3 70000 0.122273\n",
      "1 71000 0.115955\n",
      "6 72000 0.124917\n",
      "2 73000 0.117943\n",
      "6 74000 0.115493\n",
      "7 75000 0.115849\n",
      "14 76000 0.11471\n",
      "1 77000 0.119528\n",
      "8 78000 0.114383\n",
      "17 79000 0.11542\n",
      "14 80000 0.11613\n",
      "2 81000 0.115628\n",
      "19 82000 0.114332\n",
      "0 83000 0.112432\n",
      "14 84000 0.114893\n",
      "11 85000 0.112221\n",
      "12 86000 0.109887\n",
      "6 87000 0.118204\n",
      "2 88000 0.11895\n",
      "15 89000 0.116185\n",
      "8 90000 0.114889\n",
      "12 91000 0.110901\n",
      "10 92000 0.118571\n",
      "0 93000 0.114736\n",
      "6 94000 0.121205\n",
      "7 95000 0.114324\n",
      "4 96000 0.123706\n",
      "17 97000 0.118733\n",
      "15 98000 0.116809\n",
      "15 99000 0.110927\n",
      "R_square of EntireData\n",
      "0.457788879515\n",
      "R_square of TestData\n",
      "-8.85773593135\n",
      "Result of predicting TrainingData\n",
      "[[-0.21640602]\n",
      " [-0.4721272 ]\n",
      " [-0.45821205]\n",
      " [-0.11187781]\n",
      " [-0.11116005]\n",
      " [-0.1780095 ]\n",
      " [-0.19546431]\n",
      " [ 0.00310483]\n",
      " [-0.14213903]\n",
      " [ 0.0150894 ]\n",
      " [ 0.04733124]\n",
      " [ 0.5386315 ]\n",
      " [-0.13204759]\n",
      " [ 0.19215593]\n",
      " [-0.00639802]\n",
      " [ 0.09348409]\n",
      " [-0.15711351]\n",
      " [ 0.30362472]\n",
      " [ 0.04353847]\n",
      " [ 0.33661303]]\n",
      "Result of predicting TestData\n",
      "[[-0.05170492]\n",
      " [ 0.03334094]\n",
      " [-0.55904508]\n",
      " [ 0.01621964]\n",
      " [-0.10208017]]\n",
      "Y_NormalizedData\n",
      "[-0.21844449 -0.47152439 -0.45735005 -0.1123416  -0.11245536 -0.18036006\n",
      " -0.19692817  0.00145492 -0.14520267  0.01178692  0.04523337  0.52847561\n",
      " -0.13421128  0.19149351 -0.00787756  0.09143864 -0.16016158  0.30505231\n",
      "  0.04222738  0.33060721 -0.08104142  0.20294599  0.18485121  0.07951933\n",
      "  0.2628122 ]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(100000):\n",
    "        SGDorder = Sequence[step % 20] # training을 0번부터 20번까지 순차적으로 돌린다.\n",
    "        session.run(train, feed_dict ={X: X_TrainingData[SGDorder: SGDorder + 1,:], Y: Y_TrainingData[SGDorder: SGDorder + 1]})\n",
    "        #session.run(train, feed_dict ={X: X_TrainingData, Y: Y_TrainingData})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print (SGDorder,step, session.run(cost, feed_dict = {X: X_TrainingData, Y: Y_TrainingData}))\n",
    "            #print (W1)\n",
    "            #print (b1)\n",
    "        if step % 20 == 0:\n",
    "            random.shuffle(Sequence)\n",
    "            \n",
    "    Predict_to_TestData = session.run(Hypothesis, feed_dict={X : X_TestData})\n",
    "    Predict_to_TrainingData = session.run(Hypothesis, feed_dict={X : X_TrainingData})\n",
    "    Predict_to_EntireData = session.run(Hypothesis, feed_dict = {X : X_NormalizedData})\n",
    "    \n",
    "    print(\"R_square of EntireData\")\n",
    "    print(r2_score(Y_NormalizedData, Predict_to_EntireData))\n",
    "    print(\"R_square of TestData\")\n",
    "    print(r2_score(Y_TestData, Predict_to_TestData))\n",
    "    print(\"Result of predicting TrainingData\")\n",
    "    print(Predict_to_TrainingData)\n",
    "    print(\"Result of predicting TestData\")\n",
    "    print(Predict_to_TestData)\n",
    "    print(\"Y_NormalizedData\")\n",
    "    print(Y_NormalizedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd eLU, tanh, 4, 50, 50, 50, 50, 1\n",
    "R_square of EntireData\n",
    "0.643568734249\n",
    "R_square of TestData\n",
    "-5.43605667929"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "n_InputUnit = 4\n",
    "n_1stHiddenUnit=50\n",
    "n_2ndHiddenUnit=50\n",
    "n_3rdHiddenUnit=50\n",
    "n_4thHiddenUnit=50\n",
    "n_OutputUnit = 1\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([n_InputUnit, n_1stHiddenUnit],stddev=0.01))\n",
    "W2 = tf.Variable(tf.random_normal([n_1stHiddenUnit, n_2ndHiddenUnit],stddev=0.01))\n",
    "W3 = tf.Variable(tf.random_normal([n_2ndHiddenUnit, n_3rdHiddenUnit],stddev=0.01))\n",
    "W4 = tf.Variable(tf.random_normal([n_3rdHiddenUnit, n_4thHiddenUnit],stddev=0.01))\n",
    "W5 = tf.Variable(tf.random_normal([n_4thHiddenUnit, n_OutputUnit],stddev=0.01))\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([n_1stHiddenUnit], stddev=0.01))\n",
    "b2 = tf.Variable(tf.random_normal([n_2ndHiddenUnit], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([n_3rdHiddenUnit], stddev=0.01))\n",
    "b4 = tf.Variable(tf.random_normal([n_4thHiddenUnit], stddev=0.01))\n",
    "b5 = tf.Variable(tf.random_normal([n_OutputUnit], stddev=0.01))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 4]) # tensorflow의 placeholder라는 변수를 선언\n",
    "Y = tf.placeholder(tf.float32, [None,])\n",
    "\n",
    "L1 = tf.nn.elu(tf.matmul(X, W1) + b1)\n",
    "L2 = tf.nn.elu(tf.matmul(L1, W2) + b2)\n",
    "L3 = tf.nn.elu(tf.matmul(L2, W3) + b3)\n",
    "L4 = tf.nn.elu(tf.matmul(L3, W4) + b4)\n",
    "Hypothesis = tf.nn.tanh(tf.matmul(L4, W5) + b5)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(Y-Hypothesis))\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=0.5).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train NN & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 0 0.0595077\n",
      "11 1000 0.09946\n",
      "1 2000 0.0877738\n",
      "17 3000 0.0936581\n",
      "4 4000 0.0909709\n",
      "6 5000 0.0900273\n",
      "18 6000 0.0945143\n",
      "7 7000 0.101718\n",
      "0 8000 0.101703\n",
      "11 9000 0.123767\n",
      "2 10000 0.109589\n",
      "18 11000 0.103871\n",
      "19 12000 0.112006\n",
      "1 13000 0.106627\n",
      "6 14000 0.114356\n",
      "9 15000 0.117015\n",
      "17 16000 0.116913\n",
      "12 17000 0.110534\n",
      "0 18000 0.124202\n",
      "16 19000 0.109804\n",
      "18 20000 0.0977262\n",
      "8 21000 0.108214\n",
      "4 22000 0.115356\n",
      "12 23000 0.113756\n",
      "9 24000 0.112429\n",
      "10 25000 0.112796\n",
      "8 26000 0.113025\n",
      "1 27000 0.115756\n",
      "6 28000 0.11383\n",
      "6 29000 0.114028\n",
      "5 30000 0.115787\n",
      "6 31000 0.125865\n",
      "1 32000 0.127024\n",
      "19 33000 0.117203\n",
      "14 34000 0.114264\n",
      "17 35000 0.118072\n",
      "14 36000 0.11633\n",
      "18 37000 0.134329\n",
      "12 38000 0.126759\n",
      "8 39000 0.125134\n",
      "10 40000 0.112289\n",
      "19 41000 0.112127\n",
      "7 42000 0.113849\n",
      "7 43000 0.135997\n",
      "4 44000 0.11409\n",
      "7 45000 0.123144\n",
      "10 46000 0.111609\n",
      "17 47000 0.11433\n",
      "15 48000 0.115294\n",
      "0 49000 0.116343\n",
      "12 50000 0.104387\n",
      "11 51000 0.115065\n",
      "6 52000 0.115178\n",
      "9 53000 0.116986\n",
      "3 54000 0.116174\n",
      "2 55000 0.114511\n",
      "6 56000 0.11295\n",
      "7 57000 0.114964\n",
      "7 58000 0.116358\n",
      "5 59000 0.114764\n",
      "13 60000 0.117751\n",
      "1 61000 0.11614\n",
      "14 62000 0.117697\n",
      "9 63000 0.115808\n",
      "0 64000 0.111715\n",
      "17 65000 0.114613\n",
      "12 66000 0.119912\n",
      "17 67000 0.113711\n",
      "14 68000 0.115121\n",
      "19 69000 0.114728\n",
      "2 70000 0.115538\n",
      "13 71000 0.114046\n",
      "17 72000 0.115231\n",
      "18 73000 0.12171\n",
      "0 74000 0.116625\n",
      "0 75000 0.11521\n",
      "1 76000 0.114289\n",
      "7 77000 0.11457\n",
      "2 78000 0.116477\n",
      "16 79000 0.115089\n",
      "16 80000 0.113168\n",
      "17 81000 0.115044\n",
      "1 82000 0.114826\n",
      "1 83000 0.121942\n",
      "17 84000 0.114816\n",
      "1 85000 0.113722\n",
      "8 86000 0.115834\n",
      "19 87000 0.115236\n",
      "9 88000 0.113503\n",
      "6 89000 0.114676\n",
      "6 90000 0.115317\n",
      "9 91000 0.116348\n",
      "3 92000 0.115413\n",
      "6 93000 0.112511\n",
      "11 94000 0.116517\n",
      "2 95000 0.111595\n",
      "7 96000 0.110946\n",
      "3 97000 0.115189\n",
      "12 98000 0.116079\n",
      "13 99000 0.11467\n",
      "R_square of EntireData\n",
      "0.643568734249\n",
      "R_square of TestData\n",
      "-5.43605667929\n",
      "Result of predicting TrainingData\n",
      "[[-0.23107456]\n",
      " [-0.48693585]\n",
      " [-0.47327873]\n",
      " [-0.12763743]\n",
      " [-0.10107423]\n",
      " [-0.18304668]\n",
      " [-0.18508454]\n",
      " [ 0.01340145]\n",
      " [-0.13081917]\n",
      " [ 0.01563122]\n",
      " [ 0.05376654]\n",
      " [ 0.54479289]\n",
      " [-0.13328578]\n",
      " [ 0.19710602]\n",
      " [ 0.01404485]\n",
      " [ 0.09274496]\n",
      " [-0.13098171]\n",
      " [ 0.31012827]\n",
      " [ 0.0443861 ]\n",
      " [ 0.34032235]]\n",
      "Result of predicting TestData\n",
      "[[-0.13172899]\n",
      " [ 0.05596426]\n",
      " [-0.45185924]\n",
      " [-0.10327727]\n",
      " [ 0.17795077]]\n",
      "Y_NormalizedData\n",
      "[-0.21844449 -0.47152439 -0.45735005 -0.1123416  -0.11245536 -0.18036006\n",
      " -0.19692817  0.00145492 -0.14520267  0.01178692  0.04523337  0.52847561\n",
      " -0.13421128  0.19149351 -0.00787756  0.09143864 -0.16016158  0.30505231\n",
      "  0.04222738  0.33060721 -0.08104142  0.20294599  0.18485121  0.07951933\n",
      "  0.2628122 ]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(100000):\n",
    "        SGDorder = Sequence[step % 20] # training을 0번부터 20번까지 순차적으로 돌린다.\n",
    "        session.run(train, feed_dict ={X: X_TrainingData[SGDorder: SGDorder + 1,:], Y: Y_TrainingData[SGDorder: SGDorder + 1]})\n",
    "        #session.run(train, feed_dict ={X: X_TrainingData, Y: Y_TrainingData})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print (SGDorder,step, session.run(cost, feed_dict = {X: X_TrainingData, Y: Y_TrainingData}))\n",
    "            #print (W1)\n",
    "            #print (b1)\n",
    "        if step % 20 == 0:\n",
    "            random.shuffle(Sequence)\n",
    "            \n",
    "    Predict_to_TestData = session.run(Hypothesis, feed_dict={X : X_TestData})\n",
    "    Predict_to_TrainingData = session.run(Hypothesis, feed_dict={X : X_TrainingData})\n",
    "    Predict_to_EntireData = session.run(Hypothesis, feed_dict = {X : X_NormalizedData})\n",
    "    \n",
    "    print(\"R_square of EntireData\")\n",
    "    print(r2_score(Y_NormalizedData, Predict_to_EntireData))\n",
    "    print(\"R_square of TestData\")\n",
    "    print(r2_score(Y_TestData, Predict_to_TestData))\n",
    "    print(\"Result of predicting TrainingData\")\n",
    "    print(Predict_to_TrainingData)\n",
    "    print(\"Result of predicting TestData\")\n",
    "    print(Predict_to_TestData)\n",
    "    print(\"Y_NormalizedData\")\n",
    "    print(Y_NormalizedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3rd eLU, tanh, 4, 10, 10, 10, 1\n",
    "R_square of EntireData\n",
    "0.360907984837\n",
    "R_square of TestData\n",
    "-10.5949482088"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "n_InputUnit = 4\n",
    "n_1stHiddenUnit=10\n",
    "n_2ndHiddenUnit=10\n",
    "n_3rdHiddenUnit=10\n",
    "n_OutputUnit = 1\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([n_InputUnit, n_1stHiddenUnit],stddev=0.01))\n",
    "W2 = tf.Variable(tf.random_normal([n_1stHiddenUnit, n_2ndHiddenUnit],stddev=0.01))\n",
    "W3 = tf.Variable(tf.random_normal([n_2ndHiddenUnit, n_3rdHiddenUnit],stddev=0.01))\n",
    "W4 = tf.Variable(tf.random_normal([n_3rdHiddenUnit, n_OutputUnit],stddev=0.01))\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([n_1stHiddenUnit], stddev=0.01))\n",
    "b2 = tf.Variable(tf.random_normal([n_2ndHiddenUnit], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([n_3rdHiddenUnit], stddev=0.01))\n",
    "b4 = tf.Variable(tf.random_normal([n_OutputUnit], stddev=0.01))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 4]) # tensorflow의 placeholder라는 변수를 선언\n",
    "Y = tf.placeholder(tf.float32, [None,])\n",
    "\n",
    "L1 = tf.nn.elu(tf.matmul(X, W1) + b1)\n",
    "L2 = tf.nn.elu(tf.matmul(L1, W2) + b2)\n",
    "L3 = tf.nn.elu(tf.matmul(L2, W3) + b3)\n",
    "Hypothesis = tf.nn.tanh(tf.matmul(L3, W4) + b4)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(Y-Hypothesis))\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=0.5).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train NN & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 0 0.058422\n",
      "16 1000 0.0997606\n",
      "1 2000 0.094608\n",
      "8 3000 0.0967422\n",
      "15 4000 0.0963633\n",
      "13 5000 0.0987266\n",
      "1 6000 0.0961981\n",
      "18 7000 0.0971074\n",
      "18 8000 0.0974882\n",
      "3 9000 0.0993656\n",
      "18 10000 0.101455\n",
      "11 11000 0.103075\n",
      "15 12000 0.102778\n",
      "10 13000 0.103675\n",
      "5 14000 0.10346\n",
      "10 15000 0.104664\n",
      "10 16000 0.105998\n",
      "7 17000 0.103855\n",
      "8 18000 0.105087\n",
      "6 19000 0.105836\n",
      "17 20000 0.10622\n",
      "15 21000 0.107037\n",
      "14 22000 0.106481\n",
      "14 23000 0.105749\n",
      "11 24000 0.10486\n",
      "4 25000 0.107782\n",
      "7 26000 0.10366\n",
      "17 27000 0.105192\n",
      "18 28000 0.107147\n",
      "5 29000 0.10502\n",
      "14 30000 0.105536\n",
      "9 31000 0.104026\n",
      "3 32000 0.104841\n",
      "3 33000 0.106717\n",
      "5 34000 0.110441\n",
      "13 35000 0.106308\n",
      "10 36000 0.108114\n",
      "8 37000 0.108384\n",
      "8 38000 0.101711\n",
      "5 39000 0.105369\n",
      "15 40000 0.107707\n",
      "17 41000 0.113406\n",
      "5 42000 0.11125\n",
      "13 43000 0.106797\n",
      "7 44000 0.106032\n",
      "19 45000 0.113299\n",
      "7 46000 0.111743\n",
      "19 47000 0.110955\n",
      "10 48000 0.114773\n",
      "16 49000 0.112712\n",
      "18 50000 0.107372\n",
      "16 51000 0.112951\n",
      "1 52000 0.115978\n",
      "9 53000 0.110534\n",
      "8 54000 0.111508\n",
      "8 55000 0.112613\n",
      "15 56000 0.115948\n",
      "12 57000 0.111677\n",
      "13 58000 0.112684\n",
      "12 59000 0.112902\n",
      "16 60000 0.113627\n",
      "14 61000 0.115748\n",
      "5 62000 0.110534\n",
      "16 63000 0.117105\n",
      "8 64000 0.113754\n",
      "5 65000 0.115874\n",
      "11 66000 0.116651\n",
      "10 67000 0.115033\n",
      "4 68000 0.113896\n",
      "1 69000 0.11584\n",
      "13 70000 0.117654\n",
      "5 71000 0.113761\n",
      "11 72000 0.114885\n",
      "7 73000 0.113255\n",
      "13 74000 0.113234\n",
      "15 75000 0.109348\n",
      "8 76000 0.117402\n",
      "7 77000 0.109023\n",
      "1 78000 0.111944\n",
      "11 79000 0.114801\n",
      "0 80000 0.115077\n",
      "13 81000 0.117232\n",
      "2 82000 0.11582\n",
      "3 83000 0.114193\n",
      "11 84000 0.117537\n",
      "15 85000 0.111586\n",
      "13 86000 0.112294\n",
      "9 87000 0.11567\n",
      "11 88000 0.111867\n",
      "1 89000 0.114283\n",
      "13 90000 0.115521\n",
      "7 91000 0.116557\n",
      "8 92000 0.113267\n",
      "18 93000 0.115369\n",
      "5 94000 0.112802\n",
      "1 95000 0.115185\n",
      "12 96000 0.112417\n",
      "15 97000 0.10927\n",
      "8 98000 0.115404\n",
      "2 99000 0.112774\n",
      "R_square of EntireData\n",
      "0.360907984837\n",
      "R_square of TestData\n",
      "-10.5949482088\n",
      "Result of predicting TrainingData\n",
      "[[-0.21164453]\n",
      " [-0.46380118]\n",
      " [-0.4565919 ]\n",
      " [-0.10936336]\n",
      " [-0.11041891]\n",
      " [-0.18252096]\n",
      " [-0.19323364]\n",
      " [ 0.00127596]\n",
      " [-0.14693058]\n",
      " [ 0.01182006]\n",
      " [ 0.04373007]\n",
      " [ 0.49862999]\n",
      " [-0.12942851]\n",
      " [ 0.1802434 ]\n",
      " [-0.01040808]\n",
      " [ 0.0769563 ]\n",
      " [-0.16202669]\n",
      " [ 0.29363656]\n",
      " [ 0.0394395 ]\n",
      " [ 0.30903023]]\n",
      "Result of predicting TestData\n",
      "[[-0.0536935 ]\n",
      " [-0.09872713]\n",
      " [-0.48388621]\n",
      " [-0.0491752 ]\n",
      " [-0.2771394 ]]\n",
      "Y_NormalizedData\n",
      "[-0.21844449 -0.47152439 -0.45735005 -0.1123416  -0.11245536 -0.18036006\n",
      " -0.19692817  0.00145492 -0.14520267  0.01178692  0.04523337  0.52847561\n",
      " -0.13421128  0.19149351 -0.00787756  0.09143864 -0.16016158  0.30505231\n",
      "  0.04222738  0.33060721 -0.08104142  0.20294599  0.18485121  0.07951933\n",
      "  0.2628122 ]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(100000):\n",
    "        SGDorder = Sequence[step % 20] # training을 0번부터 20번까지 순차적으로 돌린다.\n",
    "        session.run(train, feed_dict ={X: X_TrainingData[SGDorder: SGDorder + 1,:], Y: Y_TrainingData[SGDorder: SGDorder + 1]})\n",
    "        #session.run(train, feed_dict ={X: X_TrainingData, Y: Y_TrainingData})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print (SGDorder,step, session.run(cost, feed_dict = {X: X_TrainingData, Y: Y_TrainingData}))\n",
    "            #print (W1)\n",
    "            #print (b1)\n",
    "        if step % 20 == 0:\n",
    "            random.shuffle(Sequence)\n",
    "            \n",
    "    Predict_to_TestData = session.run(Hypothesis, feed_dict={X : X_TestData})\n",
    "    Predict_to_TrainingData = session.run(Hypothesis, feed_dict={X : X_TrainingData})\n",
    "    Predict_to_EntireData = session.run(Hypothesis, feed_dict = {X : X_NormalizedData})\n",
    "    \n",
    "    print(\"R_square of EntireData\")\n",
    "    print(r2_score(Y_NormalizedData, Predict_to_EntireData))\n",
    "    print(\"R_square of TestData\")\n",
    "    print(r2_score(Y_TestData, Predict_to_TestData))\n",
    "    print(\"Result of predicting TrainingData\")\n",
    "    print(Predict_to_TrainingData)\n",
    "    print(\"Result of predicting TestData\")\n",
    "    print(Predict_to_TestData)\n",
    "    print(\"Y_NormalizedData\")\n",
    "    print(Y_NormalizedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4th eLU, tanh, 4, 50, 30, 10, 1\n",
    "R_square of EntireData\n",
    "0.672840700519\n",
    "R_square of TestData\n",
    "-4.92750092321"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "n_InputUnit = 4\n",
    "n_1stHiddenUnit=50\n",
    "n_2ndHiddenUnit=30\n",
    "n_3rdHiddenUnit=10\n",
    "n_OutputUnit = 1\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([n_InputUnit, n_1stHiddenUnit],stddev=0.01))\n",
    "W2 = tf.Variable(tf.random_normal([n_1stHiddenUnit, n_2ndHiddenUnit],stddev=0.01))\n",
    "W3 = tf.Variable(tf.random_normal([n_2ndHiddenUnit, n_3rdHiddenUnit],stddev=0.01))\n",
    "W4 = tf.Variable(tf.random_normal([n_3rdHiddenUnit, n_OutputUnit],stddev=0.01))\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([n_1stHiddenUnit], stddev=0.01))\n",
    "b2 = tf.Variable(tf.random_normal([n_2ndHiddenUnit], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([n_3rdHiddenUnit], stddev=0.01))\n",
    "b4 = tf.Variable(tf.random_normal([n_OutputUnit], stddev=0.01))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 4]) # tensorflow의 placeholder라는 변수를 선언\n",
    "Y = tf.placeholder(tf.float32, [None,])\n",
    "\n",
    "L1 = tf.nn.elu(tf.matmul(X, W1) + b1)\n",
    "L2 = tf.nn.elu(tf.matmul(L1, W2) + b2)\n",
    "L3 = tf.nn.elu(tf.matmul(L2, W3) + b3)\n",
    "Hypothesis = tf.nn.tanh(tf.matmul(L3, W4) + b4)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(Y-Hypothesis))\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=0.5).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train NN & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 0 0.0596981\n",
      "4 1000 0.0897008\n",
      "11 2000 0.0889376\n",
      "5 3000 0.0938809\n",
      "7 4000 0.0967513\n",
      "0 5000 0.104859\n",
      "18 6000 0.102976\n",
      "0 7000 0.105254\n",
      "17 8000 0.0989922\n",
      "17 9000 0.109437\n",
      "12 10000 0.110436\n",
      "1 11000 0.109223\n",
      "5 12000 0.103502\n",
      "0 13000 0.107501\n",
      "13 14000 0.123156\n",
      "5 15000 0.120605\n",
      "8 16000 0.120888\n",
      "3 17000 0.107334\n",
      "18 18000 0.109463\n",
      "2 19000 0.110523\n",
      "16 20000 0.0940826\n",
      "2 21000 0.117304\n",
      "13 22000 0.104647\n",
      "19 23000 0.109144\n",
      "2 24000 0.112648\n",
      "13 25000 0.126408\n",
      "12 26000 0.117465\n",
      "2 27000 0.121186\n",
      "6 28000 0.111618\n",
      "0 29000 0.110644\n",
      "0 30000 0.115826\n",
      "8 31000 0.109355\n",
      "5 32000 0.112198\n",
      "2 33000 0.116038\n",
      "5 34000 0.117024\n",
      "12 35000 0.109387\n",
      "3 36000 0.120815\n",
      "0 37000 0.107375\n",
      "17 38000 0.11584\n",
      "14 39000 0.112182\n",
      "17 40000 0.114894\n",
      "15 41000 0.112776\n",
      "5 42000 0.114154\n",
      "10 43000 0.109137\n",
      "3 44000 0.113969\n",
      "3 45000 0.114935\n",
      "6 46000 0.115283\n",
      "14 47000 0.116135\n",
      "4 48000 0.120806\n",
      "5 49000 0.116735\n",
      "10 50000 0.114097\n",
      "16 51000 0.116238\n",
      "7 52000 0.114451\n",
      "2 53000 0.115835\n",
      "16 54000 0.118529\n",
      "11 55000 0.109501\n",
      "4 56000 0.117243\n",
      "2 57000 0.114669\n",
      "15 58000 0.11306\n",
      "6 59000 0.114668\n",
      "2 60000 0.115832\n",
      "14 61000 0.115165\n",
      "15 62000 0.107132\n",
      "0 63000 0.114742\n",
      "5 64000 0.113211\n",
      "14 65000 0.101642\n",
      "5 66000 0.11521\n",
      "13 67000 0.11611\n",
      "11 68000 0.119559\n",
      "15 69000 0.116183\n",
      "1 70000 0.112708\n",
      "12 71000 0.113633\n",
      "13 72000 0.118062\n",
      "8 73000 0.113761\n",
      "11 74000 0.115592\n",
      "11 75000 0.113599\n",
      "18 76000 0.115867\n",
      "9 77000 0.115311\n",
      "3 78000 0.115402\n",
      "8 79000 0.115178\n",
      "10 80000 0.115357\n",
      "6 81000 0.118892\n",
      "8 82000 0.114651\n",
      "14 83000 0.114391\n",
      "9 84000 0.115986\n",
      "10 85000 0.124197\n",
      "8 86000 0.113744\n",
      "13 87000 0.11752\n",
      "5 88000 0.11552\n",
      "18 89000 0.115279\n",
      "10 90000 0.116129\n",
      "1 91000 0.117016\n",
      "2 92000 0.116316\n",
      "18 93000 0.113385\n",
      "5 94000 0.117503\n",
      "8 95000 0.116536\n",
      "6 96000 0.113315\n",
      "5 97000 0.109642\n",
      "2 98000 0.120484\n",
      "13 99000 0.113568\n",
      "R_square of EntireData\n",
      "0.672840700519\n",
      "R_square of TestData\n",
      "-4.92750092321\n",
      "Result of predicting TrainingData\n",
      "[[-0.21909085]\n",
      " [-0.46608952]\n",
      " [-0.44987369]\n",
      " [-0.11051637]\n",
      " [-0.11159462]\n",
      " [-0.1700034 ]\n",
      " [-0.1835416 ]\n",
      " [ 0.00764418]\n",
      " [-0.13971151]\n",
      " [ 0.01380396]\n",
      " [ 0.05322716]\n",
      " [ 0.51733696]\n",
      " [-0.12966636]\n",
      " [ 0.1934845 ]\n",
      " [-0.0073089 ]\n",
      " [ 0.10098837]\n",
      " [-0.1891084 ]\n",
      " [ 0.30167714]\n",
      " [ 0.0386852 ]\n",
      " [ 0.33261892]]\n",
      "Result of predicting TestData\n",
      "[[-0.06852978]\n",
      " [ 0.05173143]\n",
      " [-0.43711361]\n",
      " [ 0.03172613]\n",
      " [ 0.11828014]]\n",
      "Y_NormalizedData\n",
      "[-0.21844449 -0.47152439 -0.45735005 -0.1123416  -0.11245536 -0.18036006\n",
      " -0.19692817  0.00145492 -0.14520267  0.01178692  0.04523337  0.52847561\n",
      " -0.13421128  0.19149351 -0.00787756  0.09143864 -0.16016158  0.30505231\n",
      "  0.04222738  0.33060721 -0.08104142  0.20294599  0.18485121  0.07951933\n",
      "  0.2628122 ]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(100000):\n",
    "        SGDorder = Sequence[step % 20] # training을 0번부터 20번까지 순차적으로 돌린다.\n",
    "        session.run(train, feed_dict ={X: X_TrainingData[SGDorder: SGDorder + 1,:], Y: Y_TrainingData[SGDorder: SGDorder + 1]})\n",
    "        #session.run(train, feed_dict ={X: X_TrainingData, Y: Y_TrainingData})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print (SGDorder,step, session.run(cost, feed_dict = {X: X_TrainingData, Y: Y_TrainingData}))\n",
    "            #print (W1)\n",
    "            #print (b1)\n",
    "        if step % 20 == 0:\n",
    "            random.shuffle(Sequence)\n",
    "            \n",
    "    Predict_to_TestData = session.run(Hypothesis, feed_dict={X : X_TestData})\n",
    "    Predict_to_TrainingData = session.run(Hypothesis, feed_dict={X : X_TrainingData})\n",
    "    Predict_to_EntireData = session.run(Hypothesis, feed_dict = {X : X_NormalizedData})\n",
    "    \n",
    "    print(\"R_square of EntireData\")\n",
    "    print(r2_score(Y_NormalizedData, Predict_to_EntireData))\n",
    "    print(\"R_square of TestData\")\n",
    "    print(r2_score(Y_TestData, Predict_to_TestData))\n",
    "    print(\"Result of predicting TrainingData\")\n",
    "    print(Predict_to_TrainingData)\n",
    "    print(\"Result of predicting TestData\")\n",
    "    print(Predict_to_TestData)\n",
    "    print(\"Y_NormalizedData\")\n",
    "    print(Y_NormalizedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5th ReLU, tanh, 4, 50, 50, 50, 1\n",
    "R_square of EntireData\n",
    "0.642259338803\n",
    "R_square of TestData\n",
    "-5.50543815376"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "n_InputUnit = 4\n",
    "n_1stHiddenUnit=50\n",
    "n_2ndHiddenUnit=50\n",
    "n_3rdHiddenUnit=50\n",
    "n_OutputUnit = 1\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([n_InputUnit, n_1stHiddenUnit],stddev=0.01))\n",
    "W2 = tf.Variable(tf.random_normal([n_1stHiddenUnit, n_2ndHiddenUnit],stddev=0.01))\n",
    "W3 = tf.Variable(tf.random_normal([n_2ndHiddenUnit, n_3rdHiddenUnit],stddev=0.01))\n",
    "W4 = tf.Variable(tf.random_normal([n_3rdHiddenUnit, n_OutputUnit],stddev=0.01))\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([n_1stHiddenUnit], stddev=0.01))\n",
    "b2 = tf.Variable(tf.random_normal([n_2ndHiddenUnit], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([n_3rdHiddenUnit], stddev=0.01))\n",
    "b4 = tf.Variable(tf.random_normal([n_OutputUnit], stddev=0.01))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 4]) # tensorflow의 placeholder라는 변수를 선언\n",
    "Y = tf.placeholder(tf.float32, [None,])\n",
    "\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "L3 = tf.nn.relu(tf.matmul(L2, W3) + b3)\n",
    "Hypothesis = tf.nn.tanh(tf.matmul(L3, W4) + b4)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(Y-Hypothesis))\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=0.5).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train NN & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 0 0.0591693\n",
      "15 1000 0.0975256\n",
      "10 2000 0.112358\n",
      "13 3000 0.115108\n",
      "2 4000 0.113996\n",
      "6 5000 0.113809\n",
      "15 6000 0.117102\n",
      "2 7000 0.115923\n",
      "6 8000 0.115322\n",
      "8 9000 0.115124\n",
      "0 10000 0.11466\n",
      "6 11000 0.114477\n",
      "4 12000 0.119248\n",
      "0 13000 0.120742\n",
      "9 14000 0.115877\n",
      "9 15000 0.114252\n",
      "3 16000 0.115507\n",
      "4 17000 0.118868\n",
      "19 18000 0.116578\n",
      "18 19000 0.119748\n",
      "5 20000 0.115859\n",
      "10 21000 0.114764\n",
      "17 22000 0.112438\n",
      "11 23000 0.118114\n",
      "10 24000 0.120242\n",
      "16 25000 0.109328\n",
      "5 26000 0.114462\n",
      "16 27000 0.137628\n",
      "14 28000 0.113516\n",
      "14 29000 0.115665\n",
      "18 30000 0.112131\n",
      "16 31000 0.11147\n",
      "8 32000 0.114249\n",
      "9 33000 0.114376\n",
      "6 34000 0.115059\n",
      "19 35000 0.115385\n",
      "10 36000 0.113245\n",
      "16 37000 0.113158\n",
      "8 38000 0.112646\n",
      "5 39000 0.114132\n",
      "1 40000 0.11559\n",
      "8 41000 0.112814\n",
      "9 42000 0.116471\n",
      "10 43000 0.115354\n",
      "1 44000 0.11462\n",
      "10 45000 0.115058\n",
      "5 46000 0.11491\n",
      "11 47000 0.114842\n",
      "10 48000 0.117516\n",
      "7 49000 0.113884\n",
      "5 50000 0.115292\n",
      "0 51000 0.115428\n",
      "11 52000 0.116388\n",
      "19 53000 0.114227\n",
      "3 54000 0.11495\n",
      "13 55000 0.113052\n",
      "4 56000 0.116101\n",
      "9 57000 0.115329\n",
      "8 58000 0.115326\n",
      "7 59000 0.11528\n",
      "18 60000 0.11653\n",
      "18 61000 0.114857\n",
      "4 62000 0.115017\n",
      "19 63000 0.114536\n",
      "9 64000 0.118223\n",
      "0 65000 0.115167\n",
      "14 66000 0.11548\n",
      "14 67000 0.11047\n",
      "3 68000 0.111728\n",
      "14 69000 0.113763\n",
      "19 70000 0.115413\n",
      "12 71000 0.114712\n",
      "19 72000 0.115016\n",
      "8 73000 0.115456\n",
      "19 74000 0.113373\n",
      "2 75000 0.112503\n",
      "7 76000 0.116531\n",
      "9 77000 0.110424\n",
      "11 78000 0.114582\n",
      "4 79000 0.114486\n",
      "16 80000 0.114845\n",
      "9 81000 0.114946\n",
      "17 82000 0.116898\n",
      "18 83000 0.115469\n",
      "7 84000 0.115891\n",
      "13 85000 0.115514\n",
      "6 86000 0.11536\n",
      "14 87000 0.114553\n",
      "6 88000 0.114813\n",
      "2 89000 0.115862\n",
      "8 90000 0.117227\n",
      "16 91000 0.114512\n",
      "4 92000 0.116073\n",
      "5 93000 0.119845\n",
      "14 94000 0.114907\n",
      "0 95000 0.115669\n",
      "18 96000 0.114203\n",
      "19 97000 0.115899\n",
      "14 98000 0.114797\n",
      "8 99000 0.115896\n",
      "R_square of EntireData\n",
      "0.642259338803\n",
      "R_square of TestData\n",
      "-5.50543815376\n",
      "Result of predicting TrainingData\n",
      "[[-0.21700734]\n",
      " [-0.46921244]\n",
      " [-0.45546365]\n",
      " [-0.11148869]\n",
      " [-0.11148688]\n",
      " [-0.17820711]\n",
      " [-0.19613956]\n",
      " [ 0.00065907]\n",
      " [-0.14312997]\n",
      " [ 0.0122729 ]\n",
      " [ 0.0453693 ]\n",
      " [ 0.52844691]\n",
      " [-0.13292807]\n",
      " [ 0.19187082]\n",
      " [-0.00735925]\n",
      " [ 0.09145329]\n",
      " [-0.15896344]\n",
      " [ 0.3053191 ]\n",
      " [ 0.04275519]\n",
      " [ 0.33096865]]\n",
      "Result of predicting TestData\n",
      "[[-0.08813953]\n",
      " [ 0.01748955]\n",
      " [-0.43765005]\n",
      " [-0.03888638]\n",
      " [ 0.06460626]]\n",
      "Y_NormalizedData\n",
      "[-0.21844449 -0.47152439 -0.45735005 -0.1123416  -0.11245536 -0.18036006\n",
      " -0.19692817  0.00145492 -0.14520267  0.01178692  0.04523337  0.52847561\n",
      " -0.13421128  0.19149351 -0.00787756  0.09143864 -0.16016158  0.30505231\n",
      "  0.04222738  0.33060721 -0.08104142  0.20294599  0.18485121  0.07951933\n",
      "  0.2628122 ]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(100000):\n",
    "        SGDorder = Sequence[step % 20] # training을 0번부터 20번까지 순차적으로 돌린다.\n",
    "        session.run(train, feed_dict ={X: X_TrainingData[SGDorder: SGDorder + 1,:], Y: Y_TrainingData[SGDorder: SGDorder + 1]})\n",
    "        #session.run(train, feed_dict ={X: X_TrainingData, Y: Y_TrainingData})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print (SGDorder,step, session.run(cost, feed_dict = {X: X_TrainingData, Y: Y_TrainingData}))\n",
    "            #print (W1)\n",
    "            #print (b1)\n",
    "        if step % 20 == 0:\n",
    "            random.shuffle(Sequence)\n",
    "            \n",
    "    Predict_to_TestData = session.run(Hypothesis, feed_dict={X : X_TestData})\n",
    "    Predict_to_TrainingData = session.run(Hypothesis, feed_dict={X : X_TrainingData})\n",
    "    Predict_to_EntireData = session.run(Hypothesis, feed_dict = {X : X_NormalizedData})\n",
    "    \n",
    "    print(\"R_square of EntireData\")\n",
    "    print(r2_score(Y_NormalizedData, Predict_to_EntireData))\n",
    "    print(\"R_square of TestData\")\n",
    "    print(r2_score(Y_TestData, Predict_to_TestData))\n",
    "    print(\"Result of predicting TrainingData\")\n",
    "    print(Predict_to_TrainingData)\n",
    "    print(\"Result of predicting TestData\")\n",
    "    print(Predict_to_TestData)\n",
    "    print(\"Y_NormalizedData\")\n",
    "    print(Y_NormalizedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6th eLU, tanh, 4, 50, 40, 30, 20, 1\n",
    "R_square of EntireData\n",
    "0.802634340865\n",
    "R_square of TestData\n",
    "-2.54453531064"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "n_InputUnit = 4\n",
    "n_1stHiddenUnit=50\n",
    "n_2ndHiddenUnit=40\n",
    "n_3rdHiddenUnit=30\n",
    "n_4thHiddenUnit=20\n",
    "n_OutputUnit = 1\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([n_InputUnit, n_1stHiddenUnit],stddev=0.01))\n",
    "W2 = tf.Variable(tf.random_normal([n_1stHiddenUnit, n_2ndHiddenUnit],stddev=0.01))\n",
    "W3 = tf.Variable(tf.random_normal([n_2ndHiddenUnit, n_3rdHiddenUnit],stddev=0.01))\n",
    "W4 = tf.Variable(tf.random_normal([n_3rdHiddenUnit, n_4thHiddenUnit],stddev=0.01))\n",
    "W5 = tf.Variable(tf.random_normal([n_4thHiddenUnit, n_OutputUnit],stddev=0.01))\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([n_1stHiddenUnit], stddev=0.01))\n",
    "b2 = tf.Variable(tf.random_normal([n_2ndHiddenUnit], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([n_3rdHiddenUnit], stddev=0.01))\n",
    "b4 = tf.Variable(tf.random_normal([n_4thHiddenUnit], stddev=0.01))\n",
    "b5 = tf.Variable(tf.random_normal([n_OutputUnit], stddev=0.01))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 4]) # tensorflow의 placeholder라는 변수를 선언\n",
    "Y = tf.placeholder(tf.float32, [None,])\n",
    "\n",
    "L1 = tf.nn.elu(tf.matmul(X, W1) + b1)\n",
    "L2 = tf.nn.elu(tf.matmul(L1, W2) + b2)\n",
    "L3 = tf.nn.elu(tf.matmul(L2, W3) + b3)\n",
    "L4 = tf.nn.elu(tf.matmul(L3, W4) + b4)\n",
    "Hypothesis = tf.nn.tanh(tf.matmul(L4, W5) + b5)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(Y-Hypothesis))\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=0.5).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train NN & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0 0.0593363\n",
      "8 1000 0.0982946\n",
      "6 2000 0.107218\n",
      "11 3000 0.0983916\n",
      "13 4000 0.0972404\n",
      "18 5000 0.0921926\n",
      "9 6000 0.0979304\n",
      "8 7000 0.102597\n",
      "6 8000 0.103848\n",
      "2 9000 0.0978132\n",
      "19 10000 0.108216\n",
      "13 11000 0.0959886\n",
      "0 12000 0.100179\n",
      "6 13000 0.105069\n",
      "1 14000 0.109726\n",
      "5 15000 0.109577\n",
      "16 16000 0.129259\n",
      "19 17000 0.118885\n",
      "7 18000 0.0961095\n",
      "15 19000 0.116228\n",
      "2 20000 0.113653\n",
      "6 21000 0.113323\n",
      "5 22000 0.111004\n",
      "6 23000 0.114761\n",
      "0 24000 0.113706\n",
      "14 25000 0.109272\n",
      "7 26000 0.114584\n",
      "8 27000 0.119428\n",
      "9 28000 0.111844\n",
      "8 29000 0.112512\n",
      "11 30000 0.114559\n",
      "6 31000 0.121337\n",
      "6 32000 0.112563\n",
      "5 33000 0.112516\n",
      "8 34000 0.113221\n",
      "8 35000 0.114945\n",
      "3 36000 0.100093\n",
      "3 37000 0.114985\n",
      "13 38000 0.116057\n",
      "18 39000 0.115069\n",
      "5 40000 0.113988\n",
      "11 41000 0.115039\n",
      "2 42000 0.114887\n",
      "18 43000 0.115451\n",
      "18 44000 0.112967\n",
      "11 45000 0.119302\n",
      "8 46000 0.115622\n",
      "12 47000 0.114324\n",
      "19 48000 0.11638\n",
      "3 49000 0.108391\n",
      "16 50000 0.121481\n",
      "0 51000 0.129851\n",
      "19 52000 0.104721\n",
      "0 53000 0.112609\n",
      "8 54000 0.116833\n",
      "2 55000 0.115296\n",
      "10 56000 0.114775\n",
      "16 57000 0.117057\n",
      "12 58000 0.106582\n",
      "4 59000 0.117043\n",
      "0 60000 0.115797\n",
      "5 61000 0.118395\n",
      "16 62000 0.115241\n",
      "17 63000 0.11837\n",
      "11 64000 0.116696\n",
      "11 65000 0.11061\n",
      "11 66000 0.11466\n",
      "11 67000 0.112616\n",
      "0 68000 0.115763\n",
      "15 69000 0.11457\n",
      "11 70000 0.114667\n",
      "15 71000 0.115505\n",
      "2 72000 0.114439\n",
      "5 73000 0.114536\n",
      "12 74000 0.114376\n",
      "0 75000 0.109344\n",
      "2 76000 0.114458\n",
      "5 77000 0.114776\n",
      "6 78000 0.11256\n",
      "1 79000 0.113933\n",
      "9 80000 0.115256\n",
      "6 81000 0.115427\n",
      "14 82000 0.114861\n",
      "15 83000 0.114979\n",
      "18 84000 0.113973\n",
      "13 85000 0.117663\n",
      "16 86000 0.116143\n",
      "8 87000 0.113189\n",
      "2 88000 0.115143\n",
      "10 89000 0.115047\n",
      "18 90000 0.124238\n",
      "12 91000 0.114496\n",
      "9 92000 0.115051\n",
      "18 93000 0.113153\n",
      "5 94000 0.11596\n",
      "16 95000 0.115105\n",
      "9 96000 0.115636\n",
      "19 97000 0.11333\n",
      "19 98000 0.115156\n",
      "9 99000 0.113465\n",
      "R_square of EntireData\n",
      "0.802634340865\n",
      "R_square of TestData\n",
      "-2.54453531064\n",
      "Result of predicting TrainingData\n",
      "[[-0.23966677]\n",
      " [-0.49327502]\n",
      " [-0.45801601]\n",
      " [-0.13422641]\n",
      " [-0.11448685]\n",
      " [-0.16014089]\n",
      " [-0.19784372]\n",
      " [ 0.00388576]\n",
      " [-0.15302762]\n",
      " [ 0.0102513 ]\n",
      " [ 0.04501974]\n",
      " [ 0.52096212]\n",
      " [-0.1623659 ]\n",
      " [ 0.1845772 ]\n",
      " [-0.00265596]\n",
      " [ 0.08459334]\n",
      " [-0.17291765]\n",
      " [ 0.29075012]\n",
      " [ 0.03896868]\n",
      " [ 0.33626348]]\n",
      "Result of predicting TestData\n",
      "[[ 0.05594293]\n",
      " [ 0.2693885 ]\n",
      " [-0.29671827]\n",
      " [ 0.02267022]\n",
      " [ 0.23776485]]\n",
      "Y_NormalizedData\n",
      "[-0.21844449 -0.47152439 -0.45735005 -0.1123416  -0.11245536 -0.18036006\n",
      " -0.19692817  0.00145492 -0.14520267  0.01178692  0.04523337  0.52847561\n",
      " -0.13421128  0.19149351 -0.00787756  0.09143864 -0.16016158  0.30505231\n",
      "  0.04222738  0.33060721 -0.08104142  0.20294599  0.18485121  0.07951933\n",
      "  0.2628122 ]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(100000):\n",
    "        SGDorder = Sequence[step % 20] # training을 0번부터 20번까지 순차적으로 돌린다.\n",
    "        session.run(train, feed_dict ={X: X_TrainingData[SGDorder: SGDorder + 1,:], Y: Y_TrainingData[SGDorder: SGDorder + 1]})\n",
    "        #session.run(train, feed_dict ={X: X_TrainingData, Y: Y_TrainingData})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print (SGDorder,step, session.run(cost, feed_dict = {X: X_TrainingData, Y: Y_TrainingData}))\n",
    "            #print (W1)\n",
    "            #print (b1)\n",
    "        if step % 20 == 0:\n",
    "            random.shuffle(Sequence)\n",
    "            \n",
    "    Predict_to_TestData = session.run(Hypothesis, feed_dict={X : X_TestData})\n",
    "    Predict_to_TrainingData = session.run(Hypothesis, feed_dict={X : X_TrainingData})\n",
    "    Predict_to_EntireData = session.run(Hypothesis, feed_dict = {X : X_NormalizedData})\n",
    "    \n",
    "    print(\"R_square of EntireData\")\n",
    "    print(r2_score(Y_NormalizedData, Predict_to_EntireData))\n",
    "    print(\"R_square of TestData\")\n",
    "    print(r2_score(Y_TestData, Predict_to_TestData))\n",
    "    print(\"Result of predicting TrainingData\")\n",
    "    print(Predict_to_TrainingData)\n",
    "    print(\"Result of predicting TestData\")\n",
    "    print(Predict_to_TestData)\n",
    "    print(\"Y_NormalizedData\")\n",
    "    print(Y_NormalizedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7th eLU, tanh, 4, 100, 100, 50, 1\n",
    "R_square of EntireData\n",
    "0.702912816686\n",
    "R_square of TestData\n",
    "-4.37658055001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "n_InputUnit = 4\n",
    "n_1stHiddenUnit=100\n",
    "n_2ndHiddenUnit=100\n",
    "n_3rdHiddenUnit=50\n",
    "n_OutputUnit = 1\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([n_InputUnit, n_1stHiddenUnit],stddev=0.01))\n",
    "W2 = tf.Variable(tf.random_normal([n_1stHiddenUnit, n_2ndHiddenUnit],stddev=0.01))\n",
    "W3 = tf.Variable(tf.random_normal([n_2ndHiddenUnit, n_3rdHiddenUnit],stddev=0.01))\n",
    "W4 = tf.Variable(tf.random_normal([n_3rdHiddenUnit, n_OutputUnit],stddev=0.01))\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([n_1stHiddenUnit], stddev=0.01))\n",
    "b2 = tf.Variable(tf.random_normal([n_2ndHiddenUnit], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([n_3rdHiddenUnit], stddev=0.01))\n",
    "b4 = tf.Variable(tf.random_normal([n_OutputUnit], stddev=0.01))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 4]) # tensorflow의 placeholder라는 변수를 선언\n",
    "Y = tf.placeholder(tf.float32, [None,])\n",
    "\n",
    "L1 = tf.nn.elu(tf.matmul(X, W1) + b1)\n",
    "L2 = tf.nn.elu(tf.matmul(L1, W2) + b2)\n",
    "L3 = tf.nn.elu(tf.matmul(L2, W3) + b3)\n",
    "Hypothesis = tf.nn.tanh(tf.matmul(L3, W4) + b4)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(Y-Hypothesis))\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=0.5).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train NN & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 0 0.0583551\n",
      "15 1000 0.0863091\n",
      "2 2000 0.0954702\n",
      "16 3000 0.0908538\n",
      "5 4000 0.0976067\n",
      "5 5000 0.0980117\n",
      "5 6000 0.103242\n",
      "14 7000 0.116341\n",
      "4 8000 0.0999195\n",
      "10 9000 0.0936804\n",
      "6 10000 0.113702\n",
      "6 11000 0.112308\n",
      "12 12000 0.104366\n",
      "16 13000 0.119051\n",
      "10 14000 0.122052\n",
      "5 15000 0.110311\n",
      "14 16000 0.119476\n",
      "2 17000 0.111079\n",
      "6 18000 0.102843\n",
      "4 19000 0.133548\n",
      "0 20000 0.110261\n",
      "13 21000 0.108627\n",
      "7 22000 0.116181\n",
      "17 23000 0.113327\n",
      "5 24000 0.115769\n",
      "4 25000 0.117506\n",
      "1 26000 0.110776\n",
      "19 27000 0.112315\n",
      "4 28000 0.113479\n",
      "19 29000 0.111805\n",
      "15 30000 0.106639\n",
      "0 31000 0.116104\n",
      "17 32000 0.109839\n",
      "9 33000 0.112591\n",
      "18 34000 0.116151\n",
      "1 35000 0.118806\n",
      "19 36000 0.117676\n",
      "11 37000 0.106575\n",
      "8 38000 0.114518\n",
      "18 39000 0.110236\n",
      "4 40000 0.123988\n",
      "0 41000 0.117035\n",
      "12 42000 0.11829\n",
      "5 43000 0.115154\n",
      "11 44000 0.116687\n",
      "14 45000 0.108413\n",
      "19 46000 0.112382\n",
      "10 47000 0.108848\n",
      "13 48000 0.115522\n",
      "7 49000 0.113196\n",
      "8 50000 0.110597\n",
      "3 51000 0.114747\n",
      "9 52000 0.117333\n",
      "12 53000 0.113497\n",
      "13 54000 0.115426\n",
      "8 55000 0.113211\n",
      "0 56000 0.115726\n",
      "12 57000 0.115328\n",
      "8 58000 0.115207\n",
      "5 59000 0.11413\n",
      "10 60000 0.12085\n",
      "5 61000 0.115948\n",
      "16 62000 0.113335\n",
      "4 63000 0.1159\n",
      "3 64000 0.112547\n",
      "12 65000 0.119577\n",
      "2 66000 0.116335\n",
      "16 67000 0.114988\n",
      "16 68000 0.114858\n",
      "12 69000 0.113709\n",
      "11 70000 0.11542\n",
      "10 71000 0.113647\n",
      "13 72000 0.11394\n",
      "16 73000 0.116222\n",
      "9 74000 0.115161\n",
      "19 75000 0.10864\n",
      "2 76000 0.115286\n",
      "9 77000 0.115687\n",
      "3 78000 0.114296\n",
      "4 79000 0.114251\n",
      "7 80000 0.115436\n",
      "3 81000 0.115168\n",
      "10 82000 0.114278\n",
      "1 83000 0.115909\n",
      "4 84000 0.113967\n",
      "3 85000 0.114616\n",
      "12 86000 0.114077\n",
      "5 87000 0.115552\n",
      "2 88000 0.110163\n",
      "15 89000 0.114866\n",
      "18 90000 0.114602\n",
      "13 91000 0.123644\n",
      "0 92000 0.125266\n",
      "1 93000 0.115008\n",
      "9 94000 0.112906\n",
      "5 95000 0.11616\n",
      "10 96000 0.116082\n",
      "17 97000 0.114882\n",
      "11 98000 0.114778\n",
      "3 99000 0.113851\n",
      "R_square of EntireData\n",
      "0.702912816686\n",
      "R_square of TestData\n",
      "-4.37658055001\n",
      "Result of predicting TrainingData\n",
      "[[ -2.32367128e-01]\n",
      " [ -4.80203629e-01]\n",
      " [ -4.47499514e-01]\n",
      " [ -1.11357369e-01]\n",
      " [ -1.34547144e-01]\n",
      " [ -1.78590745e-01]\n",
      " [ -2.04958752e-01]\n",
      " [ -2.39819274e-04]\n",
      " [ -1.42548338e-01]\n",
      " [  2.36401688e-02]\n",
      " [  4.20538597e-02]\n",
      " [  5.31164765e-01]\n",
      " [ -1.36233345e-01]\n",
      " [  1.95505530e-01]\n",
      " [  5.53663354e-03]\n",
      " [  1.02724776e-01]\n",
      " [ -1.38109863e-01]\n",
      " [  3.05255204e-01]\n",
      " [  3.91985290e-02]\n",
      " [  3.30372632e-01]]\n",
      "Result of predicting TestData\n",
      "[[-0.07988957]\n",
      " [ 0.25584432]\n",
      " [-0.33827755]\n",
      " [ 0.0164421 ]\n",
      " [-0.07236923]]\n",
      "Y_NormalizedData\n",
      "[-0.21844449 -0.47152439 -0.45735005 -0.1123416  -0.11245536 -0.18036006\n",
      " -0.19692817  0.00145492 -0.14520267  0.01178692  0.04523337  0.52847561\n",
      " -0.13421128  0.19149351 -0.00787756  0.09143864 -0.16016158  0.30505231\n",
      "  0.04222738  0.33060721 -0.08104142  0.20294599  0.18485121  0.07951933\n",
      "  0.2628122 ]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(100000):\n",
    "        SGDorder = Sequence[step % 20] # training을 0번부터 20번까지 순차적으로 돌린다.\n",
    "        session.run(train, feed_dict ={X: X_TrainingData[SGDorder: SGDorder + 1,:], Y: Y_TrainingData[SGDorder: SGDorder + 1]})\n",
    "        #session.run(train, feed_dict ={X: X_TrainingData, Y: Y_TrainingData})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print (SGDorder,step, session.run(cost, feed_dict = {X: X_TrainingData, Y: Y_TrainingData}))\n",
    "            #print (W1)\n",
    "            #print (b1)\n",
    "        if step % 20 == 0:\n",
    "            random.shuffle(Sequence)\n",
    "            \n",
    "    Predict_to_TestData = session.run(Hypothesis, feed_dict={X : X_TestData})\n",
    "    Predict_to_TrainingData = session.run(Hypothesis, feed_dict={X : X_TrainingData})\n",
    "    Predict_to_EntireData = session.run(Hypothesis, feed_dict = {X : X_NormalizedData})\n",
    "    \n",
    "    print(\"R_square of EntireData\")\n",
    "    print(r2_score(Y_NormalizedData, Predict_to_EntireData))\n",
    "    print(\"R_square of TestData\")\n",
    "    print(r2_score(Y_TestData, Predict_to_TestData))\n",
    "    print(\"Result of predicting TrainingData\")\n",
    "    print(Predict_to_TrainingData)\n",
    "    print(\"Result of predicting TestData\")\n",
    "    print(Predict_to_TestData)\n",
    "    print(\"Y_NormalizedData\")\n",
    "    print(Y_NormalizedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8th eLU, tanh, 4, 10, 10, 10, 10, 10, 10, 1\n",
    "R_square of EntireData\n",
    "0.612517079802\n",
    "R_square of TestData\n",
    "-6.02644501071"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "n_InputUnit = 4\n",
    "n_1stHiddenUnit=10\n",
    "n_2ndHiddenUnit=10\n",
    "n_3rdHiddenUnit=10\n",
    "n_4thHiddenUnit=10\n",
    "n_5thHiddenUnit=10\n",
    "n_6thHiddenUnit=10\n",
    "n_OutputUnit = 1\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([n_InputUnit, n_1stHiddenUnit],stddev=0.01))\n",
    "W2 = tf.Variable(tf.random_normal([n_1stHiddenUnit, n_2ndHiddenUnit],stddev=0.01))\n",
    "W3 = tf.Variable(tf.random_normal([n_2ndHiddenUnit, n_3rdHiddenUnit],stddev=0.01))\n",
    "W4 = tf.Variable(tf.random_normal([n_3rdHiddenUnit, n_4thHiddenUnit],stddev=0.01))\n",
    "W5 = tf.Variable(tf.random_normal([n_4thHiddenUnit, n_5thHiddenUnit],stddev=0.01))\n",
    "W6 = tf.Variable(tf.random_normal([n_5thHiddenUnit, n_6thHiddenUnit],stddev=0.01))\n",
    "W7 = tf.Variable(tf.random_normal([n_6thHiddenUnit, n_OutputUnit],stddev=0.01))\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([n_1stHiddenUnit], stddev=0.01))\n",
    "b2 = tf.Variable(tf.random_normal([n_2ndHiddenUnit], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([n_3rdHiddenUnit], stddev=0.01))\n",
    "b4 = tf.Variable(tf.random_normal([n_4thHiddenUnit], stddev=0.01))\n",
    "b5 = tf.Variable(tf.random_normal([n_5thHiddenUnit], stddev=0.01))\n",
    "b6 = tf.Variable(tf.random_normal([n_6thHiddenUnit], stddev=0.01))\n",
    "b7 = tf.Variable(tf.random_normal([n_OutputUnit], stddev=0.01))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 4]) # tensorflow의 placeholder라는 변수를 선언\n",
    "Y = tf.placeholder(tf.float32, [None,])\n",
    "\n",
    "L1 = tf.nn.elu(tf.matmul(X, W1) + b1)\n",
    "L2 = tf.nn.elu(tf.matmul(L1, W2) + b2)\n",
    "L3 = tf.nn.elu(tf.matmul(L2, W3) + b3)\n",
    "L4 = tf.nn.elu(tf.matmul(L3, W4) + b4)\n",
    "L5 = tf.nn.elu(tf.matmul(L4, W5) + b5)\n",
    "L6 = tf.nn.elu(tf.matmul(L5, W6) + b6)\n",
    "Hypothesis = tf.nn.tanh(tf.matmul(L6, W7) + b7)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(Y-Hypothesis))\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=0.5).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train NN & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 0 0.0582934\n",
      "16 1000 0.05751\n",
      "8 2000 0.0575095\n",
      "4 3000 0.0966541\n",
      "15 4000 0.0964972\n",
      "11 5000 0.0968752\n",
      "2 6000 0.0926198\n",
      "10 7000 0.0944618\n",
      "10 8000 0.0906815\n",
      "16 9000 0.100562\n",
      "14 10000 0.103533\n",
      "12 11000 0.101885\n",
      "5 12000 0.10769\n",
      "5 13000 0.102072\n",
      "17 14000 0.105102\n",
      "13 15000 0.109704\n",
      "9 16000 0.107381\n",
      "8 17000 0.106167\n",
      "14 18000 0.107517\n",
      "5 19000 0.101307\n",
      "1 20000 0.108314\n",
      "17 21000 0.112364\n",
      "6 22000 0.114066\n",
      "9 23000 0.105962\n",
      "17 24000 0.118172\n",
      "17 25000 0.120901\n",
      "3 26000 0.105802\n",
      "16 27000 0.0977308\n",
      "19 28000 0.106979\n",
      "11 29000 0.11615\n",
      "7 30000 0.115795\n",
      "14 31000 0.131419\n",
      "15 32000 0.119447\n",
      "15 33000 0.111924\n",
      "14 34000 0.121741\n",
      "9 35000 0.112085\n",
      "10 36000 0.110781\n",
      "3 37000 0.11256\n",
      "4 38000 0.114682\n",
      "11 39000 0.117384\n",
      "15 40000 0.123782\n",
      "19 41000 0.117423\n",
      "17 42000 0.114012\n",
      "11 43000 0.115229\n",
      "9 44000 0.108603\n",
      "6 45000 0.124413\n",
      "14 46000 0.12082\n",
      "6 47000 0.124854\n",
      "7 48000 0.100911\n",
      "19 49000 0.111381\n",
      "7 50000 0.113548\n",
      "3 51000 0.117894\n",
      "9 52000 0.114129\n",
      "2 53000 0.116448\n",
      "0 54000 0.116112\n",
      "0 55000 0.112226\n",
      "14 56000 0.110771\n",
      "16 57000 0.113593\n",
      "12 58000 0.113592\n",
      "16 59000 0.118897\n",
      "6 60000 0.112218\n",
      "8 61000 0.11182\n",
      "9 62000 0.116367\n",
      "9 63000 0.114399\n",
      "15 64000 0.111211\n",
      "0 65000 0.117462\n",
      "8 66000 0.115623\n",
      "15 67000 0.114738\n",
      "15 68000 0.114339\n",
      "6 69000 0.108532\n",
      "1 70000 0.115113\n",
      "15 71000 0.114273\n",
      "8 72000 0.115014\n",
      "14 73000 0.111447\n",
      "16 74000 0.11621\n",
      "14 75000 0.115144\n",
      "4 76000 0.114184\n",
      "0 77000 0.113858\n",
      "2 78000 0.112378\n",
      "4 79000 0.115762\n",
      "11 80000 0.115175\n",
      "16 81000 0.116397\n",
      "14 82000 0.114834\n",
      "13 83000 0.118142\n",
      "19 84000 0.116247\n",
      "8 85000 0.114837\n",
      "13 86000 0.114678\n",
      "0 87000 0.112673\n",
      "15 88000 0.115664\n",
      "18 89000 0.114671\n",
      "12 90000 0.115475\n",
      "18 91000 0.117716\n",
      "15 92000 0.115329\n",
      "3 93000 0.116611\n",
      "13 94000 0.113127\n",
      "19 95000 0.11443\n",
      "2 96000 0.115507\n",
      "18 97000 0.114166\n",
      "10 98000 0.115118\n",
      "12 99000 0.109536\n",
      "R_square of EntireData\n",
      "0.612517079802\n",
      "R_square of TestData\n",
      "-6.02644501071\n",
      "Result of predicting TrainingData\n",
      "[[-0.21054499]\n",
      " [-0.47196105]\n",
      " [-0.45410606]\n",
      " [-0.11334969]\n",
      " [-0.10541697]\n",
      " [-0.17360201]\n",
      " [-0.19294038]\n",
      " [ 0.00536193]\n",
      " [-0.13458322]\n",
      " [ 0.01738316]\n",
      " [ 0.05223366]\n",
      " [ 0.53166962]\n",
      " [-0.13197705]\n",
      " [ 0.19949265]\n",
      " [ 0.00271741]\n",
      " [ 0.10835768]\n",
      " [-0.15510303]\n",
      " [ 0.29469788]\n",
      " [ 0.04234497]\n",
      " [ 0.35240924]]\n",
      "Result of predicting TestData\n",
      "[[-0.14477722]\n",
      " [ 0.10275126]\n",
      " [-0.51525867]\n",
      " [ 0.05894624]\n",
      " [ 0.16985054]]\n",
      "Y_NormalizedData\n",
      "[-0.21844449 -0.47152439 -0.45735005 -0.1123416  -0.11245536 -0.18036006\n",
      " -0.19692817  0.00145492 -0.14520267  0.01178692  0.04523337  0.52847561\n",
      " -0.13421128  0.19149351 -0.00787756  0.09143864 -0.16016158  0.30505231\n",
      "  0.04222738  0.33060721 -0.08104142  0.20294599  0.18485121  0.07951933\n",
      "  0.2628122 ]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(100000):\n",
    "        SGDorder = Sequence[step % 20] # training을 0번부터 20번까지 순차적으로 돌린다.\n",
    "        session.run(train, feed_dict ={X: X_TrainingData[SGDorder: SGDorder + 1,:], Y: Y_TrainingData[SGDorder: SGDorder + 1]})\n",
    "        #session.run(train, feed_dict ={X: X_TrainingData, Y: Y_TrainingData})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print (SGDorder,step, session.run(cost, feed_dict = {X: X_TrainingData, Y: Y_TrainingData}))\n",
    "            #print (W1)\n",
    "            #print (b1)\n",
    "        if step % 20 == 0:\n",
    "            random.shuffle(Sequence)\n",
    "            \n",
    "    Predict_to_TestData = session.run(Hypothesis, feed_dict={X : X_TestData})\n",
    "    Predict_to_TrainingData = session.run(Hypothesis, feed_dict={X : X_TrainingData})\n",
    "    Predict_to_EntireData = session.run(Hypothesis, feed_dict = {X : X_NormalizedData})\n",
    "    \n",
    "    print(\"R_square of EntireData\")\n",
    "    print(r2_score(Y_NormalizedData, Predict_to_EntireData))\n",
    "    print(\"R_square of TestData\")\n",
    "    print(r2_score(Y_TestData, Predict_to_TestData))\n",
    "    print(\"Result of predicting TrainingData\")\n",
    "    print(Predict_to_TrainingData)\n",
    "    print(\"Result of predicting TestData\")\n",
    "    print(Predict_to_TestData)\n",
    "    print(\"Y_NormalizedData\")\n",
    "    print(Y_NormalizedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9th eLU, tanh, 4, 500, 500, 100, 1 \n",
    "R_square of EntireData\n",
    "-18.8171709825\n",
    "R_square of TestData\n",
    "-51.8248455069"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "n_InputUnit = 4\n",
    "n_1stHiddenUnit=500\n",
    "n_2ndHiddenUnit=500\n",
    "n_3rdHiddenUnit=100\n",
    "n_OutputUnit = 1\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([n_InputUnit, n_1stHiddenUnit],stddev=0.01))\n",
    "W2 = tf.Variable(tf.random_normal([n_1stHiddenUnit, n_2ndHiddenUnit],stddev=0.01))\n",
    "W3 = tf.Variable(tf.random_normal([n_2ndHiddenUnit, n_3rdHiddenUnit],stddev=0.01))\n",
    "W4 = tf.Variable(tf.random_normal([n_3rdHiddenUnit, n_OutputUnit],stddev=0.01))\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([n_1stHiddenUnit], stddev=0.01))\n",
    "b2 = tf.Variable(tf.random_normal([n_2ndHiddenUnit], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([n_3rdHiddenUnit], stddev=0.01))\n",
    "b4 = tf.Variable(tf.random_normal([n_OutputUnit], stddev=0.01))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 4]) # tensorflow의 placeholder라는 변수를 선언\n",
    "Y = tf.placeholder(tf.float32, [None,])\n",
    "\n",
    "L1 = tf.nn.elu(tf.matmul(X, W1) + b1)\n",
    "L2 = tf.nn.elu(tf.matmul(L1, W2) + b2)\n",
    "L3 = tf.nn.elu(tf.matmul(L2, W3) + b3)\n",
    "Hypothesis = tf.nn.tanh(tf.matmul(L3, W4) + b4)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(Y-Hypothesis))\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=0.5).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train NN & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0.0578898\n",
      "16 1000 0.0841027\n",
      "16 2000 0.0974794\n",
      "7 3000 0.100917\n",
      "13 4000 0.11413\n",
      "1 5000 0.115132\n",
      "10 6000 0.108221\n",
      "10 7000 0.119891\n",
      "4 8000 0.125731\n",
      "18 9000 0.10196\n",
      "17 10000 0.109426\n",
      "3 11000 0.107223\n",
      "9 12000 0.115586\n",
      "4 13000 0.147572\n",
      "1 14000 0.10946\n",
      "4 15000 0.119975\n",
      "5 16000 0.124041\n",
      "2 17000 0.116147\n",
      "3 18000 0.113332\n",
      "13 19000 0.119378\n",
      "19 20000 0.118228\n",
      "7 21000 0.113308\n",
      "15 22000 0.113621\n",
      "17 23000 0.109031\n",
      "9 24000 0.117394\n",
      "12 25000 0.116164\n",
      "6 26000 0.105244\n",
      "16 27000 0.121559\n",
      "4 28000 0.110353\n",
      "16 29000 0.115952\n",
      "8 30000 0.113153\n",
      "7 31000 0.112761\n",
      "8 32000 0.11676\n",
      "14 33000 0.10687\n",
      "9 34000 0.114125\n",
      "7 35000 0.112777\n",
      "13 36000 0.116349\n",
      "12 37000 0.113663\n",
      "6 38000 0.112706\n",
      "3 39000 0.122141\n",
      "3 40000 0.111878\n",
      "7 41000 0.116525\n",
      "10 42000 0.111899\n",
      "1 43000 0.116429\n",
      "15 44000 0.116687\n",
      "16 45000 0.12634\n",
      "14 46000 0.11328\n",
      "14 47000 0.114212\n",
      "15 48000 0.116626\n",
      "2 49000 0.118573\n",
      "10 50000 0.134119\n",
      "6 51000 0.120963\n",
      "2 52000 0.115302\n",
      "1 53000 0.114458\n",
      "14 54000 0.115873\n",
      "18 55000 0.11608\n",
      "16 56000 0.10988\n",
      "6 57000 0.115464\n",
      "19 58000 0.107916\n",
      "0 59000 0.116895\n",
      "2 60000 0.120249\n",
      "15 61000 0.111253\n",
      "4 62000 0.105582\n",
      "17 63000 0.119393\n",
      "5 64000 0.109375\n",
      "5 65000 0.105247\n",
      "16 66000 0.111402\n",
      "15 67000 0.11427\n",
      "5 68000 0.115179\n",
      "18 69000 0.109755\n",
      "14 70000 0.114031\n",
      "11 71000 1.12347\n",
      "4 72000 1.12347\n",
      "18 73000 1.12347\n",
      "18 74000 1.12347\n",
      "12 75000 1.12347\n",
      "16 76000 1.12347\n",
      "7 77000 1.12347\n",
      "19 78000 1.12347\n",
      "18 79000 1.12347\n",
      "16 80000 1.12347\n",
      "7 81000 1.12347\n",
      "2 82000 1.12347\n",
      "3 83000 1.12347\n",
      "15 84000 1.12347\n",
      "3 85000 1.12347\n",
      "13 86000 1.12347\n",
      "1 87000 1.12347\n",
      "19 88000 1.12347\n",
      "2 89000 1.12347\n",
      "17 90000 1.12347\n",
      "11 91000 1.12347\n",
      "13 92000 1.12347\n",
      "5 93000 1.12347\n",
      "1 94000 1.12347\n",
      "8 95000 1.12347\n",
      "8 96000 1.12347\n",
      "13 97000 1.12347\n",
      "1 98000 1.12347\n",
      "19 99000 1.12347\n",
      "R_square of EntireData\n",
      "-18.8171709825\n",
      "R_square of TestData\n",
      "-51.8248455069\n",
      "Result of predicting TrainingData\n",
      "[[ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]]\n",
      "Result of predicting TestData\n",
      "[[ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]]\n",
      "Y_NormalizedData\n",
      "[-0.21844449 -0.47152439 -0.45735005 -0.1123416  -0.11245536 -0.18036006\n",
      " -0.19692817  0.00145492 -0.14520267  0.01178692  0.04523337  0.52847561\n",
      " -0.13421128  0.19149351 -0.00787756  0.09143864 -0.16016158  0.30505231\n",
      "  0.04222738  0.33060721 -0.08104142  0.20294599  0.18485121  0.07951933\n",
      "  0.2628122 ]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(100000):\n",
    "        SGDorder = Sequence[step % 20] # training을 0번부터 20번까지 순차적으로 돌린다.\n",
    "        session.run(train, feed_dict ={X: X_TrainingData[SGDorder: SGDorder + 1,:], Y: Y_TrainingData[SGDorder: SGDorder + 1]})\n",
    "        #session.run(train, feed_dict ={X: X_TrainingData, Y: Y_TrainingData})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print (SGDorder,step, session.run(cost, feed_dict = {X: X_TrainingData, Y: Y_TrainingData}))\n",
    "            #print (W1)\n",
    "            #print (b1)\n",
    "        if step % 20 == 0:\n",
    "            random.shuffle(Sequence)\n",
    "            \n",
    "    Predict_to_TestData = session.run(Hypothesis, feed_dict={X : X_TestData})\n",
    "    Predict_to_TrainingData = session.run(Hypothesis, feed_dict={X : X_TrainingData})\n",
    "    Predict_to_EntireData = session.run(Hypothesis, feed_dict = {X : X_NormalizedData})\n",
    "    \n",
    "    print(\"R_square of EntireData\")\n",
    "    print(r2_score(Y_NormalizedData, Predict_to_EntireData))\n",
    "    print(\"R_square of TestData\")\n",
    "    print(r2_score(Y_TestData, Predict_to_TestData))\n",
    "    print(\"Result of predicting TrainingData\")\n",
    "    print(Predict_to_TrainingData)\n",
    "    print(\"Result of predicting TestData\")\n",
    "    print(Predict_to_TestData)\n",
    "    print(\"Y_NormalizedData\")\n",
    "    print(Y_NormalizedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10th eLU, tanh, 4, 100, 100, 100, 50, 1 \n",
    "R_square of EntireData\n",
    "0.754092927381\n",
    "R_square of TestData\n",
    "-3.46744631107"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "n_InputUnit = 4\n",
    "n_1stHiddenUnit=100\n",
    "n_2ndHiddenUnit=100\n",
    "n_3rdHiddenUnit=100\n",
    "n_4thHiddenUnit=50\n",
    "n_OutputUnit = 1\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([n_InputUnit, n_1stHiddenUnit],stddev=0.01))\n",
    "W2 = tf.Variable(tf.random_normal([n_1stHiddenUnit, n_2ndHiddenUnit],stddev=0.01))\n",
    "W3 = tf.Variable(tf.random_normal([n_2ndHiddenUnit, n_3rdHiddenUnit],stddev=0.01))\n",
    "W4 = tf.Variable(tf.random_normal([n_3rdHiddenUnit, n_4thHiddenUnit],stddev=0.01))\n",
    "W5 = tf.Variable(tf.random_normal([n_4thHiddenUnit, n_OutputUnit],stddev=0.01))\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([n_1stHiddenUnit], stddev=0.01))\n",
    "b2 = tf.Variable(tf.random_normal([n_2ndHiddenUnit], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([n_3rdHiddenUnit], stddev=0.01))\n",
    "b4 = tf.Variable(tf.random_normal([n_4thHiddenUnit], stddev=0.01))\n",
    "b5 = tf.Variable(tf.random_normal([n_OutputUnit], stddev=0.01))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 4]) # tensorflow의 placeholder라는 변수를 선언\n",
    "Y = tf.placeholder(tf.float32, [None,])\n",
    "\n",
    "L1 = tf.nn.elu(tf.matmul(X, W1) + b1)\n",
    "L2 = tf.nn.elu(tf.matmul(L1, W2) + b2)\n",
    "L3 = tf.nn.elu(tf.matmul(L2, W3) + b3)\n",
    "L4 = tf.nn.elu(tf.matmul(L3, W4) + b4)\n",
    "Hypothesis = tf.nn.tanh(tf.matmul(L4, W5) + b5)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(Y-Hypothesis))\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=0.5).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train NN & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0 0.0590917\n",
      "5 1000 0.118709\n",
      "14 2000 0.0932212\n",
      "0 3000 0.0979851\n",
      "0 4000 0.106285\n",
      "2 5000 0.105408\n",
      "6 6000 0.105537\n",
      "7 7000 0.113743\n",
      "7 8000 0.118868\n",
      "8 9000 0.100202\n",
      "4 10000 0.114723\n",
      "8 11000 0.112881\n",
      "1 12000 0.114681\n",
      "2 13000 0.104768\n",
      "5 14000 0.120103\n",
      "16 15000 0.114904\n",
      "9 16000 0.113971\n",
      "16 17000 0.111085\n",
      "2 18000 0.115722\n",
      "5 19000 0.113407\n",
      "17 20000 0.114827\n",
      "13 21000 0.115482\n",
      "3 22000 0.103965\n",
      "11 23000 0.117315\n",
      "11 24000 0.113727\n",
      "11 25000 0.115044\n",
      "0 26000 0.117305\n",
      "12 27000 0.115627\n",
      "10 28000 0.114337\n",
      "18 29000 0.116013\n",
      "8 30000 0.11508\n",
      "1 31000 0.114487\n",
      "16 32000 0.114685\n",
      "19 33000 0.114983\n",
      "2 34000 0.116197\n",
      "6 35000 0.114229\n",
      "1 36000 0.114139\n",
      "4 37000 0.111973\n",
      "15 38000 0.113882\n",
      "18 39000 0.116054\n",
      "10 40000 0.121342\n",
      "13 41000 0.112518\n",
      "19 42000 0.115446\n",
      "5 43000 0.110768\n",
      "19 44000 0.114641\n",
      "5 45000 0.114582\n",
      "0 46000 0.114922\n",
      "2 47000 0.116096\n",
      "10 48000 0.122311\n",
      "1 49000 0.116251\n",
      "15 50000 0.115628\n",
      "6 51000 0.115042\n",
      "2 52000 0.114676\n",
      "7 53000 0.114749\n",
      "11 54000 0.115082\n",
      "6 55000 0.115064\n",
      "14 56000 0.118031\n",
      "1 57000 0.115032\n",
      "15 58000 0.11355\n",
      "7 59000 0.113787\n",
      "3 60000 0.115772\n",
      "3 61000 0.114769\n",
      "17 62000 0.115032\n",
      "12 63000 0.11501\n",
      "2 64000 0.115081\n",
      "14 65000 0.111949\n",
      "14 66000 0.115063\n",
      "9 67000 0.115086\n",
      "10 68000 0.117541\n",
      "14 69000 0.112944\n",
      "16 70000 0.114357\n",
      "16 71000 0.114951\n",
      "6 72000 0.116045\n",
      "7 73000 0.11503\n",
      "12 74000 0.113797\n",
      "18 75000 0.110045\n",
      "4 76000 0.115225\n",
      "10 77000 0.113657\n",
      "3 78000 0.11538\n",
      "19 79000 0.115043\n",
      "0 80000 0.122765\n",
      "10 81000 0.113047\n",
      "19 82000 0.114892\n",
      "14 83000 0.115008\n",
      "11 84000 0.115054\n",
      "2 85000 0.114216\n",
      "7 86000 0.114999\n",
      "1 87000 0.117016\n",
      "13 88000 0.114799\n",
      "13 89000 0.13963\n",
      "11 90000 0.11502\n",
      "16 91000 0.115156\n",
      "18 92000 0.115944\n",
      "7 93000 0.115737\n",
      "15 94000 0.115599\n",
      "14 95000 0.11491\n",
      "6 96000 0.114956\n",
      "12 97000 0.115287\n",
      "11 98000 0.115248\n",
      "18 99000 0.116728\n",
      "R_square of EntireData\n",
      "0.754092927381\n",
      "R_square of TestData\n",
      "-3.46744631107\n",
      "Result of predicting TrainingData\n",
      "[[-0.22276631]\n",
      " [-0.47481394]\n",
      " [-0.45997408]\n",
      " [-0.11544278]\n",
      " [-0.1112064 ]\n",
      " [-0.17643005]\n",
      " [-0.19805369]\n",
      " [ 0.00339771]\n",
      " [-0.145346  ]\n",
      " [ 0.01199914]\n",
      " [ 0.05281614]\n",
      " [ 0.53268731]\n",
      " [-0.1356131 ]\n",
      " [ 0.1975939 ]\n",
      " [-0.00554326]\n",
      " [ 0.09437786]\n",
      " [-0.15723559]\n",
      " [ 0.31389165]\n",
      " [ 0.04231293]\n",
      " [ 0.33774853]]\n",
      "Result of predicting TestData\n",
      "[[-0.14141095]\n",
      " [ 0.02785319]\n",
      " [-0.31399208]\n",
      " [-0.06154916]\n",
      " [ 0.11008878]]\n",
      "Y_NormalizedData\n",
      "[-0.21844449 -0.47152439 -0.45735005 -0.1123416  -0.11245536 -0.18036006\n",
      " -0.19692817  0.00145492 -0.14520267  0.01178692  0.04523337  0.52847561\n",
      " -0.13421128  0.19149351 -0.00787756  0.09143864 -0.16016158  0.30505231\n",
      "  0.04222738  0.33060721 -0.08104142  0.20294599  0.18485121  0.07951933\n",
      "  0.2628122 ]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(100000):\n",
    "        SGDorder = Sequence[step % 20] # training을 0번부터 20번까지 순차적으로 돌린다.\n",
    "        session.run(train, feed_dict ={X: X_TrainingData[SGDorder: SGDorder + 1,:], Y: Y_TrainingData[SGDorder: SGDorder + 1]})\n",
    "        #session.run(train, feed_dict ={X: X_TrainingData, Y: Y_TrainingData})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print (SGDorder,step, session.run(cost, feed_dict = {X: X_TrainingData, Y: Y_TrainingData}))\n",
    "            #print (W1)\n",
    "            #print (b1)\n",
    "        if step % 20 == 0:\n",
    "            random.shuffle(Sequence)\n",
    "            \n",
    "    Predict_to_TestData = session.run(Hypothesis, feed_dict={X : X_TestData})\n",
    "    Predict_to_TrainingData = session.run(Hypothesis, feed_dict={X : X_TrainingData})\n",
    "    Predict_to_EntireData = session.run(Hypothesis, feed_dict = {X : X_NormalizedData})\n",
    "    \n",
    "    print(\"R_square of EntireData\")\n",
    "    print(r2_score(Y_NormalizedData, Predict_to_EntireData))\n",
    "    print(\"R_square of TestData\")\n",
    "    print(r2_score(Y_TestData, Predict_to_TestData))\n",
    "    print(\"Result of predicting TrainingData\")\n",
    "    print(Predict_to_TrainingData)\n",
    "    print(\"Result of predicting TestData\")\n",
    "    print(Predict_to_TestData)\n",
    "    print(\"Y_NormalizedData\")\n",
    "    print(Y_NormalizedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "426px",
    "left": "1770.98px",
    "right": "20px",
    "top": "120.984px",
    "width": "354px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
