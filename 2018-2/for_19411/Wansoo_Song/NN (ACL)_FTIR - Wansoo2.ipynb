{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n",
    "\n",
    "# 2nd eLU, tanh, 4, 50, 50, 50, 1\n",
    "## Model\n",
    "## Train NN & Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data (normalized) & Separate to Training and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.   0.   0.5  0.5]\n",
      " [ 0.  -0.5  0.   0.5]\n",
      " [-0.5 -0.5  0.   0. ]\n",
      " [-0.5  0.   0.5  0. ]\n",
      " [ 0.5  0.   0.   0.5]\n",
      " [ 0.   0.  -0.5  0.5]\n",
      " [ 0.5 -0.5  0.   0. ]\n",
      " [ 0.   0.  -0.5 -0.5]\n",
      " [ 0.  -0.5 -0.5  0. ]\n",
      " [ 0.   0.   0.5 -0.5]\n",
      " [-0.5  0.   0.  -0.5]\n",
      " [ 0.5  0.5  0.   0. ]\n",
      " [ 0.  -0.5  0.5  0. ]\n",
      " [-0.5  0.5  0.   0. ]\n",
      " [ 0.5  0.   0.  -0.5]\n",
      " [-0.5  0.  -0.5  0. ]\n",
      " [ 0.   0.5  0.5  0. ]\n",
      " [ 0.   0.5  0.  -0.5]\n",
      " [ 0.5  0.   0.5  0. ]\n",
      " [ 0.   0.5 -0.5  0. ]]\n",
      "------------------------\n",
      "[[ 0.  -0.5  0.  -0.5]\n",
      " [ 0.5  0.  -0.5  0. ]\n",
      " [-0.5  0.   0.   0.5]\n",
      " [ 0.   0.   0.   0. ]\n",
      " [ 0.   0.5  0.   0.5]]\n",
      "------------------------\n",
      "[-0.21844449 -0.47152439 -0.45735005 -0.1123416  -0.11245536 -0.18036006\n",
      " -0.19692817  0.00145492 -0.14520267  0.01178692  0.04523337  0.52847561\n",
      " -0.13421128  0.19149351 -0.00787756  0.09143864 -0.16016158  0.30505231\n",
      "  0.04222738  0.33060721]\n",
      "------------------------\n",
      "[-0.08104142  0.20294599  0.18485121  0.07951933  0.2628122 ]\n"
     ]
    }
   ],
   "source": [
    "#data = np.loadtxt(\"ACL nomalization data.txt\")\n",
    "#data2 = np.loadtxt(\"acl data.txt\")\n",
    "data = np.loadtxt(\"ACL FTIR data_mean.txt\")\n",
    "\n",
    "X_NormalizedData = data[:,0:4]\n",
    "X_NormalizedData = X_NormalizedData - 0.5\n",
    "Y_NormalizedData = data[:,4]\n",
    "\n",
    "X_TrainingData = data[0:20,0:4]\n",
    "X_TrainingData = X_TrainingData - 0.5\n",
    "Y_TrainingData = data[0:20,4]\n",
    "\n",
    "X_TestData = data[20:,0:4]\n",
    "X_TestData = X_TestData - 0.5\n",
    "Y_TestData = data[20:,4]\n",
    "\n",
    "Sequence = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19]\n",
    "\n",
    "#XY_TrainingData = data[0:21,:]\n",
    "#X_TrainingData = XY_TrainingData[0:21,0:4]\n",
    "#Y_TrainingData = XY_TrainingData[0:21,4]\n",
    "#\n",
    "#XY_TestData = data[21:,:]\n",
    "#X_TestData = XY_TestData[:,0:4]\n",
    "#Y_TestData = XY_TestData[:,4]\n",
    "\n",
    "print(X_TrainingData)\n",
    "print(\"------------------------\")\n",
    "print(X_TestData)\n",
    "print(\"------------------------\")\n",
    "print(Y_TrainingData)\n",
    "print(\"------------------------\")\n",
    "print(Y_TestData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st eLU, tanh, 4, 5, 5, 5, 5, 1\n",
    "R_square of EntireData\n",
    "0.491762023498\n",
    "R_square of TestData\n",
    "-8.19693580628"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "n_InputUnit = 4\n",
    "n_1stHiddenUnit=5\n",
    "n_2ndHiddenUnit=5\n",
    "n_3rdHiddenUnit=5\n",
    "n_4thHiddenUnit=5\n",
    "n_OutputUnit = 1\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([n_InputUnit, n_1stHiddenUnit],stddev=0.01))\n",
    "W2 = tf.Variable(tf.random_normal([n_1stHiddenUnit, n_2ndHiddenUnit],stddev=0.01))\n",
    "W3 = tf.Variable(tf.random_normal([n_2ndHiddenUnit, n_3rdHiddenUnit],stddev=0.01))\n",
    "W4 = tf.Variable(tf.random_normal([n_3rdHiddenUnit, n_4thHiddenUnit],stddev=0.01))\n",
    "W5 = tf.Variable(tf.random_normal([n_4thHiddenUnit, n_OutputUnit],stddev=0.01))\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([n_1stHiddenUnit], stddev=0.01))\n",
    "b2 = tf.Variable(tf.random_normal([n_2ndHiddenUnit], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([n_3rdHiddenUnit], stddev=0.01))\n",
    "b4 = tf.Variable(tf.random_normal([n_4thHiddenUnit], stddev=0.01))\n",
    "b5 = tf.Variable(tf.random_normal([n_OutputUnit], stddev=0.01))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 4]) # tensorflow의 placeholder라는 변수를 선언\n",
    "Y = tf.placeholder(tf.float32, [None,])\n",
    "\n",
    "L1 = tf.nn.elu(tf.matmul(X, W1) + b1)\n",
    "L2 = tf.nn.elu(tf.matmul(L1, W2) + b2)\n",
    "L3 = tf.nn.elu(tf.matmul(L2, W3) + b3)\n",
    "L4 = tf.nn.elu(tf.matmul(L3, W4) + b4)\n",
    "Hypothesis = tf.nn.tanh(tf.matmul(L4, W5) + b5)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(Y-Hypothesis))\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=0.5).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train NN & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0.0591919\n",
      "9 1000 0.0959228\n",
      "18 2000 0.0972936\n",
      "7 3000 0.0957881\n",
      "0 4000 0.0972038\n",
      "18 5000 0.0981984\n",
      "19 6000 0.0958883\n",
      "5 7000 0.0973792\n",
      "14 8000 0.0976975\n",
      "1 9000 0.0975046\n",
      "1 10000 0.0990406\n",
      "7 11000 0.100786\n",
      "8 12000 0.101334\n",
      "7 13000 0.100444\n",
      "16 14000 0.102394\n",
      "1 15000 0.103348\n",
      "5 16000 0.103701\n",
      "7 17000 0.104582\n",
      "9 18000 0.105857\n",
      "5 19000 0.104066\n",
      "19 20000 0.105914\n",
      "5 21000 0.104616\n",
      "10 22000 0.104949\n",
      "7 23000 0.104981\n",
      "19 24000 0.105593\n",
      "7 25000 0.104459\n",
      "0 26000 0.10555\n",
      "18 27000 0.10458\n",
      "15 28000 0.106922\n",
      "13 29000 0.106271\n",
      "3 30000 0.107948\n",
      "5 31000 0.104551\n",
      "15 32000 0.106601\n",
      "19 33000 0.109628\n",
      "14 34000 0.105702\n",
      "6 35000 0.105445\n",
      "1 36000 0.107343\n",
      "0 37000 0.108003\n",
      "8 38000 0.106962\n",
      "3 39000 0.106481\n",
      "13 40000 0.10712\n",
      "17 41000 0.105158\n",
      "3 42000 0.106845\n",
      "18 43000 0.105547\n",
      "14 44000 0.109072\n",
      "11 45000 0.109383\n",
      "9 46000 0.107513\n",
      "13 47000 0.108123\n",
      "7 48000 0.112371\n",
      "7 49000 0.107268\n",
      "6 50000 0.11141\n",
      "11 51000 0.108614\n",
      "8 52000 0.109432\n",
      "13 53000 0.117002\n",
      "4 54000 0.115507\n",
      "10 55000 0.112323\n",
      "4 56000 0.114265\n",
      "3 57000 0.12234\n",
      "12 58000 0.111482\n",
      "6 59000 0.120477\n",
      "16 60000 0.117749\n",
      "18 61000 0.11201\n",
      "14 62000 0.111921\n",
      "15 63000 0.112154\n",
      "10 64000 0.116126\n",
      "18 65000 0.124267\n",
      "11 66000 0.112888\n",
      "8 67000 0.114988\n",
      "7 68000 0.118954\n",
      "16 69000 0.115086\n",
      "14 70000 0.116229\n",
      "16 71000 0.112842\n",
      "11 72000 0.11403\n",
      "15 73000 0.119513\n",
      "18 74000 0.117227\n",
      "2 75000 0.116058\n",
      "1 76000 0.122772\n",
      "4 77000 0.115318\n",
      "7 78000 0.120168\n",
      "2 79000 0.110313\n",
      "18 80000 0.114561\n",
      "4 81000 0.119701\n",
      "3 82000 0.11748\n",
      "11 83000 0.113175\n",
      "10 84000 0.119577\n",
      "11 85000 0.111661\n",
      "2 86000 0.11507\n",
      "17 87000 0.11516\n",
      "14 88000 0.111928\n",
      "8 89000 0.112723\n",
      "1 90000 0.116906\n",
      "0 91000 0.113081\n",
      "14 92000 0.112198\n",
      "1 93000 0.118515\n",
      "7 94000 0.11681\n",
      "8 95000 0.106511\n",
      "6 96000 0.119268\n",
      "6 97000 0.113667\n",
      "19 98000 0.115919\n",
      "14 99000 0.107104\n",
      "R_square of EntireData\n",
      "0.491762023498\n",
      "R_square of TestData\n",
      "-8.19693580628\n",
      "Result of predicting TrainingData\n",
      "[[-0.22779073]\n",
      " [-0.47364601]\n",
      " [-0.45906338]\n",
      " [-0.11703568]\n",
      " [-0.11402885]\n",
      " [-0.16993606]\n",
      " [-0.19212542]\n",
      " [ 0.01226401]\n",
      " [-0.13748574]\n",
      " [ 0.01735924]\n",
      " [ 0.04630231]\n",
      " [ 0.52038926]\n",
      " [-0.14673012]\n",
      " [ 0.14715177]\n",
      " [-0.01187989]\n",
      " [ 0.08164079]\n",
      " [-0.1605216 ]\n",
      " [ 0.29036224]\n",
      " [ 0.05251797]\n",
      " [ 0.34683916]]\n",
      "Result of predicting TestData\n",
      "[[-0.16233711]\n",
      " [-0.15480253]\n",
      " [-0.17085062]\n",
      " [ 0.03866468]\n",
      " [-0.37679747]]\n",
      "Y_NormalizedData\n",
      "[-0.21844449 -0.47152439 -0.45735005 -0.1123416  -0.11245536 -0.18036006\n",
      " -0.19692817  0.00145492 -0.14520267  0.01178692  0.04523337  0.52847561\n",
      " -0.13421128  0.19149351 -0.00787756  0.09143864 -0.16016158  0.30505231\n",
      "  0.04222738  0.33060721 -0.08104142  0.20294599  0.18485121  0.07951933\n",
      "  0.2628122 ]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(100000):\n",
    "        SGDorder = Sequence[step % 20] # training을 0번부터 20번까지 순차적으로 돌린다.\n",
    "        session.run(train, feed_dict ={X: X_TrainingData[SGDorder: SGDorder + 1,:], Y: Y_TrainingData[SGDorder: SGDorder + 1]})\n",
    "        #session.run(train, feed_dict ={X: X_TrainingData, Y: Y_TrainingData})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print (SGDorder,step, session.run(cost, feed_dict = {X: X_TrainingData, Y: Y_TrainingData}))\n",
    "            #print (W1)\n",
    "            #print (b1)\n",
    "        if step % 20 == 0:\n",
    "            random.shuffle(Sequence)\n",
    "            \n",
    "    Predict_to_TestData = session.run(Hypothesis, feed_dict={X : X_TestData})\n",
    "    Predict_to_TrainingData = session.run(Hypothesis, feed_dict={X : X_TrainingData})\n",
    "    Predict_to_EntireData = session.run(Hypothesis, feed_dict = {X : X_NormalizedData})\n",
    "    \n",
    "    print(\"R_square of EntireData\")\n",
    "    print(r2_score(Y_NormalizedData, Predict_to_EntireData))\n",
    "    print(\"R_square of TestData\")\n",
    "    print(r2_score(Y_TestData, Predict_to_TestData))\n",
    "    print(\"Result of predicting TrainingData\")\n",
    "    print(Predict_to_TrainingData)\n",
    "    print(\"Result of predicting TestData\")\n",
    "    print(Predict_to_TestData)\n",
    "    print(\"Y_NormalizedData\")\n",
    "    print(Y_NormalizedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 2th eLU, tanh, 4, 5, 5, 3, 3, 1\n",
    "R_square of EntireData\n",
    "0.0879968649096\n",
    "R_square of TestData\n",
    "-15.5296440731"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "n_InputUnit = 4\n",
    "n_1stHiddenUnit=5\n",
    "n_2ndHiddenUnit=5\n",
    "n_3rdHiddenUnit=3\n",
    "n_4thHiddenUnit=3\n",
    "n_OutputUnit = 1\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([n_InputUnit, n_1stHiddenUnit],stddev=0.01))\n",
    "W2 = tf.Variable(tf.random_normal([n_1stHiddenUnit, n_2ndHiddenUnit],stddev=0.01))\n",
    "W3 = tf.Variable(tf.random_normal([n_2ndHiddenUnit, n_3rdHiddenUnit],stddev=0.01))\n",
    "W4 = tf.Variable(tf.random_normal([n_3rdHiddenUnit, n_4thHiddenUnit],stddev=0.01))\n",
    "W5 = tf.Variable(tf.random_normal([n_4thHiddenUnit, n_OutputUnit],stddev=0.01))\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([n_1stHiddenUnit], stddev=0.01))\n",
    "b2 = tf.Variable(tf.random_normal([n_2ndHiddenUnit], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([n_3rdHiddenUnit], stddev=0.01))\n",
    "b4 = tf.Variable(tf.random_normal([n_4thHiddenUnit], stddev=0.01))\n",
    "b5 = tf.Variable(tf.random_normal([n_OutputUnit], stddev=0.01))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 4]) # tensorflow의 placeholder라는 변수를 선언\n",
    "Y = tf.placeholder(tf.float32, [None,])\n",
    "\n",
    "L1 = tf.nn.elu(tf.matmul(X, W1) + b1)\n",
    "L2 = tf.nn.elu(tf.matmul(L1, W2) + b2)\n",
    "L3 = tf.nn.elu(tf.matmul(L2, W3) + b3)\n",
    "L4 = tf.nn.elu(tf.matmul(L3, W4) + b4)\n",
    "Hypothesis = tf.nn.tanh(tf.matmul(L4, W5) + b5)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(Y-Hypothesis))\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=0.5).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Train NN & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 0 0.0597166\n",
      "8 1000 0.0953603\n",
      "2 2000 0.0944426\n",
      "17 3000 0.0963795\n",
      "7 4000 0.0963795\n",
      "4 5000 0.0958485\n",
      "0 6000 0.097133\n",
      "12 7000 0.0980876\n",
      "12 8000 0.0982557\n",
      "17 9000 0.0975394\n",
      "9 10000 0.098718\n",
      "1 11000 0.100373\n",
      "14 12000 0.102021\n",
      "15 13000 0.103701\n",
      "4 14000 0.10416\n",
      "6 15000 0.103341\n",
      "4 16000 0.104254\n",
      "8 17000 0.10419\n",
      "10 18000 0.104536\n",
      "14 19000 0.104724\n",
      "12 20000 0.104065\n",
      "18 21000 0.105047\n",
      "19 22000 0.106695\n",
      "17 23000 0.104891\n",
      "3 24000 0.106019\n",
      "9 25000 0.105744\n",
      "12 26000 0.104032\n",
      "1 27000 0.105561\n",
      "15 28000 0.104748\n",
      "10 29000 0.105825\n",
      "16 30000 0.105625\n",
      "18 31000 0.105387\n",
      "5 32000 0.104354\n",
      "5 33000 0.105053\n",
      "9 34000 0.105998\n",
      "4 35000 0.104409\n",
      "4 36000 0.106646\n",
      "13 37000 0.106219\n",
      "12 38000 0.108553\n",
      "5 39000 0.110096\n",
      "16 40000 0.108568\n",
      "6 41000 0.108332\n",
      "4 42000 0.114196\n",
      "7 43000 0.114663\n",
      "4 44000 0.108781\n",
      "17 45000 0.111401\n",
      "14 46000 0.109848\n",
      "12 47000 0.122036\n",
      "15 48000 0.110694\n",
      "13 49000 0.113502\n",
      "8 50000 0.109766\n",
      "17 51000 0.111349\n",
      "4 52000 0.110082\n",
      "7 53000 0.114402\n",
      "6 54000 0.111124\n",
      "17 55000 0.123863\n",
      "17 56000 0.113634\n",
      "9 57000 0.105706\n",
      "7 58000 0.110285\n",
      "16 59000 0.113751\n",
      "11 60000 0.115168\n",
      "1 61000 0.115698\n",
      "10 62000 0.113554\n",
      "15 63000 0.107892\n",
      "12 64000 0.107886\n",
      "2 65000 0.113076\n",
      "6 66000 0.114405\n",
      "8 67000 0.113843\n",
      "18 68000 0.116543\n",
      "7 69000 0.111241\n",
      "3 70000 0.114691\n",
      "5 71000 0.114287\n",
      "13 72000 0.113983\n",
      "9 73000 0.112859\n",
      "14 74000 0.116007\n",
      "3 75000 0.118529\n",
      "17 76000 0.116149\n",
      "17 77000 0.110193\n",
      "6 78000 0.116018\n",
      "4 79000 0.11532\n",
      "11 80000 0.11904\n",
      "17 81000 0.119375\n",
      "15 82000 0.114899\n",
      "15 83000 0.114893\n",
      "0 84000 0.113486\n",
      "18 85000 0.112361\n",
      "3 86000 0.118694\n",
      "4 87000 0.117039\n",
      "10 88000 0.11127\n",
      "2 89000 0.115329\n",
      "3 90000 0.11739\n",
      "19 91000 0.115643\n",
      "4 92000 0.114225\n",
      "8 93000 0.116097\n",
      "11 94000 0.114894\n",
      "4 95000 0.117195\n",
      "11 96000 0.114724\n",
      "13 97000 0.115394\n",
      "8 98000 0.11418\n",
      "12 99000 0.114363\n",
      "R_square of EntireData\n",
      "0.0879968649096\n",
      "R_square of TestData\n",
      "-15.5296440731\n",
      "Result of predicting TrainingData\n",
      "[[ -2.17626631e-01]\n",
      " [ -4.73316252e-01]\n",
      " [ -4.60034609e-01]\n",
      " [ -1.14919499e-01]\n",
      " [ -1.18401982e-01]\n",
      " [ -1.96914002e-01]\n",
      " [ -1.94087788e-01]\n",
      " [  4.61713597e-03]\n",
      " [ -1.48445576e-01]\n",
      " [  4.63618599e-02]\n",
      " [  2.10031644e-02]\n",
      " [  5.17031729e-01]\n",
      " [ -1.37052417e-01]\n",
      " [  1.83339894e-01]\n",
      " [ -1.95145578e-04]\n",
      " [  8.79378095e-02]\n",
      " [ -1.55441806e-01]\n",
      " [  2.98471451e-01]\n",
      " [  6.87406491e-03]\n",
      " [  3.11841875e-01]]\n",
      "Result of predicting TestData\n",
      "[[-0.07731552]\n",
      " [ 0.44284832]\n",
      " [-0.71946651]\n",
      " [-0.05440504]\n",
      " [-0.29780135]]\n",
      "Y_NormalizedData\n",
      "[-0.21844449 -0.47152439 -0.45735005 -0.1123416  -0.11245536 -0.18036006\n",
      " -0.19692817  0.00145492 -0.14520267  0.01178692  0.04523337  0.52847561\n",
      " -0.13421128  0.19149351 -0.00787756  0.09143864 -0.16016158  0.30505231\n",
      "  0.04222738  0.33060721 -0.08104142  0.20294599  0.18485121  0.07951933\n",
      "  0.2628122 ]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(100000):\n",
    "        SGDorder = Sequence[step % 20] # training을 0번부터 20번까지 순차적으로 돌린다.\n",
    "        session.run(train, feed_dict ={X: X_TrainingData[SGDorder: SGDorder + 1,:], Y: Y_TrainingData[SGDorder: SGDorder + 1]})\n",
    "        #session.run(train, feed_dict ={X: X_TrainingData, Y: Y_TrainingData})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print (SGDorder,step, session.run(cost, feed_dict = {X: X_TrainingData, Y: Y_TrainingData}))\n",
    "            #print (W1)\n",
    "            #print (b1)\n",
    "        if step % 20 == 0:\n",
    "            random.shuffle(Sequence)\n",
    "            \n",
    "    Predict_to_TestData = session.run(Hypothesis, feed_dict={X : X_TestData})\n",
    "    Predict_to_TrainingData = session.run(Hypothesis, feed_dict={X : X_TrainingData})\n",
    "    Predict_to_EntireData = session.run(Hypothesis, feed_dict = {X : X_NormalizedData})\n",
    "    \n",
    "    print(\"R_square of EntireData\")\n",
    "    print(r2_score(Y_NormalizedData, Predict_to_EntireData))\n",
    "    print(\"R_square of TestData\")\n",
    "    print(r2_score(Y_TestData, Predict_to_TestData))\n",
    "    print(\"Result of predicting TrainingData\")\n",
    "    print(Predict_to_TrainingData)\n",
    "    print(\"Result of predicting TestData\")\n",
    "    print(Predict_to_TestData)\n",
    "    print(\"Y_NormalizedData\")\n",
    "    print(Y_NormalizedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 3rd eLU, tanh, 4, 20, 20, 20, 1\n",
    "R_square of EntireData\n",
    "0.671702126264\n",
    "R_square of TestData\n",
    "-4.94691754594"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "n_InputUnit = 4\n",
    "n_1stHiddenUnit=20\n",
    "n_2ndHiddenUnit=20\n",
    "n_3rdHiddenUnit=20\n",
    "n_OutputUnit = 1\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([n_InputUnit, n_1stHiddenUnit],stddev=0.01))\n",
    "W2 = tf.Variable(tf.random_normal([n_1stHiddenUnit, n_2ndHiddenUnit],stddev=0.01))\n",
    "W3 = tf.Variable(tf.random_normal([n_2ndHiddenUnit, n_3rdHiddenUnit],stddev=0.01))\n",
    "W4 = tf.Variable(tf.random_normal([n_3rdHiddenUnit, n_OutputUnit],stddev=0.01))\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([n_1stHiddenUnit], stddev=0.01))\n",
    "b2 = tf.Variable(tf.random_normal([n_2ndHiddenUnit], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([n_3rdHiddenUnit], stddev=0.01))\n",
    "b4 = tf.Variable(tf.random_normal([n_OutputUnit], stddev=0.01))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 4]) # tensorflow의 placeholder라는 변수를 선언\n",
    "Y = tf.placeholder(tf.float32, [None,])\n",
    "\n",
    "L1 = tf.nn.elu(tf.matmul(X, W1) + b1)\n",
    "L2 = tf.nn.elu(tf.matmul(L1, W2) + b2)\n",
    "L3 = tf.nn.elu(tf.matmul(L2, W3) + b3)\n",
    "Hypothesis = tf.nn.tanh(tf.matmul(L3, W4) + b4)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(Y-Hypothesis))\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=0.5).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Train NN & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0 0.058412\n",
      "8 1000 0.100367\n",
      "13 2000 0.0966509\n",
      "6 3000 0.0967577\n",
      "16 4000 0.100647\n",
      "12 5000 0.0960784\n",
      "14 6000 0.0952815\n",
      "3 7000 0.0949181\n",
      "19 8000 0.0999141\n",
      "13 9000 0.100355\n",
      "8 10000 0.101971\n",
      "8 11000 0.0998259\n",
      "6 12000 0.105001\n",
      "8 13000 0.107792\n",
      "16 14000 0.107174\n",
      "15 15000 0.103811\n",
      "13 16000 0.10591\n",
      "18 17000 0.103655\n",
      "7 18000 0.107135\n",
      "0 19000 0.111169\n",
      "10 20000 0.108073\n",
      "2 21000 0.108399\n",
      "5 22000 0.106963\n",
      "10 23000 0.104092\n",
      "13 24000 0.115817\n",
      "1 25000 0.110288\n",
      "7 26000 0.108349\n",
      "8 27000 0.117448\n",
      "18 28000 0.104903\n",
      "1 29000 0.105404\n",
      "13 30000 0.113069\n",
      "1 31000 0.104067\n",
      "18 32000 0.11286\n",
      "12 33000 0.106168\n",
      "12 34000 0.111838\n",
      "14 35000 0.11139\n",
      "17 36000 0.11077\n",
      "12 37000 0.122134\n",
      "17 38000 0.112531\n",
      "14 39000 0.110562\n",
      "0 40000 0.10956\n",
      "3 41000 0.123868\n",
      "5 42000 0.117178\n",
      "2 43000 0.111359\n",
      "0 44000 0.107219\n",
      "8 45000 0.108931\n",
      "10 46000 0.118463\n",
      "12 47000 0.103889\n",
      "17 48000 0.111973\n",
      "1 49000 0.109355\n",
      "11 50000 0.116494\n",
      "9 51000 0.123685\n",
      "6 52000 0.11601\n",
      "13 53000 0.112595\n",
      "11 54000 0.118241\n",
      "19 55000 0.115132\n",
      "2 56000 0.114646\n",
      "1 57000 0.112459\n",
      "18 58000 0.114053\n",
      "8 59000 0.117749\n",
      "1 60000 0.111179\n",
      "17 61000 0.113653\n",
      "15 62000 0.114464\n",
      "8 63000 0.115975\n",
      "9 64000 0.114087\n",
      "19 65000 0.115644\n",
      "10 66000 0.117702\n",
      "13 67000 0.114904\n",
      "7 68000 0.113811\n",
      "7 69000 0.115553\n",
      "3 70000 0.118912\n",
      "15 71000 0.112507\n",
      "3 72000 0.116381\n",
      "2 73000 0.114098\n",
      "10 74000 0.115173\n",
      "6 75000 0.119767\n",
      "12 76000 0.111449\n",
      "6 77000 0.122319\n",
      "18 78000 0.115256\n",
      "15 79000 0.112902\n",
      "8 80000 0.115172\n",
      "7 81000 0.11476\n",
      "11 82000 0.114519\n",
      "14 83000 0.115882\n",
      "13 84000 0.115727\n",
      "16 85000 0.117851\n",
      "15 86000 0.120269\n",
      "2 87000 0.114404\n",
      "8 88000 0.114594\n",
      "17 89000 0.114996\n",
      "3 90000 0.115921\n",
      "10 91000 0.114757\n",
      "11 92000 0.118003\n",
      "17 93000 0.111038\n",
      "10 94000 0.114698\n",
      "8 95000 0.114149\n",
      "3 96000 0.116039\n",
      "9 97000 0.111971\n",
      "14 98000 0.115242\n",
      "14 99000 0.111957\n",
      "R_square of EntireData\n",
      "0.671702126264\n",
      "R_square of TestData\n",
      "-4.94691754594\n",
      "Result of predicting TrainingData\n",
      "[[-0.23616573]\n",
      " [-0.48688108]\n",
      " [-0.46545896]\n",
      " [-0.12378632]\n",
      " [-0.13155396]\n",
      " [-0.19796632]\n",
      " [-0.19968723]\n",
      " [ 0.0038819 ]\n",
      " [-0.14696041]\n",
      " [ 0.0103071 ]\n",
      " [ 0.0435315 ]\n",
      " [ 0.53348988]\n",
      " [-0.13941008]\n",
      " [ 0.18650401]\n",
      " [-0.00307971]\n",
      " [ 0.08554289]\n",
      " [-0.15463889]\n",
      " [ 0.31335184]\n",
      " [ 0.0367025 ]\n",
      " [ 0.33291897]]\n",
      "Result of predicting TestData\n",
      "[[-0.09988993]\n",
      " [ 0.11582699]\n",
      " [-0.42946848]\n",
      " [ 0.08083751]\n",
      " [ 0.0411832 ]]\n",
      "Y_NormalizedData\n",
      "[-0.21844449 -0.47152439 -0.45735005 -0.1123416  -0.11245536 -0.18036006\n",
      " -0.19692817  0.00145492 -0.14520267  0.01178692  0.04523337  0.52847561\n",
      " -0.13421128  0.19149351 -0.00787756  0.09143864 -0.16016158  0.30505231\n",
      "  0.04222738  0.33060721 -0.08104142  0.20294599  0.18485121  0.07951933\n",
      "  0.2628122 ]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(100000):\n",
    "        SGDorder = Sequence[step % 20] # training을 0번부터 20번까지 순차적으로 돌린다.\n",
    "        session.run(train, feed_dict ={X: X_TrainingData[SGDorder: SGDorder + 1,:], Y: Y_TrainingData[SGDorder: SGDorder + 1]})\n",
    "        #session.run(train, feed_dict ={X: X_TrainingData, Y: Y_TrainingData})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print (SGDorder,step, session.run(cost, feed_dict = {X: X_TrainingData, Y: Y_TrainingData}))\n",
    "            #print (W1)\n",
    "            #print (b1)\n",
    "        if step % 20 == 0:\n",
    "            random.shuffle(Sequence)\n",
    "            \n",
    "    Predict_to_TestData = session.run(Hypothesis, feed_dict={X : X_TestData})\n",
    "    Predict_to_TrainingData = session.run(Hypothesis, feed_dict={X : X_TrainingData})\n",
    "    Predict_to_EntireData = session.run(Hypothesis, feed_dict = {X : X_NormalizedData})\n",
    "    \n",
    "    print(\"R_square of EntireData\")\n",
    "    print(r2_score(Y_NormalizedData, Predict_to_EntireData))\n",
    "    print(\"R_square of TestData\")\n",
    "    print(r2_score(Y_TestData, Predict_to_TestData))\n",
    "    print(\"Result of predicting TrainingData\")\n",
    "    print(Predict_to_TrainingData)\n",
    "    print(\"Result of predicting TestData\")\n",
    "    print(Predict_to_TestData)\n",
    "    print(\"Y_NormalizedData\")\n",
    "    print(Y_NormalizedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 4th eLU, tanh, 4, 10, 20, 30, 1\n",
    "R_square of EntireData\n",
    "0.575180176745\n",
    "R_square of TestData\n",
    "-6.72425037375"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "n_InputUnit = 4\n",
    "n_1stHiddenUnit=10\n",
    "n_2ndHiddenUnit=20\n",
    "n_3rdHiddenUnit=30\n",
    "n_OutputUnit = 1\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([n_InputUnit, n_1stHiddenUnit],stddev=0.01))\n",
    "W2 = tf.Variable(tf.random_normal([n_1stHiddenUnit, n_2ndHiddenUnit],stddev=0.01))\n",
    "W3 = tf.Variable(tf.random_normal([n_2ndHiddenUnit, n_3rdHiddenUnit],stddev=0.01))\n",
    "W4 = tf.Variable(tf.random_normal([n_3rdHiddenUnit, n_OutputUnit],stddev=0.01))\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([n_1stHiddenUnit], stddev=0.01))\n",
    "b2 = tf.Variable(tf.random_normal([n_2ndHiddenUnit], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([n_3rdHiddenUnit], stddev=0.01))\n",
    "b4 = tf.Variable(tf.random_normal([n_OutputUnit], stddev=0.01))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 4]) # tensorflow의 placeholder라는 변수를 선언\n",
    "Y = tf.placeholder(tf.float32, [None,])\n",
    "\n",
    "L1 = tf.nn.elu(tf.matmul(X, W1) + b1)\n",
    "L2 = tf.nn.elu(tf.matmul(L1, W2) + b2)\n",
    "L3 = tf.nn.elu(tf.matmul(L2, W3) + b3)\n",
    "Hypothesis = tf.nn.tanh(tf.matmul(L3, W4) + b4)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(Y-Hypothesis))\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=0.5).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Train NN & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 0 0.0597475\n",
      "3 1000 0.0964565\n",
      "11 2000 0.0940569\n",
      "0 3000 0.0989742\n",
      "11 4000 0.0990248\n",
      "1 5000 0.0988625\n",
      "1 6000 0.0970362\n",
      "12 7000 0.0992741\n",
      "3 8000 0.092746\n",
      "16 9000 0.098734\n",
      "7 10000 0.102468\n",
      "14 11000 0.0995066\n",
      "6 12000 0.10282\n",
      "17 13000 0.103724\n",
      "1 14000 0.104931\n",
      "10 15000 0.103118\n",
      "3 16000 0.106145\n",
      "9 17000 0.102453\n",
      "10 18000 0.100412\n",
      "6 19000 0.107461\n",
      "17 20000 0.105655\n",
      "6 21000 0.105097\n",
      "10 22000 0.106502\n",
      "3 23000 0.105323\n",
      "5 24000 0.107999\n",
      "19 25000 0.108825\n",
      "7 26000 0.111369\n",
      "0 27000 0.110698\n",
      "18 28000 0.105986\n",
      "6 29000 0.107401\n",
      "10 30000 0.108991\n",
      "18 31000 0.111791\n",
      "1 32000 0.105231\n",
      "14 33000 0.113548\n",
      "5 34000 0.108347\n",
      "1 35000 0.120247\n",
      "16 36000 0.113965\n",
      "14 37000 0.109611\n",
      "17 38000 0.116788\n",
      "4 39000 0.117658\n",
      "6 40000 0.114389\n",
      "16 41000 0.116574\n",
      "12 42000 0.113811\n",
      "4 43000 0.113042\n",
      "6 44000 0.112776\n",
      "5 45000 0.118605\n",
      "11 46000 0.117271\n",
      "2 47000 0.115339\n",
      "16 48000 0.111501\n",
      "15 49000 0.115365\n",
      "0 50000 0.119064\n",
      "19 51000 0.115285\n",
      "11 52000 0.114666\n",
      "6 53000 0.115304\n",
      "16 54000 0.115296\n",
      "17 55000 0.11529\n",
      "1 56000 0.114641\n",
      "12 57000 0.106455\n",
      "16 58000 0.118919\n",
      "1 59000 0.115267\n",
      "13 60000 0.11868\n",
      "9 61000 0.11446\n",
      "7 62000 0.111209\n",
      "4 63000 0.115482\n",
      "1 64000 0.114552\n",
      "5 65000 0.116176\n",
      "15 66000 0.113757\n",
      "13 67000 0.110722\n",
      "11 68000 0.115977\n",
      "5 69000 0.112497\n",
      "11 70000 0.115268\n",
      "13 71000 0.11132\n",
      "9 72000 0.111912\n",
      "7 73000 0.113234\n",
      "1 74000 0.110649\n",
      "2 75000 0.120014\n",
      "2 76000 0.115183\n",
      "17 77000 0.114998\n",
      "19 78000 0.114324\n",
      "10 79000 0.113405\n",
      "13 80000 0.117366\n",
      "15 81000 0.115224\n",
      "12 82000 0.108777\n",
      "15 83000 0.111755\n",
      "19 84000 0.114873\n",
      "17 85000 0.116032\n",
      "15 86000 0.113852\n",
      "3 87000 0.115318\n",
      "4 88000 0.114757\n",
      "6 89000 0.115525\n",
      "17 90000 0.121015\n",
      "2 91000 0.110477\n",
      "4 92000 0.115439\n",
      "7 93000 0.114885\n",
      "4 94000 0.11503\n",
      "4 95000 0.112927\n",
      "2 96000 0.115371\n",
      "14 97000 0.114396\n",
      "16 98000 0.11576\n",
      "14 99000 0.113403\n",
      "R_square of EntireData\n",
      "0.575180176745\n",
      "R_square of TestData\n",
      "-6.72425037375\n",
      "Result of predicting TrainingData\n",
      "[[-0.21609148]\n",
      " [-0.46722767]\n",
      " [-0.45362201]\n",
      " [-0.11040594]\n",
      " [-0.11034343]\n",
      " [-0.17642339]\n",
      " [-0.19391412]\n",
      " [ 0.00268687]\n",
      " [-0.14289345]\n",
      " [ 0.01283929]\n",
      " [ 0.04616763]\n",
      " [ 0.52793735]\n",
      " [-0.13188615]\n",
      " [ 0.1910293 ]\n",
      " [-0.00603351]\n",
      " [ 0.09242319]\n",
      " [-0.16334656]\n",
      " [ 0.30729443]\n",
      " [ 0.04158775]\n",
      " [ 0.32997927]]\n",
      "Result of predicting TestData\n",
      "[[-0.12744008]\n",
      " [ 0.03929989]\n",
      " [-0.51505584]\n",
      " [ 0.11883311]\n",
      " [ 0.05316877]]\n",
      "Y_NormalizedData\n",
      "[-0.21844449 -0.47152439 -0.45735005 -0.1123416  -0.11245536 -0.18036006\n",
      " -0.19692817  0.00145492 -0.14520267  0.01178692  0.04523337  0.52847561\n",
      " -0.13421128  0.19149351 -0.00787756  0.09143864 -0.16016158  0.30505231\n",
      "  0.04222738  0.33060721 -0.08104142  0.20294599  0.18485121  0.07951933\n",
      "  0.2628122 ]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(100000):\n",
    "        SGDorder = Sequence[step % 20] # training을 0번부터 20번까지 순차적으로 돌린다.\n",
    "        session.run(train, feed_dict ={X: X_TrainingData[SGDorder: SGDorder + 1,:], Y: Y_TrainingData[SGDorder: SGDorder + 1]})\n",
    "        #session.run(train, feed_dict ={X: X_TrainingData, Y: Y_TrainingData})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print (SGDorder,step, session.run(cost, feed_dict = {X: X_TrainingData, Y: Y_TrainingData}))\n",
    "            #print (W1)\n",
    "            #print (b1)\n",
    "        if step % 20 == 0:\n",
    "            random.shuffle(Sequence)\n",
    "            \n",
    "    Predict_to_TestData = session.run(Hypothesis, feed_dict={X : X_TestData})\n",
    "    Predict_to_TrainingData = session.run(Hypothesis, feed_dict={X : X_TrainingData})\n",
    "    Predict_to_EntireData = session.run(Hypothesis, feed_dict = {X : X_NormalizedData})\n",
    "    \n",
    "    print(\"R_square of EntireData\")\n",
    "    print(r2_score(Y_NormalizedData, Predict_to_EntireData))\n",
    "    print(\"R_square of TestData\")\n",
    "    print(r2_score(Y_TestData, Predict_to_TestData))\n",
    "    print(\"Result of predicting TrainingData\")\n",
    "    print(Predict_to_TrainingData)\n",
    "    print(\"Result of predicting TestData\")\n",
    "    print(Predict_to_TestData)\n",
    "    print(\"Y_NormalizedData\")\n",
    "    print(Y_NormalizedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5th eLU, tanh, 4, 40, 50, 60, 70, 1\n",
    "R_square of EntireData\n",
    "0.810615608259\n",
    "R_square of TestData\n",
    "-2.40258045515"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "n_InputUnit = 4\n",
    "n_1stHiddenUnit=40\n",
    "n_2ndHiddenUnit=50\n",
    "n_3rdHiddenUnit=60\n",
    "n_4thHiddenUnit=70\n",
    "n_OutputUnit = 1\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([n_InputUnit, n_1stHiddenUnit],stddev=0.01))\n",
    "W2 = tf.Variable(tf.random_normal([n_1stHiddenUnit, n_2ndHiddenUnit],stddev=0.01))\n",
    "W3 = tf.Variable(tf.random_normal([n_2ndHiddenUnit, n_3rdHiddenUnit],stddev=0.01))\n",
    "W4 = tf.Variable(tf.random_normal([n_3rdHiddenUnit, n_4thHiddenUnit],stddev=0.01))\n",
    "W5 = tf.Variable(tf.random_normal([n_4thHiddenUnit, n_OutputUnit],stddev=0.01))\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([n_1stHiddenUnit], stddev=0.01))\n",
    "b2 = tf.Variable(tf.random_normal([n_2ndHiddenUnit], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([n_3rdHiddenUnit], stddev=0.01))\n",
    "b4 = tf.Variable(tf.random_normal([n_4thHiddenUnit], stddev=0.01))\n",
    "b5 = tf.Variable(tf.random_normal([n_OutputUnit], stddev=0.01))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 4]) # tensorflow의 placeholder라는 변수를 선언\n",
    "Y = tf.placeholder(tf.float32, [None,])\n",
    "\n",
    "L1 = tf.nn.elu(tf.matmul(X, W1) + b1)\n",
    "L2 = tf.nn.elu(tf.matmul(L1, W2) + b2)\n",
    "L3 = tf.nn.elu(tf.matmul(L2, W3) + b3)\n",
    "L4 = tf.nn.elu(tf.matmul(L3, W4) + b4)\n",
    "Hypothesis = tf.nn.tanh(tf.matmul(L4, W5) + b5)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(Y-Hypothesis))\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=0.5).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train NN & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0.0586837\n",
      "16 1000 0.0813662\n",
      "5 2000 0.084448\n",
      "6 3000 0.077176\n",
      "5 4000 0.0940011\n",
      "16 5000 0.09757\n",
      "2 6000 0.100815\n",
      "16 7000 0.105982\n",
      "12 8000 0.0966139\n",
      "10 9000 0.107551\n",
      "14 10000 0.109695\n",
      "15 11000 0.102497\n",
      "2 12000 0.108934\n",
      "4 13000 0.112782\n",
      "5 14000 0.110663\n",
      "12 15000 0.128403\n",
      "19 16000 0.107295\n",
      "10 17000 0.120805\n",
      "6 18000 0.12446\n",
      "19 19000 0.118903\n",
      "16 20000 0.116528\n",
      "18 21000 0.114924\n",
      "9 22000 0.110553\n",
      "4 23000 0.117864\n",
      "7 24000 0.118129\n",
      "12 25000 0.131394\n",
      "15 26000 0.115053\n",
      "18 27000 0.121583\n",
      "11 28000 0.115279\n",
      "11 29000 0.113733\n",
      "0 30000 0.116131\n",
      "16 31000 0.116159\n",
      "3 32000 0.12088\n",
      "10 33000 0.112699\n",
      "6 34000 0.114782\n",
      "19 35000 0.115301\n",
      "18 36000 0.115749\n",
      "16 37000 0.117063\n",
      "19 38000 0.114877\n",
      "16 39000 0.114496\n",
      "15 40000 0.115866\n",
      "15 41000 0.116528\n",
      "18 42000 0.115217\n",
      "11 43000 0.114929\n",
      "6 44000 0.115407\n",
      "3 45000 0.112576\n",
      "11 46000 0.115086\n",
      "17 47000 0.113386\n",
      "7 48000 0.113178\n",
      "12 49000 0.113351\n",
      "11 50000 0.11524\n",
      "17 51000 0.115451\n",
      "16 52000 0.116023\n",
      "17 53000 0.116675\n",
      "4 54000 0.115337\n",
      "6 55000 0.105283\n",
      "10 56000 0.115034\n",
      "6 57000 0.115827\n",
      "16 58000 0.114996\n",
      "13 59000 0.111617\n",
      "9 60000 0.114961\n",
      "10 61000 0.112141\n",
      "3 62000 0.107789\n",
      "10 63000 0.114431\n",
      "6 64000 0.11606\n",
      "3 65000 0.113781\n",
      "0 66000 0.119059\n",
      "1 67000 0.115917\n",
      "8 68000 0.115655\n",
      "4 69000 0.11534\n",
      "16 70000 0.115122\n",
      "12 71000 0.115034\n",
      "15 72000 0.113357\n",
      "18 73000 0.110236\n",
      "12 74000 0.115091\n",
      "10 75000 0.113219\n",
      "16 76000 0.119833\n",
      "12 77000 0.115094\n",
      "1 78000 0.115125\n",
      "3 79000 0.115212\n",
      "14 80000 0.113435\n",
      "15 81000 0.115477\n",
      "18 82000 0.115836\n",
      "19 83000 0.115279\n",
      "7 84000 0.115972\n",
      "4 85000 0.11567\n",
      "14 86000 0.115288\n",
      "0 87000 0.114577\n",
      "12 88000 0.11427\n",
      "12 89000 0.114904\n",
      "8 90000 0.117877\n",
      "15 91000 0.11629\n",
      "8 92000 0.115018\n",
      "13 93000 0.115395\n",
      "0 94000 0.115108\n",
      "15 95000 0.115237\n",
      "8 96000 0.115197\n",
      "8 97000 0.11638\n",
      "13 98000 0.114809\n",
      "6 99000 0.118591\n",
      "R_square of EntireData\n",
      "0.810615608259\n",
      "R_square of TestData\n",
      "-2.40258045515\n",
      "Result of predicting TrainingData\n",
      "[[-0.22237635]\n",
      " [-0.46952242]\n",
      " [-0.4718765 ]\n",
      " [-0.11523674]\n",
      " [-0.11135043]\n",
      " [-0.1820462 ]\n",
      " [-0.1982598 ]\n",
      " [-0.02675832]\n",
      " [-0.14014764]\n",
      " [ 0.01378772]\n",
      " [ 0.03706124]\n",
      " [ 0.55409694]\n",
      " [-0.13706665]\n",
      " [ 0.19620468]\n",
      " [ 0.01042506]\n",
      " [ 0.09237953]\n",
      " [-0.15782319]\n",
      " [ 0.27591676]\n",
      " [ 0.04656771]\n",
      " [ 0.33167878]]\n",
      "Result of predicting TestData\n",
      "[[-0.06891082]\n",
      " [ 0.23288831]\n",
      " [-0.2549454 ]\n",
      " [-0.01511907]\n",
      " [ 0.05031298]]\n",
      "Y_NormalizedData\n",
      "[-0.21844449 -0.47152439 -0.45735005 -0.1123416  -0.11245536 -0.18036006\n",
      " -0.19692817  0.00145492 -0.14520267  0.01178692  0.04523337  0.52847561\n",
      " -0.13421128  0.19149351 -0.00787756  0.09143864 -0.16016158  0.30505231\n",
      "  0.04222738  0.33060721 -0.08104142  0.20294599  0.18485121  0.07951933\n",
      "  0.2628122 ]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(100000):\n",
    "        SGDorder = Sequence[step % 20] # training을 0번부터 20번까지 순차적으로 돌린다.\n",
    "        session.run(train, feed_dict ={X: X_TrainingData[SGDorder: SGDorder + 1,:], Y: Y_TrainingData[SGDorder: SGDorder + 1]})\n",
    "        #session.run(train, feed_dict ={X: X_TrainingData, Y: Y_TrainingData})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print (SGDorder,step, session.run(cost, feed_dict = {X: X_TrainingData, Y: Y_TrainingData}))\n",
    "            #print (W1)\n",
    "            #print (b1)\n",
    "        if step % 20 == 0:\n",
    "            random.shuffle(Sequence)\n",
    "            \n",
    "    Predict_to_TestData = session.run(Hypothesis, feed_dict={X : X_TestData})\n",
    "    Predict_to_TrainingData = session.run(Hypothesis, feed_dict={X : X_TrainingData})\n",
    "    Predict_to_EntireData = session.run(Hypothesis, feed_dict = {X : X_NormalizedData})\n",
    "    \n",
    "    print(\"R_square of EntireData\")\n",
    "    print(r2_score(Y_NormalizedData, Predict_to_EntireData))\n",
    "    print(\"R_square of TestData\")\n",
    "    print(r2_score(Y_TestData, Predict_to_TestData))\n",
    "    print(\"Result of predicting TrainingData\")\n",
    "    print(Predict_to_TrainingData)\n",
    "    print(\"Result of predicting TestData\")\n",
    "    print(Predict_to_TestData)\n",
    "    print(\"Y_NormalizedData\")\n",
    "    print(Y_NormalizedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 6th eLU, tanh, 4, 50, 2, 2, 1\n",
    "R_square of EntireData\n",
    "0.701180318268\n",
    "R_square of TestData\n",
    "-4.3893905412"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "n_InputUnit = 4\n",
    "n_1stHiddenUnit=50\n",
    "n_2ndHiddenUnit=2\n",
    "n_3rdHiddenUnit=2\n",
    "n_OutputUnit = 1\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([n_InputUnit, n_1stHiddenUnit],stddev=0.01))\n",
    "W2 = tf.Variable(tf.random_normal([n_1stHiddenUnit, n_2ndHiddenUnit],stddev=0.01))\n",
    "W3 = tf.Variable(tf.random_normal([n_2ndHiddenUnit, n_3rdHiddenUnit],stddev=0.01))\n",
    "W4 = tf.Variable(tf.random_normal([n_3rdHiddenUnit, n_OutputUnit],stddev=0.01))\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([n_1stHiddenUnit], stddev=0.01))\n",
    "b2 = tf.Variable(tf.random_normal([n_2ndHiddenUnit], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([n_3rdHiddenUnit], stddev=0.01))\n",
    "b4 = tf.Variable(tf.random_normal([n_OutputUnit], stddev=0.01))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 4]) # tensorflow의 placeholder라는 변수를 선언\n",
    "Y = tf.placeholder(tf.float32, [None,])\n",
    "\n",
    "L1 = tf.nn.elu(tf.matmul(X, W1) + b1)\n",
    "L2 = tf.nn.elu(tf.matmul(L1, W2) + b2)\n",
    "L3 = tf.nn.elu(tf.matmul(L2, W3) + b3)\n",
    "Hypothesis = tf.nn.tanh(tf.matmul(L3, W4) + b4)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(Y-Hypothesis))\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=0.5).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Train NN & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 0 0.0594601\n",
      "9 1000 0.0934064\n",
      "15 2000 0.0965876\n",
      "6 3000 0.0946368\n",
      "17 4000 0.0964658\n",
      "9 5000 0.0979333\n",
      "16 6000 0.0973441\n",
      "8 7000 0.0982568\n",
      "9 8000 0.0986618\n",
      "1 9000 0.0981649\n",
      "4 10000 0.0963043\n",
      "2 11000 0.0964808\n",
      "0 12000 0.0986737\n",
      "18 13000 0.0966697\n",
      "13 14000 0.096515\n",
      "5 15000 0.0969437\n",
      "17 16000 0.0976925\n",
      "7 17000 0.0995399\n",
      "11 18000 0.099032\n",
      "18 19000 0.0976869\n",
      "5 20000 0.100851\n",
      "5 21000 0.099556\n",
      "12 22000 0.10009\n",
      "1 23000 0.100578\n",
      "4 24000 0.100958\n",
      "18 25000 0.102717\n",
      "17 26000 0.103648\n",
      "0 27000 0.102469\n",
      "15 28000 0.101772\n",
      "3 29000 0.103947\n",
      "11 30000 0.104661\n",
      "12 31000 0.105486\n",
      "9 32000 0.105851\n",
      "15 33000 0.106912\n",
      "16 34000 0.108095\n",
      "13 35000 0.107389\n",
      "15 36000 0.108063\n",
      "7 37000 0.110803\n",
      "4 38000 0.109853\n",
      "5 39000 0.106883\n",
      "13 40000 0.110425\n",
      "2 41000 0.111069\n",
      "0 42000 0.10688\n",
      "16 43000 0.112925\n",
      "18 44000 0.109092\n",
      "4 45000 0.114666\n",
      "14 46000 0.110644\n",
      "3 47000 0.114949\n",
      "9 48000 0.115098\n",
      "0 49000 0.112519\n",
      "16 50000 0.109139\n",
      "11 51000 0.115148\n",
      "1 52000 0.113867\n",
      "2 53000 0.114957\n",
      "18 54000 0.11408\n",
      "16 55000 0.111486\n",
      "19 56000 0.113863\n",
      "16 57000 0.114334\n",
      "6 58000 0.113136\n",
      "10 59000 0.109079\n",
      "0 60000 0.110635\n",
      "19 61000 0.113388\n",
      "15 62000 0.106477\n",
      "7 63000 0.111758\n",
      "2 64000 0.110074\n",
      "13 65000 0.115391\n",
      "19 66000 0.110351\n",
      "19 67000 0.110721\n",
      "15 68000 0.11013\n",
      "14 69000 0.115976\n",
      "11 70000 0.113561\n",
      "17 71000 0.115452\n",
      "12 72000 0.115137\n",
      "0 73000 0.115581\n",
      "4 74000 0.112992\n",
      "17 75000 0.119586\n",
      "1 76000 0.115326\n",
      "1 77000 0.115915\n",
      "18 78000 0.11365\n",
      "17 79000 0.111974\n",
      "14 80000 0.117517\n",
      "17 81000 0.113941\n",
      "13 82000 0.113864\n",
      "18 83000 0.116092\n",
      "17 84000 0.116692\n",
      "15 85000 0.11185\n",
      "19 86000 0.11448\n",
      "19 87000 0.115279\n",
      "19 88000 0.114197\n",
      "11 89000 0.115492\n",
      "0 90000 0.117989\n",
      "19 91000 0.112507\n",
      "8 92000 0.11484\n",
      "5 93000 0.11663\n",
      "9 94000 0.115196\n",
      "3 95000 0.11387\n",
      "3 96000 0.104268\n",
      "8 97000 0.113905\n",
      "5 98000 0.111759\n",
      "9 99000 0.11554\n",
      "R_square of EntireData\n",
      "0.701180318268\n",
      "R_square of TestData\n",
      "-4.3893905412\n",
      "Result of predicting TrainingData\n",
      "[[ -2.39789307e-01]\n",
      " [ -4.73721176e-01]\n",
      " [ -4.52927619e-01]\n",
      " [ -1.26564473e-01]\n",
      " [ -1.18330032e-01]\n",
      " [ -1.63863555e-01]\n",
      " [ -2.02624634e-01]\n",
      " [  1.83288474e-02]\n",
      " [ -1.33635566e-01]\n",
      " [ -3.70502385e-04]\n",
      " [  4.29724529e-02]\n",
      " [  5.14868021e-01]\n",
      " [ -1.49370432e-01]\n",
      " [  1.89846963e-01]\n",
      " [ -7.45997811e-03]\n",
      " [  1.04076147e-01]\n",
      " [ -1.79903448e-01]\n",
      " [  3.00327301e-01]\n",
      " [  2.35621482e-02]\n",
      " [  3.49281520e-01]]\n",
      "Result of predicting TestData\n",
      "[[ -3.98741692e-01]\n",
      " [  2.61379272e-01]\n",
      " [ -2.78434336e-01]\n",
      " [  1.55089542e-01]\n",
      " [  7.24792408e-05]]\n",
      "Y_NormalizedData\n",
      "[-0.21844449 -0.47152439 -0.45735005 -0.1123416  -0.11245536 -0.18036006\n",
      " -0.19692817  0.00145492 -0.14520267  0.01178692  0.04523337  0.52847561\n",
      " -0.13421128  0.19149351 -0.00787756  0.09143864 -0.16016158  0.30505231\n",
      "  0.04222738  0.33060721 -0.08104142  0.20294599  0.18485121  0.07951933\n",
      "  0.2628122 ]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(100000):\n",
    "        SGDorder = Sequence[step % 20] # training을 0번부터 20번까지 순차적으로 돌린다.\n",
    "        session.run(train, feed_dict ={X: X_TrainingData[SGDorder: SGDorder + 1,:], Y: Y_TrainingData[SGDorder: SGDorder + 1]})\n",
    "        #session.run(train, feed_dict ={X: X_TrainingData, Y: Y_TrainingData})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print (SGDorder,step, session.run(cost, feed_dict = {X: X_TrainingData, Y: Y_TrainingData}))\n",
    "            #print (W1)\n",
    "            #print (b1)\n",
    "        if step % 20 == 0:\n",
    "            random.shuffle(Sequence)\n",
    "            \n",
    "    Predict_to_TestData = session.run(Hypothesis, feed_dict={X : X_TestData})\n",
    "    Predict_to_TrainingData = session.run(Hypothesis, feed_dict={X : X_TrainingData})\n",
    "    Predict_to_EntireData = session.run(Hypothesis, feed_dict = {X : X_NormalizedData})\n",
    "    \n",
    "    print(\"R_square of EntireData\")\n",
    "    print(r2_score(Y_NormalizedData, Predict_to_EntireData))\n",
    "    print(\"R_square of TestData\")\n",
    "    print(r2_score(Y_TestData, Predict_to_TestData))\n",
    "    print(\"Result of predicting TrainingData\")\n",
    "    print(Predict_to_TrainingData)\n",
    "    print(\"Result of predicting TestData\")\n",
    "    print(Predict_to_TestData)\n",
    "    print(\"Y_NormalizedData\")\n",
    "    print(Y_NormalizedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 7th eLU, tanh, 4, 50, 10, 1\n",
    "R_square of EntireData\n",
    "0.539880865102\n",
    "R_square of TestData\n",
    "-7.36494950223"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "n_InputUnit = 4\n",
    "n_1stHiddenUnit=50\n",
    "n_2ndHiddenUnit=10\n",
    "n_OutputUnit = 1\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([n_InputUnit, n_1stHiddenUnit],stddev=0.01))\n",
    "W2 = tf.Variable(tf.random_normal([n_1stHiddenUnit, n_2ndHiddenUnit],stddev=0.01))\n",
    "W3 = tf.Variable(tf.random_normal([n_2ndHiddenUnit, n_OutputUnit],stddev=0.01))\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([n_1stHiddenUnit], stddev=0.01))\n",
    "b2 = tf.Variable(tf.random_normal([n_2ndHiddenUnit], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([n_OutputUnit], stddev=0.01))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 4]) # tensorflow의 placeholder라는 변수를 선언\n",
    "Y = tf.placeholder(tf.float32, [None,])\n",
    "\n",
    "L1 = tf.nn.elu(tf.matmul(X, W1) + b1)\n",
    "L2 = tf.nn.elu(tf.matmul(L1, W2) + b2)\n",
    "Hypothesis = tf.nn.tanh(tf.matmul(L2, W3) + b3)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(Y-Hypothesis))\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=0.5).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Train NN & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 0 0.0577447\n",
      "4 1000 0.0993924\n",
      "15 2000 0.0958965\n",
      "14 3000 0.0998972\n",
      "11 4000 0.0969414\n",
      "2 5000 0.0975838\n",
      "10 6000 0.102921\n",
      "11 7000 0.101741\n",
      "15 8000 0.10482\n",
      "2 9000 0.102175\n",
      "16 10000 0.104245\n",
      "13 11000 0.103003\n",
      "11 12000 0.101066\n",
      "14 13000 0.102098\n",
      "11 14000 0.103142\n",
      "0 15000 0.104334\n",
      "13 16000 0.100961\n",
      "8 17000 0.106286\n",
      "17 18000 0.103284\n",
      "16 19000 0.107802\n",
      "4 20000 0.107784\n",
      "6 21000 0.107092\n",
      "14 22000 0.110817\n",
      "3 23000 0.105056\n",
      "2 24000 0.108719\n",
      "2 25000 0.110693\n",
      "2 26000 0.107626\n",
      "16 27000 0.112719\n",
      "1 28000 0.114173\n",
      "12 29000 0.113733\n",
      "11 30000 0.111946\n",
      "6 31000 0.117163\n",
      "13 32000 0.110595\n",
      "18 33000 0.114331\n",
      "19 34000 0.114433\n",
      "7 35000 0.114561\n",
      "1 36000 0.115473\n",
      "8 37000 0.110441\n",
      "7 38000 0.115779\n",
      "19 39000 0.111459\n",
      "14 40000 0.113994\n",
      "2 41000 0.117166\n",
      "6 42000 0.115462\n",
      "12 43000 0.11451\n",
      "19 44000 0.114293\n",
      "14 45000 0.117195\n",
      "2 46000 0.114973\n",
      "3 47000 0.115104\n",
      "17 48000 0.11252\n",
      "8 49000 0.115724\n",
      "18 50000 0.115669\n",
      "15 51000 0.115218\n",
      "15 52000 0.112333\n",
      "16 53000 0.115368\n",
      "2 54000 0.114829\n",
      "4 55000 0.116792\n",
      "1 56000 0.126323\n",
      "9 57000 0.116217\n",
      "3 58000 0.113468\n",
      "13 59000 0.114297\n",
      "9 60000 0.112672\n",
      "19 61000 0.114756\n",
      "15 62000 0.116488\n",
      "17 63000 0.116656\n",
      "4 64000 0.117927\n",
      "7 65000 0.115493\n",
      "9 66000 0.114912\n",
      "8 67000 0.115502\n",
      "5 68000 0.115984\n",
      "3 69000 0.115895\n",
      "5 70000 0.115937\n",
      "1 71000 0.114568\n",
      "7 72000 0.11516\n",
      "1 73000 0.120756\n",
      "10 74000 0.113703\n",
      "1 75000 0.115175\n",
      "19 76000 0.1152\n",
      "13 77000 0.114898\n",
      "13 78000 0.115126\n",
      "15 79000 0.113846\n",
      "5 80000 0.115094\n",
      "18 81000 0.113639\n",
      "15 82000 0.114907\n",
      "16 83000 0.117708\n",
      "19 84000 0.114891\n",
      "0 85000 0.11226\n",
      "8 86000 0.12139\n",
      "11 87000 0.11639\n",
      "14 88000 0.113776\n",
      "19 89000 0.11519\n",
      "16 90000 0.115248\n",
      "19 91000 0.112796\n",
      "14 92000 0.113358\n",
      "0 93000 0.114476\n",
      "3 94000 0.114797\n",
      "11 95000 0.115703\n",
      "5 96000 0.111012\n",
      "17 97000 0.113551\n",
      "0 98000 0.116845\n",
      "9 99000 0.114723\n",
      "R_square of EntireData\n",
      "0.539880865102\n",
      "R_square of TestData\n",
      "-7.36494950223\n",
      "Result of predicting TrainingData\n",
      "[[-0.21503149]\n",
      " [-0.46954075]\n",
      " [-0.45596367]\n",
      " [-0.11232729]\n",
      " [-0.10595624]\n",
      " [-0.1815417 ]\n",
      " [-0.19789858]\n",
      " [-0.00684117]\n",
      " [-0.14874846]\n",
      " [ 0.01292149]\n",
      " [ 0.04487848]\n",
      " [ 0.5267545 ]\n",
      " [-0.13463864]\n",
      " [ 0.19149144]\n",
      " [-0.0081466 ]\n",
      " [ 0.08603403]\n",
      " [-0.16189803]\n",
      " [ 0.30284059]\n",
      " [ 0.04194265]\n",
      " [ 0.32719684]]\n",
      "Result of predicting TestData\n",
      "[[-0.34448987]\n",
      " [ 0.35224754]\n",
      " [-0.41584444]\n",
      " [-0.00324687]\n",
      " [-0.1267051 ]]\n",
      "Y_NormalizedData\n",
      "[-0.21844449 -0.47152439 -0.45735005 -0.1123416  -0.11245536 -0.18036006\n",
      " -0.19692817  0.00145492 -0.14520267  0.01178692  0.04523337  0.52847561\n",
      " -0.13421128  0.19149351 -0.00787756  0.09143864 -0.16016158  0.30505231\n",
      "  0.04222738  0.33060721 -0.08104142  0.20294599  0.18485121  0.07951933\n",
      "  0.2628122 ]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(100000):\n",
    "        SGDorder = Sequence[step % 20] # training을 0번부터 20번까지 순차적으로 돌린다.\n",
    "        session.run(train, feed_dict ={X: X_TrainingData[SGDorder: SGDorder + 1,:], Y: Y_TrainingData[SGDorder: SGDorder + 1]})\n",
    "        #session.run(train, feed_dict ={X: X_TrainingData, Y: Y_TrainingData})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print (SGDorder,step, session.run(cost, feed_dict = {X: X_TrainingData, Y: Y_TrainingData}))\n",
    "            #print (W1)\n",
    "            #print (b1)\n",
    "        if step % 20 == 0:\n",
    "            random.shuffle(Sequence)\n",
    "            \n",
    "    Predict_to_TestData = session.run(Hypothesis, feed_dict={X : X_TestData})\n",
    "    Predict_to_TrainingData = session.run(Hypothesis, feed_dict={X : X_TrainingData})\n",
    "    Predict_to_EntireData = session.run(Hypothesis, feed_dict = {X : X_NormalizedData})\n",
    "    \n",
    "    print(\"R_square of EntireData\")\n",
    "    print(r2_score(Y_NormalizedData, Predict_to_EntireData))\n",
    "    print(\"R_square of TestData\")\n",
    "    print(r2_score(Y_TestData, Predict_to_TestData))\n",
    "    print(\"Result of predicting TrainingData\")\n",
    "    print(Predict_to_TrainingData)\n",
    "    print(\"Result of predicting TestData\")\n",
    "    print(Predict_to_TestData)\n",
    "    print(\"Y_NormalizedData\")\n",
    "    print(Y_NormalizedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 8th eLU 4, 50, 50, 50, 1\n",
    "R_square of EntireData\n",
    "0.832872722312\n",
    "R_square of TestData\n",
    "-2.03928093358"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "n_InputUnit = 4\n",
    "n_1stHiddenUnit=50\n",
    "n_2ndHiddenUnit=50\n",
    "n_3rdHiddenUnit=50\n",
    "n_OutputUnit = 1\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([n_InputUnit, n_1stHiddenUnit],stddev=0.01))\n",
    "W2 = tf.Variable(tf.random_normal([n_1stHiddenUnit, n_2ndHiddenUnit],stddev=0.01))\n",
    "W3 = tf.Variable(tf.random_normal([n_2ndHiddenUnit, n_3rdHiddenUnit],stddev=0.01))\n",
    "W4 = tf.Variable(tf.random_normal([n_3rdHiddenUnit, n_OutputUnit],stddev=0.01))\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([n_1stHiddenUnit], stddev=0.01))\n",
    "b2 = tf.Variable(tf.random_normal([n_2ndHiddenUnit], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([n_3rdHiddenUnit], stddev=0.01))\n",
    "b4 = tf.Variable(tf.random_normal([n_OutputUnit], stddev=0.01))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 4]) # tensorflow의 placeholder라는 변수를 선언\n",
    "Y = tf.placeholder(tf.float32, [None,])\n",
    "\n",
    "L1 = tf.nn.elu(tf.matmul(X, W1) + b1)\n",
    "L2 = tf.nn.elu(tf.matmul(L1, W2) + b2)\n",
    "L3 = tf.nn.elu(tf.matmul(L2, W3) + b3)\n",
    "Hypothesis = tf.nn.elu(tf.matmul(L3, W4) + b4)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(Y-Hypothesis))\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=0.5).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Train NN & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 0 0.0598591\n",
      "9 1000 0.0914237\n",
      "17 2000 0.0979066\n",
      "16 3000 0.0944706\n",
      "16 4000 0.103999\n",
      "15 5000 0.0968753\n",
      "1 6000 0.102053\n",
      "0 7000 0.105114\n",
      "3 8000 0.110146\n",
      "16 9000 0.115229\n",
      "11 10000 0.107359\n",
      "19 11000 0.10457\n",
      "5 12000 0.111356\n",
      "14 13000 0.102579\n",
      "2 14000 0.109531\n",
      "10 15000 0.113722\n",
      "8 16000 0.107954\n",
      "15 17000 0.111239\n",
      "5 18000 0.110317\n",
      "15 19000 0.111807\n",
      "7 20000 0.115354\n",
      "15 21000 0.112118\n",
      "1 22000 0.117924\n",
      "9 23000 0.109133\n",
      "14 24000 0.119852\n",
      "12 25000 0.125901\n",
      "14 26000 0.119969\n",
      "15 27000 0.113637\n",
      "8 28000 0.122699\n",
      "5 29000 0.11928\n",
      "10 30000 0.109864\n",
      "11 31000 0.109449\n",
      "13 32000 0.115359\n",
      "19 33000 0.118647\n",
      "9 34000 0.112424\n",
      "4 35000 0.117118\n",
      "10 36000 0.113096\n",
      "9 37000 0.115166\n",
      "16 38000 0.121802\n",
      "1 39000 0.115921\n",
      "12 40000 0.115253\n",
      "14 41000 0.10848\n",
      "15 42000 0.121393\n",
      "1 43000 0.117291\n",
      "18 44000 0.119663\n",
      "7 45000 0.114446\n",
      "10 46000 0.114564\n",
      "3 47000 0.116915\n",
      "10 48000 0.115696\n",
      "8 49000 0.114827\n",
      "7 50000 0.117232\n",
      "6 51000 0.112185\n",
      "2 52000 0.116451\n",
      "18 53000 0.116935\n",
      "1 54000 0.118424\n",
      "2 55000 0.113852\n",
      "0 56000 0.114224\n",
      "2 57000 0.115046\n",
      "6 58000 0.111264\n",
      "17 59000 0.116779\n",
      "16 60000 0.115906\n",
      "9 61000 0.115752\n",
      "16 62000 0.115339\n",
      "18 63000 0.115077\n",
      "1 64000 0.114841\n",
      "1 65000 0.11339\n",
      "18 66000 0.117786\n",
      "2 67000 0.11511\n",
      "6 68000 0.114841\n",
      "16 69000 0.114408\n",
      "10 70000 0.114596\n",
      "18 71000 0.114129\n",
      "0 72000 0.115149\n",
      "17 73000 0.114716\n",
      "15 74000 0.11246\n",
      "11 75000 0.115418\n",
      "3 76000 0.115609\n",
      "19 77000 0.114938\n",
      "18 78000 0.114425\n",
      "17 79000 0.115748\n",
      "11 80000 0.11531\n",
      "6 81000 0.113072\n",
      "14 82000 0.11371\n",
      "1 83000 0.114574\n",
      "16 84000 0.115524\n",
      "11 85000 0.110066\n",
      "11 86000 0.11812\n",
      "19 87000 0.114849\n",
      "4 88000 0.114375\n",
      "8 89000 0.114918\n",
      "2 90000 0.115378\n",
      "19 91000 0.115006\n",
      "12 92000 0.118048\n",
      "4 93000 0.114963\n",
      "9 94000 0.113114\n",
      "12 95000 0.114948\n",
      "8 96000 0.115502\n",
      "1 97000 0.115295\n",
      "11 98000 0.114879\n",
      "1 99000 0.115619\n",
      "R_square of EntireData\n",
      "0.832872722312\n",
      "R_square of TestData\n",
      "-2.03928093358\n",
      "Result of predicting TrainingData\n",
      "[[-0.21855927]\n",
      " [-0.47212243]\n",
      " [-0.45701784]\n",
      " [-0.11185157]\n",
      " [-0.11312127]\n",
      " [-0.18120235]\n",
      " [-0.19693887]\n",
      " [ 0.00138743]\n",
      " [-0.1457209 ]\n",
      " [ 0.01209452]\n",
      " [ 0.04575473]\n",
      " [ 0.5279125 ]\n",
      " [-0.13361984]\n",
      " [ 0.19185078]\n",
      " [-0.00777113]\n",
      " [ 0.0910578 ]\n",
      " [-0.16002703]\n",
      " [ 0.30543441]\n",
      " [ 0.04210848]\n",
      " [ 0.32951507]]\n",
      "Result of predicting TestData\n",
      "[[-0.09585774]\n",
      " [ 0.07013718]\n",
      " [-0.25438076]\n",
      " [-0.02336568]\n",
      " [ 0.23696023]]\n",
      "Y_NormalizedData\n",
      "[-0.21844449 -0.47152439 -0.45735005 -0.1123416  -0.11245536 -0.18036006\n",
      " -0.19692817  0.00145492 -0.14520267  0.01178692  0.04523337  0.52847561\n",
      " -0.13421128  0.19149351 -0.00787756  0.09143864 -0.16016158  0.30505231\n",
      "  0.04222738  0.33060721 -0.08104142  0.20294599  0.18485121  0.07951933\n",
      "  0.2628122 ]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(100000):\n",
    "        SGDorder = Sequence[step % 20] # training을 0번부터 20번까지 순차적으로 돌린다.\n",
    "        session.run(train, feed_dict ={X: X_TrainingData[SGDorder: SGDorder + 1,:], Y: Y_TrainingData[SGDorder: SGDorder + 1]})\n",
    "        #session.run(train, feed_dict ={X: X_TrainingData, Y: Y_TrainingData})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print (SGDorder,step, session.run(cost, feed_dict = {X: X_TrainingData, Y: Y_TrainingData}))\n",
    "            #print (W1)\n",
    "            #print (b1)\n",
    "        if step % 20 == 0:\n",
    "            random.shuffle(Sequence)\n",
    "            \n",
    "    Predict_to_TestData = session.run(Hypothesis, feed_dict={X : X_TestData})\n",
    "    Predict_to_TrainingData = session.run(Hypothesis, feed_dict={X : X_TrainingData})\n",
    "    Predict_to_EntireData = session.run(Hypothesis, feed_dict = {X : X_NormalizedData})\n",
    "    \n",
    "    print(\"R_square of EntireData\")\n",
    "    print(r2_score(Y_NormalizedData, Predict_to_EntireData))\n",
    "    print(\"R_square of TestData\")\n",
    "    print(r2_score(Y_TestData, Predict_to_TestData))\n",
    "    print(\"Result of predicting TrainingData\")\n",
    "    print(Predict_to_TrainingData)\n",
    "    print(\"Result of predicting TestData\")\n",
    "    print(Predict_to_TestData)\n",
    "    print(\"Y_NormalizedData\")\n",
    "    print(Y_NormalizedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 9th eLU, tanh, 4, 50, 30, 50, 1\n",
    "R_square of EntireData\n",
    "0.630267524699\n",
    "R_square of TestData\n",
    "-5.72368478092"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "n_InputUnit = 4\n",
    "n_1stHiddenUnit=50\n",
    "n_2ndHiddenUnit=30\n",
    "n_3rdHiddenUnit=50\n",
    "n_OutputUnit = 1\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([n_InputUnit, n_1stHiddenUnit],stddev=0.01))\n",
    "W2 = tf.Variable(tf.random_normal([n_1stHiddenUnit, n_2ndHiddenUnit],stddev=0.01))\n",
    "W3 = tf.Variable(tf.random_normal([n_2ndHiddenUnit, n_3rdHiddenUnit],stddev=0.01))\n",
    "W4 = tf.Variable(tf.random_normal([n_3rdHiddenUnit, n_OutputUnit],stddev=0.01))\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([n_1stHiddenUnit], stddev=0.01))\n",
    "b2 = tf.Variable(tf.random_normal([n_2ndHiddenUnit], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([n_3rdHiddenUnit], stddev=0.01))\n",
    "b4 = tf.Variable(tf.random_normal([n_OutputUnit], stddev=0.01))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 4]) # tensorflow의 placeholder라는 변수를 선언\n",
    "Y = tf.placeholder(tf.float32, [None,])\n",
    "\n",
    "L1 = tf.nn.elu(tf.matmul(X, W1) + b1)\n",
    "L2 = tf.nn.elu(tf.matmul(L1, W2) + b2)\n",
    "L3 = tf.nn.elu(tf.matmul(L2, W3) + b3)\n",
    "Hypothesis = tf.nn.tanh(tf.matmul(L3, W4) + b4)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(Y-Hypothesis))\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=0.5).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Train NN & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0 0.0578097\n",
      "8 1000 0.104041\n",
      "15 2000 0.0983504\n",
      "2 3000 0.0930979\n",
      "8 4000 0.0932963\n",
      "8 5000 0.101727\n",
      "12 6000 0.105457\n",
      "19 7000 0.0996321\n",
      "3 8000 0.101341\n",
      "4 9000 0.0982755\n",
      "0 10000 0.103124\n",
      "15 11000 0.0998071\n",
      "12 12000 0.108508\n",
      "15 13000 0.102191\n",
      "11 14000 0.10747\n",
      "12 15000 0.112387\n",
      "16 16000 0.104686\n",
      "14 17000 0.0961403\n",
      "11 18000 0.113374\n",
      "13 19000 0.104729\n",
      "6 20000 0.123605\n",
      "17 21000 0.110309\n",
      "11 22000 0.119569\n",
      "10 23000 0.110472\n",
      "19 24000 0.117266\n",
      "8 25000 0.117665\n",
      "4 26000 0.116432\n",
      "0 27000 0.11503\n",
      "14 28000 0.108145\n",
      "6 29000 0.119603\n",
      "1 30000 0.112214\n",
      "8 31000 0.115803\n",
      "12 32000 0.106642\n",
      "17 33000 0.112969\n",
      "13 34000 0.116522\n",
      "0 35000 0.111167\n",
      "1 36000 0.113808\n",
      "16 37000 0.116378\n",
      "17 38000 0.115915\n",
      "1 39000 0.118066\n",
      "7 40000 0.114333\n",
      "11 41000 0.116423\n",
      "19 42000 0.114417\n",
      "13 43000 0.113679\n",
      "7 44000 0.115322\n",
      "11 45000 0.115138\n",
      "0 46000 0.113851\n",
      "18 47000 0.115664\n",
      "15 48000 0.120533\n",
      "14 49000 0.114185\n",
      "19 50000 0.115286\n",
      "1 51000 0.113196\n",
      "7 52000 0.115491\n",
      "16 53000 0.115995\n",
      "9 54000 0.114901\n",
      "3 55000 0.115417\n",
      "11 56000 0.116224\n",
      "1 57000 0.116673\n",
      "7 58000 0.11965\n",
      "1 59000 0.116736\n",
      "17 60000 0.11131\n",
      "0 61000 0.113264\n",
      "16 62000 0.111203\n",
      "4 63000 0.117982\n",
      "7 64000 0.12126\n",
      "0 65000 0.11688\n",
      "9 66000 0.115697\n",
      "12 67000 0.114139\n",
      "5 68000 0.113902\n",
      "17 69000 0.115111\n",
      "14 70000 0.115031\n",
      "19 71000 0.11606\n",
      "15 72000 0.115283\n",
      "11 73000 0.112879\n",
      "4 74000 0.111994\n",
      "6 75000 0.118096\n",
      "9 76000 0.115223\n",
      "19 77000 0.114444\n",
      "16 78000 0.115784\n",
      "0 79000 0.114665\n",
      "9 80000 0.114674\n",
      "0 81000 0.113828\n",
      "19 82000 0.114837\n",
      "5 83000 0.113719\n",
      "5 84000 0.115146\n",
      "0 85000 0.116771\n",
      "10 86000 0.114524\n",
      "2 87000 0.116703\n",
      "5 88000 0.11534\n",
      "2 89000 0.115315\n",
      "0 90000 0.117466\n",
      "15 91000 0.114033\n",
      "12 92000 0.113739\n",
      "16 93000 0.115535\n",
      "9 94000 0.114626\n",
      "13 95000 0.116991\n",
      "6 96000 0.115202\n",
      "5 97000 0.117909\n",
      "18 98000 0.114962\n",
      "16 99000 0.106976\n",
      "R_square of EntireData\n",
      "0.630267524699\n",
      "R_square of TestData\n",
      "-5.72368478092\n",
      "Result of predicting TrainingData\n",
      "[[-0.21848378]\n",
      " [-0.47154823]\n",
      " [-0.45867112]\n",
      " [-0.11303254]\n",
      " [-0.11194187]\n",
      " [-0.18048364]\n",
      " [-0.196603  ]\n",
      " [ 0.00143176]\n",
      " [-0.14552511]\n",
      " [ 0.01177766]\n",
      " [ 0.04492906]\n",
      " [ 0.530635  ]\n",
      " [-0.13447377]\n",
      " [ 0.19206841]\n",
      " [-0.00733237]\n",
      " [ 0.09103706]\n",
      " [-0.16012587]\n",
      " [ 0.30682504]\n",
      " [ 0.04261322]\n",
      " [ 0.33243227]]\n",
      "Result of predicting TestData\n",
      "[[-0.0610462 ]\n",
      " [-0.04033669]\n",
      " [-0.32210302]\n",
      " [-0.1110189 ]\n",
      " [-0.10908594]]\n",
      "Y_NormalizedData\n",
      "[-0.21844449 -0.47152439 -0.45735005 -0.1123416  -0.11245536 -0.18036006\n",
      " -0.19692817  0.00145492 -0.14520267  0.01178692  0.04523337  0.52847561\n",
      " -0.13421128  0.19149351 -0.00787756  0.09143864 -0.16016158  0.30505231\n",
      "  0.04222738  0.33060721 -0.08104142  0.20294599  0.18485121  0.07951933\n",
      "  0.2628122 ]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(100000):\n",
    "        SGDorder = Sequence[step % 20] # training을 0번부터 20번까지 순차적으로 돌린다.\n",
    "        session.run(train, feed_dict ={X: X_TrainingData[SGDorder: SGDorder + 1,:], Y: Y_TrainingData[SGDorder: SGDorder + 1]})\n",
    "        #session.run(train, feed_dict ={X: X_TrainingData, Y: Y_TrainingData})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print (SGDorder,step, session.run(cost, feed_dict = {X: X_TrainingData, Y: Y_TrainingData}))\n",
    "            #print (W1)\n",
    "            #print (b1)\n",
    "        if step % 20 == 0:\n",
    "            random.shuffle(Sequence)\n",
    "            \n",
    "    Predict_to_TestData = session.run(Hypothesis, feed_dict={X : X_TestData})\n",
    "    Predict_to_TrainingData = session.run(Hypothesis, feed_dict={X : X_TrainingData})\n",
    "    Predict_to_EntireData = session.run(Hypothesis, feed_dict = {X : X_NormalizedData})\n",
    "    \n",
    "    print(\"R_square of EntireData\")\n",
    "    print(r2_score(Y_NormalizedData, Predict_to_EntireData))\n",
    "    print(\"R_square of TestData\")\n",
    "    print(r2_score(Y_TestData, Predict_to_TestData))\n",
    "    print(\"Result of predicting TrainingData\")\n",
    "    print(Predict_to_TrainingData)\n",
    "    print(\"Result of predicting TestData\")\n",
    "    print(Predict_to_TestData)\n",
    "    print(\"Y_NormalizedData\")\n",
    "    print(Y_NormalizedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10th eLU, tanh, 4, 10, 5, 10, 5, 10, 5, 1\n",
    "R_square of EntireData\n",
    "0.65002034887\n",
    "R_square of TestData\n",
    "-5.33083609998"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "n_InputUnit = 4\n",
    "n_1stHiddenUnit=10\n",
    "n_2ndHiddenUnit=5\n",
    "n_3rdHiddenUnit=10\n",
    "n_4thHiddenUnit=5\n",
    "n_5thHiddenUnit=10\n",
    "n_6thHiddenUnit=5\n",
    "n_OutputUnit = 1\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([n_InputUnit, n_1stHiddenUnit],stddev=0.01))\n",
    "W2 = tf.Variable(tf.random_normal([n_1stHiddenUnit, n_2ndHiddenUnit],stddev=0.01))\n",
    "W3 = tf.Variable(tf.random_normal([n_2ndHiddenUnit, n_3rdHiddenUnit],stddev=0.01))\n",
    "W4 = tf.Variable(tf.random_normal([n_3rdHiddenUnit, n_4thHiddenUnit],stddev=0.01))\n",
    "W5 = tf.Variable(tf.random_normal([n_4thHiddenUnit, n_5thHiddenUnit],stddev=0.01))\n",
    "W6 = tf.Variable(tf.random_normal([n_5thHiddenUnit, n_6thHiddenUnit],stddev=0.01))\n",
    "W7 = tf.Variable(tf.random_normal([n_6thHiddenUnit, n_OutputUnit],stddev=0.01))\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([n_1stHiddenUnit], stddev=0.01))\n",
    "b2 = tf.Variable(tf.random_normal([n_2ndHiddenUnit], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([n_3rdHiddenUnit], stddev=0.01))\n",
    "b4 = tf.Variable(tf.random_normal([n_4thHiddenUnit], stddev=0.01))\n",
    "b5 = tf.Variable(tf.random_normal([n_5thHiddenUnit], stddev=0.01))\n",
    "b6 = tf.Variable(tf.random_normal([n_6thHiddenUnit], stddev=0.01))\n",
    "b7 = tf.Variable(tf.random_normal([n_OutputUnit], stddev=0.01))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 4]) # tensorflow의 placeholder라는 변수를 선언\n",
    "Y = tf.placeholder(tf.float32, [None,])\n",
    "\n",
    "L1 = tf.nn.elu(tf.matmul(X, W1) + b1)\n",
    "L2 = tf.nn.elu(tf.matmul(L1, W2) + b2)\n",
    "L3 = tf.nn.elu(tf.matmul(L2, W3) + b3)\n",
    "L4 = tf.nn.elu(tf.matmul(L3, W4) + b4)\n",
    "L5 = tf.nn.elu(tf.matmul(L4, W5) + b5)\n",
    "L6 = tf.nn.elu(tf.matmul(L5, W6) + b6)\n",
    "Hypothesis = tf.nn.tanh(tf.matmul(L6, W7) + b7)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(Y-Hypothesis))\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=0.5).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train NN & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 0 0.0588626\n",
      "7 1000 0.05751\n",
      "5 2000 0.0575098\n",
      "7 3000 0.0575095\n",
      "18 4000 0.0876663\n",
      "14 5000 0.0952687\n",
      "5 6000 0.0952653\n",
      "0 7000 0.0941646\n",
      "15 8000 0.100329\n",
      "15 9000 0.105696\n",
      "17 10000 0.103891\n",
      "5 11000 0.103319\n",
      "12 12000 0.109899\n",
      "6 13000 0.106556\n",
      "3 14000 0.106418\n",
      "10 15000 0.106722\n",
      "2 16000 0.10627\n",
      "5 17000 0.113369\n",
      "11 18000 0.105539\n",
      "13 19000 0.109041\n",
      "2 20000 0.107679\n",
      "4 21000 0.113016\n",
      "5 22000 0.109042\n",
      "18 23000 0.114648\n",
      "0 24000 0.113606\n",
      "19 25000 0.111849\n",
      "12 26000 0.11019\n",
      "13 27000 0.112587\n",
      "0 28000 0.109758\n",
      "11 29000 0.111665\n",
      "11 30000 0.114578\n",
      "18 31000 0.109267\n",
      "19 32000 0.114746\n",
      "12 33000 0.11678\n",
      "9 34000 0.11131\n",
      "16 35000 0.110497\n",
      "10 36000 0.117077\n",
      "10 37000 0.115443\n",
      "5 38000 0.110542\n",
      "8 39000 0.112324\n",
      "16 40000 0.115057\n",
      "18 41000 0.114785\n",
      "10 42000 0.112093\n",
      "19 43000 0.109926\n",
      "5 44000 0.114256\n",
      "10 45000 0.109574\n",
      "6 46000 0.114539\n",
      "10 47000 0.113398\n",
      "7 48000 0.11171\n",
      "1 49000 0.116477\n",
      "9 50000 0.113038\n",
      "16 51000 0.117898\n",
      "4 52000 0.114571\n",
      "15 53000 0.1081\n",
      "5 54000 0.117119\n",
      "19 55000 0.118219\n",
      "9 56000 0.110107\n",
      "7 57000 0.1209\n",
      "1 58000 0.115413\n",
      "16 59000 0.115825\n",
      "4 60000 0.119397\n",
      "19 61000 0.116824\n",
      "16 62000 0.11215\n",
      "5 63000 0.111394\n",
      "3 64000 0.127365\n",
      "5 65000 0.116755\n",
      "6 66000 0.118459\n",
      "14 67000 0.114135\n",
      "6 68000 0.113737\n",
      "19 69000 0.115067\n",
      "12 70000 0.121767\n",
      "7 71000 0.115075\n",
      "13 72000 0.112557\n",
      "12 73000 0.114687\n",
      "5 74000 0.120036\n",
      "17 75000 0.112088\n",
      "0 76000 0.121366\n",
      "8 77000 0.114905\n",
      "5 78000 0.103513\n",
      "10 79000 0.116519\n",
      "14 80000 0.115156\n",
      "19 81000 0.11516\n",
      "1 82000 0.117231\n",
      "11 83000 0.115003\n",
      "16 84000 0.115307\n",
      "11 85000 0.115992\n",
      "13 86000 0.115236\n",
      "3 87000 0.114597\n",
      "3 88000 0.116184\n",
      "18 89000 0.110832\n",
      "7 90000 0.11461\n",
      "9 91000 0.115597\n",
      "1 92000 0.112445\n",
      "19 93000 0.11467\n",
      "18 94000 0.106186\n",
      "12 95000 0.110567\n",
      "1 96000 0.117165\n",
      "2 97000 0.1145\n",
      "13 98000 0.115284\n",
      "1 99000 0.117915\n",
      "R_square of EntireData\n",
      "0.65002034887\n",
      "R_square of TestData\n",
      "-5.33083609998\n",
      "Result of predicting TrainingData\n",
      "[[-0.21577598]\n",
      " [-0.46747091]\n",
      " [-0.45075044]\n",
      " [-0.10382311]\n",
      " [-0.11171182]\n",
      " [-0.16016215]\n",
      " [-0.19843683]\n",
      " [ 0.00857509]\n",
      " [-0.14292753]\n",
      " [ 0.02192832]\n",
      " [ 0.0532832 ]\n",
      " [ 0.52838683]\n",
      " [-0.13231248]\n",
      " [ 0.19294779]\n",
      " [ 0.00609778]\n",
      " [ 0.10107013]\n",
      " [-0.1531582 ]\n",
      " [ 0.28973141]\n",
      " [ 0.04801366]\n",
      " [ 0.36357039]]\n",
      "Result of predicting TestData\n",
      "[[ 0.0610757 ]\n",
      " [ 0.30561751]\n",
      " [-0.46490443]\n",
      " [ 0.06762271]\n",
      " [ 0.3599695 ]]\n",
      "Y_NormalizedData\n",
      "[-0.21844449 -0.47152439 -0.45735005 -0.1123416  -0.11245536 -0.18036006\n",
      " -0.19692817  0.00145492 -0.14520267  0.01178692  0.04523337  0.52847561\n",
      " -0.13421128  0.19149351 -0.00787756  0.09143864 -0.16016158  0.30505231\n",
      "  0.04222738  0.33060721 -0.08104142  0.20294599  0.18485121  0.07951933\n",
      "  0.2628122 ]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(100000):\n",
    "        SGDorder = Sequence[step % 20] # training을 0번부터 20번까지 순차적으로 돌린다.\n",
    "        session.run(train, feed_dict ={X: X_TrainingData[SGDorder: SGDorder + 1,:], Y: Y_TrainingData[SGDorder: SGDorder + 1]})\n",
    "        #session.run(train, feed_dict ={X: X_TrainingData, Y: Y_TrainingData})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print (SGDorder, step, session.run(cost, feed_dict = {X: X_TrainingData, Y: Y_TrainingData}))\n",
    "            #print (W1)\n",
    "            #print (b1)\n",
    "        if step % 20 == 0:\n",
    "            random.shuffle(Sequence)\n",
    "            \n",
    "    Predict_to_TestData = session.run(Hypothesis, feed_dict={X : X_TestData})\n",
    "    Predict_to_TrainingData = session.run(Hypothesis, feed_dict={X : X_TrainingData})\n",
    "    Predict_to_EntireData = session.run(Hypothesis, feed_dict = {X : X_NormalizedData})\n",
    "    \n",
    "    print(\"R_square of EntireData\")\n",
    "    print(r2_score(Y_NormalizedData, Predict_to_EntireData))\n",
    "    print(\"R_square of TestData\")\n",
    "    print(r2_score(Y_TestData, Predict_to_TestData))\n",
    "    print(\"Result of predicting TrainingData\")\n",
    "    print(Predict_to_TrainingData)\n",
    "    print(\"Result of predicting TestData\")\n",
    "    print(Predict_to_TestData)\n",
    "    print(\"Y_NormalizedData\")\n",
    "    print(Y_NormalizedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11th eLU, tanh, 4, 100, 100, 1, training 5만\n",
    "R_square of EntireData\n",
    "0.680782977573\n",
    "R_square of TestData\n",
    "-4.76003266007"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "n_InputUnit = 4\n",
    "n_1stHiddenUnit=100\n",
    "n_2ndHiddenUnit=100\n",
    "n_OutputUnit = 1\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([n_InputUnit, n_1stHiddenUnit],stddev=0.01))\n",
    "W2 = tf.Variable(tf.random_normal([n_1stHiddenUnit, n_2ndHiddenUnit],stddev=0.01))\n",
    "W3 = tf.Variable(tf.random_normal([n_2ndHiddenUnit, n_OutputUnit],stddev=0.01))\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([n_1stHiddenUnit], stddev=0.01))\n",
    "b2 = tf.Variable(tf.random_normal([n_2ndHiddenUnit], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([n_OutputUnit], stddev=0.01))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 4]) # tensorflow의 placeholder라는 변수를 선언\n",
    "Y = tf.placeholder(tf.float32, [None,])\n",
    "\n",
    "L1 = tf.nn.elu(tf.matmul(X, W1) + b1)\n",
    "L2 = tf.nn.elu(tf.matmul(L1, W2) + b2)\n",
    "Hypothesis = tf.nn.tanh(tf.matmul(L2, W3) + b3)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(Y-Hypothesis))\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=0.5).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train NN & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 0 0.0591034\n",
      "10 1000 0.095497\n",
      "0 2000 0.100748\n",
      "10 3000 0.10011\n",
      "19 4000 0.10358\n",
      "2 5000 0.102973\n",
      "16 6000 0.107615\n",
      "17 7000 0.104846\n",
      "4 8000 0.102327\n",
      "15 9000 0.10647\n",
      "3 10000 0.100107\n",
      "12 11000 0.102766\n",
      "17 12000 0.100352\n",
      "17 13000 0.102319\n",
      "11 14000 0.102009\n",
      "17 15000 0.108424\n",
      "4 16000 0.106031\n",
      "15 17000 0.101045\n",
      "3 18000 0.106557\n",
      "1 19000 0.108531\n",
      "1 20000 0.107142\n",
      "16 21000 0.108163\n",
      "5 22000 0.100563\n",
      "15 23000 0.10887\n",
      "11 24000 0.113715\n",
      "11 25000 0.11393\n",
      "2 26000 0.110144\n",
      "10 27000 0.121316\n",
      "1 28000 0.112117\n",
      "0 29000 0.116818\n",
      "7 30000 0.113812\n",
      "16 31000 0.112864\n",
      "9 32000 0.113096\n",
      "12 33000 0.121244\n",
      "1 34000 0.111504\n",
      "12 35000 0.115022\n",
      "5 36000 0.116123\n",
      "0 37000 0.111989\n",
      "3 38000 0.114672\n",
      "3 39000 0.114947\n",
      "18 40000 0.116181\n",
      "0 41000 0.11369\n",
      "12 42000 0.114471\n",
      "4 43000 0.113867\n",
      "7 44000 0.115502\n",
      "19 45000 0.113971\n",
      "0 46000 0.113858\n",
      "8 47000 0.113345\n",
      "8 48000 0.115065\n",
      "12 49000 0.113724\n",
      "R_square of EntireData\n",
      "0.680782977573\n",
      "R_square of TestData\n",
      "-4.76003266007\n",
      "Result of predicting TrainingData\n",
      "[[-0.2106258 ]\n",
      " [-0.46098411]\n",
      " [-0.44991985]\n",
      " [-0.10494339]\n",
      " [-0.09192928]\n",
      " [-0.16255938]\n",
      " [-0.20628634]\n",
      " [ 0.0073505 ]\n",
      " [-0.14744429]\n",
      " [ 0.01457615]\n",
      " [ 0.05437038]\n",
      " [ 0.54228348]\n",
      " [-0.13632232]\n",
      " [ 0.19949335]\n",
      " [-0.01559612]\n",
      " [ 0.10600006]\n",
      " [-0.1351376 ]\n",
      " [ 0.31449604]\n",
      " [ 0.05013368]\n",
      " [ 0.35806456]]\n",
      "Result of predicting TestData\n",
      "[[-0.36008528]\n",
      " [ 0.28219074]\n",
      " [-0.34120658]\n",
      " [ 0.0236871 ]\n",
      " [ 0.0244792 ]]\n",
      "Y_NormalizedData\n",
      "[-0.21844449 -0.47152439 -0.45735005 -0.1123416  -0.11245536 -0.18036006\n",
      " -0.19692817  0.00145492 -0.14520267  0.01178692  0.04523337  0.52847561\n",
      " -0.13421128  0.19149351 -0.00787756  0.09143864 -0.16016158  0.30505231\n",
      "  0.04222738  0.33060721 -0.08104142  0.20294599  0.18485121  0.07951933\n",
      "  0.2628122 ]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(50000):\n",
    "        SGDorder = Sequence[step % 20] # training을 0번부터 20번까지 순차적으로 돌린다.\n",
    "        session.run(train, feed_dict ={X: X_TrainingData[SGDorder: SGDorder + 1,:], Y: Y_TrainingData[SGDorder: SGDorder + 1]})\n",
    "        #session.run(train, feed_dict ={X: X_TrainingData, Y: Y_TrainingData})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print (SGDorder, step, session.run(cost, feed_dict = {X: X_TrainingData, Y: Y_TrainingData}))\n",
    "            #print (W1)\n",
    "            #print (b1)\n",
    "        if step % 20 == 0:\n",
    "            random.shuffle(Sequence)\n",
    "            \n",
    "    Predict_to_TestData = session.run(Hypothesis, feed_dict={X : X_TestData})\n",
    "    Predict_to_TrainingData = session.run(Hypothesis, feed_dict={X : X_TrainingData})\n",
    "    Predict_to_EntireData = session.run(Hypothesis, feed_dict = {X : X_NormalizedData})\n",
    "    \n",
    "    print(\"R_square of EntireData\")\n",
    "    print(r2_score(Y_NormalizedData, Predict_to_EntireData))\n",
    "    print(\"R_square of TestData\")\n",
    "    print(r2_score(Y_TestData, Predict_to_TestData))\n",
    "    print(\"Result of predicting TrainingData\")\n",
    "    print(Predict_to_TrainingData)\n",
    "    print(\"Result of predicting TestData\")\n",
    "    print(Predict_to_TestData)\n",
    "    print(\"Y_NormalizedData\")\n",
    "    print(Y_NormalizedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
