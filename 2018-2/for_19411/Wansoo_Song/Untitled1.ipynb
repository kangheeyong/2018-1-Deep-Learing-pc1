{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "import random\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.000001\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "batchsize = 50\n",
    "\n",
    "n_InputUnit = 3648\n",
    "n_1stHiddenUnit = 3648\n",
    "n_2ndHiddenUnit = 500\n",
    "n_3rdHiddenUnit = 200\n",
    "n_4thHiddenUnit = 60\n",
    "n_OutputUnit = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm which decides standard for classifying data\n",
    "# Algorithm which can detect some kind of different phenomena\n",
    "W1 = np.random.normal(0.0,0.01,size = n_InputUnit)\n",
    "\n",
    "batch_X = RealOESdata[Order*batchsize: (Order+1)*batchsize,:]\n",
    "L = W1[0]*batch_X[0,0]\n",
    "for i in range (batchsize):\n",
    "    for j in range(3648):\n",
    "        if i == 0 && j == 0:\n",
    "            L = L\n",
    "        else:\n",
    "            L = np.hstack((L, W1[j]*batch_X[batch])))\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([n_1stHiddenUnit, n_2ndHiddenUnit],stddev=0.01))\n",
    "W3 = tf.Variable(tf.random_normal([n_2ndHiddenUnit, n_3rdHiddenUnit],stddev=0.01))\n",
    "W4 = tf.Variable(tf.random_normal([n_3rdHiddenUnit, n_4thHiddenUnit],stddev=0.01))\n",
    "W5 = tf.Variable(tf.random_normal([n_4thHiddenUnit, n_OutputUnit],stddev=0.01))\n",
    "\n",
    "b2 = tf.Variable(tf.random_normal([n_2ndHiddenUnit], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([n_3rdHiddenUnit], stddev=0.01))\n",
    "b4 = tf.Variable(tf.random_normal([n_4thHiddenUnit], stddev=0.01))\n",
    "b5 = tf.Variable(tf.random_normal([n_OutputUnit], stddev=0.01))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [n_InputUnit, None]) # tensorflow의 placeholder라는 변수를 선언\n",
    "Y = tf.placeholder(tf.float32, [None, n_OutputUnit])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "L2 = tf.nn.elu(tf.matmul(X, W2) + b2)\n",
    "L2_drop = tf.nn.dropout(L2, keep_prob)\n",
    "\n",
    "L3 = tf.nn.elu(tf.matmul(L2_drop, W3) + b3)\n",
    "L3_drop = tf.nn.dropout(L3, keep_prob)\n",
    "\n",
    "L4 = tf.nn.elu(tf.matmul(L3_drop, W4) + b4)\n",
    "logits = tf.matmul(L4, W5) + b5\n",
    "Hypothesis = tf.nn.softmax(logits)\n",
    "\n",
    "K = 0.0\n",
    "for i in range(3648):\n",
    "    K = K+abs(W1[i])\n",
    "\n",
    "#tf.stop_gradient(Y)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=logits) + K)\n",
    "#cost = cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(, Y))\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=0.5).minimize(cost)\n",
    "prediction = tf.argmax(Hypothesis, 1)\n",
    "correct_prediction = tf.equal(tf.argmax(Hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    \n",
    "    \n",
    "    for step in range (150001):\n",
    "        Order = Sequence[step % 24]\n",
    "        \n",
    "        \n",
    "        ### Y_ClassifiedResult_Power -> Power에 대한 one hot vector\n",
    "        batch_Y = np.reshape(Y_ClassifiedResult_Press[Order*batchsize: (Order+1)*batchsize,:],\n",
    "                             (batchsize, n_OutputUnit))\n",
    "        session.run(train, feed_dict = {X: batch_X, Y: batch_Y, keep_prob: 0.5})\n",
    "        MinibatchCost = session.run(cost, feed_dict = {X: batch_X, Y: batch_Y, keep_prob: 1.0})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={X: batch_X, Y: batch_Y, keep_prob: 1.0})\n",
    "            print ('Step %i: Minibatch Loss: %f, Minibatch Accuracy: %f' % (step, MinibatchCost,\n",
    "                                                                            train_accuracy))\n",
    "            \n",
    "        if step % 24 == 0:\n",
    "            random.shuffle(Sequence)\n",
    "    \n",
    "    RealOESdata_Reshaped = np.reshape(RealOESdata, (1200, 3648))\n",
    "    \n",
    "    ###Y_ClassifiedResult_Power\n",
    "    train_accuracy = accuracy.eval(feed_dict = {X: RealOESdata_Reshaped, Y: Y_ClassifiedResult_Press, keep_prob: 1.0})        \n",
    "    print('Full batch Accuracy: %f' % (train_accuracy))\n",
    "    \n",
    "    PredictedSimplifiedInputData = session.run(logits, feed_dict = {X : SimplifiedInput,keep_prob: 1.0})\n",
    "    print(PredictedSimplifiedInputData)\n",
    "    np.savetxt('Press_Weight.txt', PredictedSimplifiedInputData, delimiter='\\t')\n",
    "    \n",
    "    PredictedSimplifiedInputDataLinear = session.run(WL4, feed_dict = {X : SimplifiedInput,keep_prob: 1.0})\n",
    "    print(PredictedSimplifiedInputDataLinear)\n",
    "    np.savetxt('Press_Weight2.txt', PredictedSimplifiedInputDataLinear, delimiter='\\t')\n",
    "    \n",
    "    #for i in range(24):\n",
    "    #    Result_batch_X = np.reshape(RealOESdata[i*batchsize: (i+1)*batchsize,:],\n",
    "    #                                (batchsize, n_InputUnit))\n",
    "    #    PredictedBatchData = session.run(prediction, feed_dict = {X : Result_batch_X, keep_prob: 1.0})\n",
    "    #    \n",
    "    #    ### Y_ClassifiedResult_Power\n",
    "    #    Y_ClassifiedResult_Reshaped = np.reshape(Y_ClassifiedResult_Press[i*batchsize: (i+1)*batchsize,:],\n",
    "    #                                             (batchsize, n_OutputUnit))\n",
    "    #    \n",
    "    #    if i % 1 == 0:\n",
    "    #        print(\"Original Data\")\n",
    "    #        print(Y_ClassifiedResult_Reshaped[0,:])\n",
    "    #    \n",
    "    #    print(i)\n",
    "    #    print(\"Result of predicting EntireData\")\n",
    "    #    print(PredictedBatchData)\n",
    "    #        \n",
    "    #print(\"####################################################\")  \n",
    "    #\n",
    "    #for i in range(24):\n",
    "    #    #\n",
    "    #    Test_batch_X = np.reshape(TestOESdata[i*batchsize: (i+1)*batchsize,:],\n",
    "    #                                (batchsize, n_InputUnit))\n",
    "    #    \n",
    "    #    \n",
    "    #    PredictedTestBatchData = session.run(prediction, feed_dict = {X : Test_batch_X, keep_prob: 1.0})\n",
    "    #    \n",
    "    #    ###Y_Test_Power -> Test data의 power에 대한 one hot vector\n",
    "    #    #\n",
    "    #    Y_Test_Reshaped = np.reshape(Y_Test_Press[i*batchsize: (i+1)*batchsize,:],\n",
    "    #                                             (batchsize, n_OutputUnit))\n",
    "    #    \n",
    "    #    if i % 1 == 0:\n",
    "    #        print(\"Original Data\")\n",
    "    #        print(Y_Test_Reshaped[0,:])\n",
    "    #    \n",
    "    #    print(i)\n",
    "    #    print(\"Result of Predicted Test Data\")\n",
    "    #    print(PredictedTestBatchData)\n",
    "    ##\n",
    "    #TestOESdata_Reshaped = np.reshape(TestOESdata, (1200,3648))\n",
    "    #\n",
    "    ####Y_Test_Power\n",
    "    ##\n",
    "    #train_accuracy = accuracy.eval(feed_dict = {X: TestOESdata_Reshaped, Y: Y_Test_Press, keep_prob: 1.0})        \n",
    "    #print('Test Full batch Accuracy: %f' % (train_accuracy))          \n",
    "    #"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "384px",
    "left": "588px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
